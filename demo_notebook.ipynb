{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CVSS-BERT\n",
    "\n",
    "This notebook describes the code corresponding to the following paper:\n",
    "\n",
    "M. R. Shahid and H. Debar , \"CVSS-BERT: Explainable Natural Language Processing to Determine the Severity of a Computer Security Vulnerability from its Description,\" *2021 20th IEEE International Conference on Machine Learning and Applications (ICMLA)*, 2021.\n",
    "\n",
    "**Abstract:** When a new computer security vulnerability is publicly disclosed, only a textual description of it is available. Cybersecurity experts later provide an analysis of the severity of the vulnerability using the Common Vulnerability Scoring System (CVSS). Specifically, the different characteristics of the vulnerability are summarized into a vector (consisting of a set of metrics), from which a severity score is computed. However, because of the high number of vulnerabilities disclosed everyday this process requires lot of manpower, and several days may pass before a vulnerability is analyzed. We propose to leverage recent advances in the field of Natural Language Processing (NLP) to determine the CVSS vector and the associated severity score of a vulnerability from its textual description in an explainable manner. To this purpose, we trained multiple BERT classifiers, one for each metric composing the CVSS vector. Experimental results show that our trained classifiers are able to determine the value of the metrics of the CVSS vector with high accuracy. The severity score computed from the predicted CVSS vector is also very close to the real severity score attributed by a human expert. For explainability purpose, gradient-based input saliency method was used to determine the most relevant input words for a given prediction made by our classifiers. Often, the top relevant words include terms in agreement with the rationales of a human cybersecurity expert, making the explanation comprehensible for end-users.\n",
    "\n",
    "A CVSS vector consists of 8 metrics: Attack Vector, Attack Complexity, Privileges Required, User Interaction, Scope, Confidentiality Impact, Integrity Impact, Availability Impact. **In this notebook, we describe how to train a BERT classifier to determine the \"Confidentiality Impact\" metric of a vulnerability from its textual description. The \"Confidentiality Impact\" is a categorical variable that can take 3 values: HIGH, LOW, NONE. Hence, the task described in this notebook is a classification problem. We are trying to determine the \"Confidentiality Impact\" of a vulnerability from its textual description.** The methodology described in this notebook can be used to determine the value of the other metrics composing the CVSS vector.\n",
    "\n",
    "The notebook contains 4 parts:\n",
    "- Data preprocessing\n",
    "- BERT classifier training\n",
    "- BERT classifier testing\n",
    "- Explaining classification results using gradient-based input saliency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22963, 2)\n",
      "(22963, 2)\n",
      "(22963, 16)\n",
      "(22963, 16)\n",
      "HIGH    0.589949\n",
      "NONE    0.212516\n",
      "LOW     0.197535\n",
      "Name: cvssV3_confidentialityImpact, dtype: float64\n",
      "HIGH    0.588599\n",
      "NONE    0.215477\n",
      "LOW     0.195924\n",
      "Name: cvssV3_confidentialityImpact, dtype: float64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22963 entries, 0 to 22962\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   CVE_ID       22963 non-null  object\n",
      " 1   Description  22963 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 358.9+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22963 entries, 0 to 22962\n",
      "Data columns (total 16 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   cvssV3_vectorString           22963 non-null  object \n",
      " 1   cvssV3_attackVector           22963 non-null  object \n",
      " 2   cvssV3_attackComplexity       22963 non-null  object \n",
      " 3   cvssV3_privilegesRequired     22963 non-null  object \n",
      " 4   cvssV3_userInteraction        22963 non-null  object \n",
      " 5   cvssV3_scope                  22963 non-null  object \n",
      " 6   cvssV3_confidentialityImpact  22963 non-null  object \n",
      " 7   cvssV3_integrityImpact        22963 non-null  object \n",
      " 8   cvssV3_availabilityImpact     22963 non-null  object \n",
      " 9   cvssV3_baseScore              22963 non-null  float64\n",
      " 10  cvssV3_baseSeverity           22963 non-null  object \n",
      " 11  V3_exploitabilityScore        22963 non-null  float64\n",
      " 12  V3_impactScore                22963 non-null  float64\n",
      " 13  nb_CWE                        22963 non-null  int64  \n",
      " 14  CWE1                          22963 non-null  object \n",
      " 15  CWE2                          22963 non-null  object \n",
      "dtypes: float64(3), int64(1), object(12)\n",
      "memory usage: 2.8+ MB\n",
      "None\n",
      "['HIGH', 'HIGH', 'HIGH', 'LOW', 'NONE', 'NONE', 'NONE', 'HIGH', 'HIGH', 'HIGH'] ['LOW', 'HIGH', 'LOW', 'HIGH', 'LOW', 'HIGH', 'HIGH', 'HIGH', 'HIGH', 'HIGH']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#loading train and test datasets. X_* contains vulnerability ID and description, y_* contains the target labels.\n",
    "#for more information on how the dataset was obtained and partitioned, we refer the reader to the original paper\n",
    "\n",
    "X_train = pd.read_csv('./data/cve_2018-2020_X_train.csv')\n",
    "y_train = pd.read_csv('./data/cve_2018-2020_y_train.csv')\n",
    "\n",
    "X_test = pd.read_csv('./data/cve_2018-2020_X_test.csv')\n",
    "y_test = pd.read_csv('./data/cve_2018-2020_y_test.csv')\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "label_column_name = \"cvssV3_confidentialityImpact\" #we only keep the Confidentiality Impact metric for our target label\n",
    "\n",
    "#check the class ditribution in our dataset\n",
    "print(y_train[label_column_name].value_counts(dropna=False) / y_train.shape[0])\n",
    "print(y_test[label_column_name].value_counts(dropna=False) / y_test.shape[0])\n",
    "print(X_train.info())\n",
    "print(y_train.info())\n",
    "\n",
    "\n",
    "\n",
    "train_labels = y_train.loc[:, label_column_name]\n",
    "test_labels = y_test.loc[:, label_column_name]\n",
    "\n",
    "print(list(train_labels[:10]), list(test_labels[:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of classes: 3\n",
      "classes: ['HIGH' 'LOW' 'NONE']\n",
      "examples of labels from the training set:\n",
      " 0    HIGH\n",
      "1    HIGH\n",
      "2    HIGH\n",
      "3     LOW\n",
      "4    NONE\n",
      "Name: cvssV3_confidentialityImpact, dtype: object \n",
      " the corresponding encoded training labels: [0 0 0 1 2]\n",
      "examples of labels from the test set:\n",
      " 0     LOW\n",
      "1    HIGH\n",
      "2     LOW\n",
      "3    HIGH\n",
      "4     LOW\n",
      "Name: cvssV3_confidentialityImpact, dtype: object \n",
      " the corresponding encoded test labels: [1 0 1 0 1]\n",
      "22963 22963 22963 22963\n"
     ]
    }
   ],
   "source": [
    "from explainable_bert_classifier.data import train_test_LabelEncoder\n",
    "\n",
    "encoded_train_labels, encoded_test_labels = train_test_LabelEncoder(train_labels, test_labels)\n",
    "print(\"examples of labels from the training set:\\n\", train_labels[:5], \"\\n the corresponding encoded training labels:\", encoded_train_labels[:5])\n",
    "print(\"examples of labels from the test set:\\n\", test_labels[:5], \"\\n the corresponding encoded test labels:\", encoded_test_labels[:5])\n",
    "print(len(X_train), len(train_labels), len(X_test), len(test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizing the vulnerability descriptions: splitting into smaller units (words, subwords,...). Under the hood BERT tokenizer provided by Huggingface Transformers library is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from explainable_bert_classifier.data import tokenizer\n",
    "\n",
    "mytokenizer = tokenizer()\n",
    "\n",
    "train_encodings = mytokenizer(X_train.loc[:,\"Description\"].tolist(), truncation=True, padding=True, max_length=128)\n",
    "test_encodings = mytokenizer(X_test.loc[:,\"Description\"].tolist(), truncation=True, padding=True, max_length=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([  101,  1037, 18130,  1999, 26408, 16380, 17083,  8080,  1006, 17083,\n",
       "          8202,  1007,  4007,  2005, 26408, 16771, 23944,  2692,  2186, 15924,\n",
       "          2071,  3499,  2019, 14477, 14317,  4765, 17872,  1010,  2334, 17346,\n",
       "          2000, 11826, 26408,  5851,  9573, 27354, 14148,  1998,  7170,  1037,\n",
       "         20419,  4007,  3746,  2006,  2019,  5360,  5080,  1012,  1996, 18130,\n",
       "          2003,  2349,  2000,  1996,  3739,  1997,  1037,  5023,  3094,  1999,\n",
       "          1996,  5360,  4007,  1012,  2019, 17346,  2071, 18077,  2023, 18130,\n",
       "          2011,  7176,  2000,  2019,  5360,  5080,  3081,  1996, 10122,  1010,\n",
       "          6932,  1996,  5080,  2046, 17083,  8202,  5549,  1010,  1998,  3015,\n",
       "          1037, 24391,  5418,  2000,  1037,  3563,  3638,  4769,  2006,  1996,\n",
       "          5080,  1012,  1037,  3144, 18077,  2071,  3499,  1996, 17346,  2000,\n",
       "         11826,  8085, 27354, 14148,  2011, 26408,  5851,  9573,  2974,  1998,\n",
       "          7170,  1037, 20419,  4007,  3746,  2006,  1996,   102]),\n",
       " 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1]),\n",
       " 'text_labels': 'HIGH',\n",
       " 'encoded_labels': tensor(0),\n",
       " 'CVE_ID': 'CVE-2018-15370',\n",
       " 'vulnerability_description': 'A vulnerability in Cisco IOS ROM Monitor (ROMMON) Software for Cisco Catalyst 6800 Series Switches could allow an unauthenticated, local attacker to bypass Cisco Secure Boot validation checks and load a compromised software image on an affected device. The vulnerability is due to the presence of a hidden command in the affected software. An attacker could exploit this vulnerability by connecting to an affected device via the console, forcing the device into ROMMON mode, and writing a malicious pattern to a specific memory address on the device. A successful exploit could allow the attacker to bypass signature validation checks by Cisco Secure Boot technology and load a compromised software image on the affected device. A compromised software image is any software image that has not been digitally signed by Cisco.'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating an object that inherits from Pytorch dataset class. Required to train Pytorch models.\n",
    "\n",
    "from explainable_bert_classifier.data import CVEDataset\n",
    "\n",
    "train_dataset = CVEDataset(X_train, train_encodings, train_labels, encoded_train_labels)\n",
    "test_dataset = CVEDataset(X_test, test_encodings, test_labels, encoded_test_labels)\n",
    "\n",
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a BERT classifier with the appropriate number of classes added on top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-small were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-small and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from explainable_bert_classifier.model import BertClassifier\n",
    "\n",
    "NUM_CLASSES = len(set(train_labels))\n",
    "print(NUM_CLASSES)\n",
    "\n",
    "classifier =  BertClassifier(num_labels=NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BERT is a pretrained model that was trained on huge corpus of textual data to effectively model texts written in English (underlying syntax, semantics, meanings, relationships between words, etc.). To have a BERT classifier, we added a classifier on top of the base pretrained BERT model. We have to be careful during training because the added classifier is randomly initialized. Hence, very large weight updates will be propagated through the network, and the representation learned by the pretrained BERT model will be destroyed. To avoid this issue, the weights of the base pretrained BERT model are frozen for the first 2 epochs and only the weights of the classifier are fine-tuned. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of trainable parameters: 1539\n",
      "trainable parameters: classifier.weight tensor([[-0.0007, -0.0114,  0.0002,  ...,  0.0212,  0.0017,  0.0161],\n",
      "        [-0.0045, -0.0333, -0.0033,  ...,  0.0218,  0.0051, -0.0059],\n",
      "        [ 0.0290, -0.0194,  0.0062,  ...,  0.0171, -0.0216, -0.0264]])\n",
      "trainable parameters: classifier.bias tensor([0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "classifier.freeze_base()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Training Loss: 0.9459798993151897, Training Accuracy = 0.5854635718329486\n",
      "Epoch: 1, Training Loss: 0.9046845489229801, Training Accuracy = 0.5937377520358839\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from transformers import AdamW\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16)\n",
    "\n",
    "\n",
    "history1 = classifier.fit(loader=train_loader, total_iterations=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the 2 \"warm-up\" epochs, the weights of the classifier reach reasonable values. The weights of the base pretrained BERT model are unfrozen. From here on, the classifier and the base BERT model are trained jointly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of trainable parameters: 28765187\n",
      "trainable parameters: bert.embeddings.word_embeddings.weight tensor([[ 0.0770, -0.1024,  0.0109,  ...,  0.0265,  0.0527, -0.0099],\n",
      "        [-0.0062, -0.0448,  0.0068,  ...,  0.0460,  0.0177, -0.0487],\n",
      "        [-0.0014, -0.0184,  0.0207,  ...,  0.0936,  0.0561, -0.0690],\n",
      "        ...,\n",
      "        [-0.0539, -0.0298,  0.0711,  ...,  0.0057,  0.0172, -0.0437],\n",
      "        [ 0.0446, -0.0571,  0.0028,  ..., -0.0138,  0.0534, -0.0741],\n",
      "        [ 0.0798,  0.0307, -0.0254,  ...,  0.0389,  0.0417, -0.0208]])\n",
      "trainable parameters: bert.embeddings.position_embeddings.weight tensor([[-2.2368e-03, -1.6215e-02, -5.7656e-03,  ..., -8.1258e-02,\n",
      "         -1.8137e-02,  1.0507e-03],\n",
      "        [-1.4434e-02, -9.5276e-03, -3.3733e-04,  ...,  2.2632e-02,\n",
      "         -2.4823e-02, -2.0542e-02],\n",
      "        [-1.3487e-02, -6.8095e-05,  7.1685e-03,  ...,  4.7153e-03,\n",
      "         -1.9992e-03,  6.1711e-03],\n",
      "        ...,\n",
      "        [ 2.4908e-02, -1.1784e-03, -9.2854e-03,  ...,  1.1964e-03,\n",
      "         -1.9798e-02,  4.2636e-03],\n",
      "        [ 2.8236e-02, -1.1161e-02,  1.2986e-02,  ..., -1.3145e-02,\n",
      "         -2.3795e-02, -9.2794e-03],\n",
      "        [-1.1595e-01,  4.0169e-02, -1.8074e-02,  ..., -1.9477e-02,\n",
      "          1.4155e-02, -8.6847e-02]])\n",
      "trainable parameters: bert.embeddings.token_type_embeddings.weight tensor([[ 0.0018,  0.0157,  0.0012,  ...,  0.0003,  0.0008, -0.0003],\n",
      "        [ 0.0096,  0.0078, -0.0005,  ...,  0.0021,  0.0008,  0.0033]])\n",
      "trainable parameters: bert.embeddings.LayerNorm.weight tensor([1.0034, 0.9734, 1.0339, 0.9759, 1.0329, 0.9348, 1.0640, 0.9110, 0.7746,\n",
      "        1.0390, 1.0827, 1.0285, 1.0088, 1.0306, 1.0258, 1.0381, 1.0420, 1.0932,\n",
      "        1.0324, 1.0761, 0.9938, 0.9593, 1.0131, 0.2699, 1.0195, 1.0126, 1.0117,\n",
      "        1.0622, 1.0085, 1.0426, 1.0065, 0.6157, 0.9810, 1.0818, 1.0051, 0.9930,\n",
      "        0.9159, 0.8869, 1.0652, 1.0311, 1.0263, 0.9553, 0.9719, 0.9848, 1.0022,\n",
      "        1.0505, 1.0381, 0.9876, 1.0145, 0.9522, 0.9998, 1.0502, 1.0087, 1.0512,\n",
      "        1.0562, 1.0013, 0.9994, 1.0906, 1.0435, 1.0236, 1.0520, 1.0947, 1.0363,\n",
      "        1.0631, 1.0075, 1.0199, 1.0587, 0.9934, 1.0314, 1.0170, 1.0488, 1.0740,\n",
      "        0.9587, 1.0365, 0.9911, 0.9992, 1.0818, 1.0270, 1.0651, 1.0286, 0.9470,\n",
      "        1.0499, 1.0596, 1.0377, 0.9994, 0.9777, 1.0159, 1.0252, 0.9654, 0.9655,\n",
      "        1.0130, 1.0144, 1.0392, 1.0346, 0.9942, 1.0510, 0.9944, 1.0531, 1.0308,\n",
      "        0.9650, 1.0581, 1.0535, 0.9822, 1.0426, 1.0097, 0.9952, 1.0254, 0.9723,\n",
      "        0.9495, 1.0376, 1.0125, 1.0060, 1.0174, 1.0061, 0.9635, 0.9505, 1.0104,\n",
      "        1.0527, 0.9248, 0.9430, 0.9208, 0.2811, 1.0434, 0.9928, 0.9989, 1.0287,\n",
      "        1.0341, 0.9946, 0.9816, 1.0062, 0.8707, 1.0235, 1.0387, 1.0315, 0.3075,\n",
      "        1.0543, 0.6230, 1.0598, 1.0955, 1.0605, 1.0588, 1.0279, 1.0038, 1.0625,\n",
      "        1.0251, 1.0181, 0.9990, 0.9988, 1.0078, 1.0615, 0.9940, 0.9671, 0.9885,\n",
      "        0.9848, 1.0222, 1.0222, 0.7879, 0.9493, 0.9443, 1.0465, 0.9998, 0.9977,\n",
      "        1.0355, 1.0547, 1.0213, 1.0370, 0.6097, 1.0172, 0.9928, 1.0178, 1.0336,\n",
      "        0.9287, 0.9921, 1.0203, 1.0709, 0.9740, 0.9564, 1.0099, 1.0028, 1.0078,\n",
      "        0.9877, 0.9929, 1.0411, 0.9252, 0.9876, 1.0458, 1.0324, 0.9749, 1.0107,\n",
      "        1.0354, 1.0335, 1.0514, 1.0009, 0.4976, 1.0231, 1.0229, 0.9812, 0.9792,\n",
      "        1.0383, 1.0872, 1.0634, 1.0052, 1.0952, 0.9343, 1.0401, 0.9857, 0.9938,\n",
      "        0.9854, 1.0203, 0.9849, 0.9843, 0.9969, 1.0243, 1.0206, 0.9118, 1.0016,\n",
      "        1.0131, 0.9935, 0.9791, 1.0394, 0.9003, 1.0023, 1.0233, 1.0437, 1.0280,\n",
      "        0.9996, 1.0296, 0.9463, 0.9597, 1.0787, 1.0185, 1.0015, 1.0090, 1.0273,\n",
      "        1.0120, 1.0660, 1.0325, 0.9119, 1.0332, 0.9869, 1.0016, 1.0422, 1.0315,\n",
      "        0.7693, 1.0422, 1.0438, 1.0457, 1.0582, 1.0005, 1.0737, 1.0191, 1.0168,\n",
      "        1.0190, 1.0070, 1.0406, 1.0570, 0.9394, 0.9484, 0.9239, 1.0445, 0.9722,\n",
      "        1.0149, 0.2265, 1.0745, 0.9605, 0.9636, 0.9492, 1.0412, 1.1088, 1.0338,\n",
      "        1.0478, 1.0076, 1.0034, 1.0383, 1.0027, 0.7969, 0.7445, 1.0086, 1.0241,\n",
      "        1.0159, 1.0114, 1.0094, 1.0538, 0.9592, 1.0406, 1.0204, 1.0377, 0.9681,\n",
      "        0.9656, 1.0550, 0.9685, 1.0834, 0.9997, 1.0156, 1.0520, 0.9925, 1.0208,\n",
      "        0.9202, 1.0037, 1.0040, 1.0402, 1.0831, 1.0331, 1.0155, 1.0271, 1.0067,\n",
      "        1.0593, 1.0141, 1.0697, 1.0174, 1.0293, 1.0129, 1.0579, 1.0292, 1.0603,\n",
      "        0.9600, 1.0104, 1.0546, 1.0409, 0.9511, 1.0166, 0.9935, 1.0377, 1.0800,\n",
      "        1.0789, 1.0276, 1.0294, 1.0200, 0.3678, 1.0114, 1.0090, 1.0459, 1.0241,\n",
      "        1.0431, 0.5972, 1.0184, 0.9906, 1.0089, 0.9738, 1.0185, 1.0564, 0.9955,\n",
      "        0.9639, 1.0098, 0.9804, 1.0246, 1.0010, 1.0747, 1.0048, 0.9969, 0.2762,\n",
      "        1.0097, 0.9405, 1.0045, 1.0563, 1.0390, 0.5877, 1.0226, 0.9398, 0.9913,\n",
      "        1.0222, 1.0169, 0.9680, 0.9960, 1.0611, 1.0709, 1.0509, 1.0354, 1.0018,\n",
      "        1.0421, 1.0029, 1.0450, 1.0476, 0.9643, 1.0304, 0.9640, 1.0566, 1.0082,\n",
      "        1.0217, 0.9993, 1.0591, 1.0388, 1.0053, 0.9844, 1.0191, 1.0019, 0.3202,\n",
      "        1.0095, 1.0126, 0.9875, 1.0421, 1.0520, 1.0429, 0.9640, 1.0050, 1.0512,\n",
      "        1.0287, 1.0556, 1.0272, 1.0198, 1.0026, 1.0347, 1.0404, 1.0405, 0.9292,\n",
      "        1.0203, 1.0854, 1.0008, 1.0038, 1.0246, 1.0164, 1.0112, 1.0516, 0.9808,\n",
      "        1.0530, 1.0258, 1.0419, 1.0368, 0.9644, 1.0167, 1.0669, 0.5925, 1.0068,\n",
      "        1.0357, 0.8449, 1.0377, 0.9907, 0.9799, 1.0162, 0.9761, 1.0031, 1.0345,\n",
      "        1.0067, 1.0728, 1.0487, 0.9266, 1.0323, 1.0616, 1.0152, 1.0464, 1.0301,\n",
      "        0.9941, 1.0352, 1.0526, 0.7651, 0.9933, 0.9531, 1.0055, 1.0728, 1.0437,\n",
      "        1.0523, 1.0203, 1.0580, 0.9148, 0.5365, 0.9980, 1.0527, 1.0501, 1.0150,\n",
      "        1.0197, 1.0158, 1.0328, 0.9232, 0.9206, 0.9979, 0.9618, 1.0299, 1.0892,\n",
      "        1.0012, 0.4570, 0.9594, 1.0116, 0.9440, 0.9823, 0.8462, 1.0090, 1.0683,\n",
      "        1.0466, 1.0687, 1.0129, 1.0082, 1.0288, 0.9924, 1.0728, 1.0110, 1.0563,\n",
      "        1.0090, 0.9853, 1.0306, 1.0889, 0.9610, 1.0336, 0.9881, 1.0241, 0.9747,\n",
      "        1.0163, 1.0394, 0.9930, 1.0536, 1.0219, 0.9866, 0.9966, 0.9867, 0.9806,\n",
      "        1.0670, 1.0437, 0.9660, 0.9753, 1.0258, 0.9697, 1.0029, 1.0511])\n",
      "trainable parameters: bert.embeddings.LayerNorm.bias tensor([-7.5030e-02,  3.0542e-02, -3.8807e-02,  7.6015e-02,  6.8023e-02,\n",
      "        -3.5668e-02, -2.2968e-02, -2.0072e-02,  4.6957e-02, -8.6805e-02,\n",
      "        -2.9697e-02, -2.8380e-02,  1.2737e-03,  1.2192e-02, -1.1201e-01,\n",
      "        -3.2923e-02, -4.2584e-03,  5.2725e-02,  1.8230e-03, -3.4777e-02,\n",
      "         3.0596e-02, -5.1838e-02,  1.8954e-02,  9.5967e-02, -8.8823e-02,\n",
      "         1.1160e-02, -1.8184e-02,  1.5397e-02, -5.4874e-02,  4.2951e-02,\n",
      "        -4.9852e-02,  1.2850e-01, -1.1274e-02, -3.8277e-02, -5.9616e-02,\n",
      "         5.4902e-04, -9.8228e-02, -4.7431e-02, -7.0690e-02, -3.8623e-02,\n",
      "         1.1178e-02,  2.7043e-02, -9.7237e-02, -9.1909e-02, -4.5786e-02,\n",
      "        -4.2172e-02, -6.1973e-02, -6.7079e-02,  3.5619e-02, -5.0562e-03,\n",
      "        -3.2160e-02, -9.7595e-02, -4.5171e-02, -3.0408e-02,  3.1879e-02,\n",
      "        -1.3094e-01, -5.5456e-02, -2.5509e-02, -6.0790e-02,  1.9779e-02,\n",
      "        -3.8125e-02, -1.2645e-02, -4.6758e-02, -4.5201e-02,  9.4161e-03,\n",
      "         1.0789e-02, -1.6892e-02, -9.6474e-02, -1.5330e-02, -6.6676e-02,\n",
      "        -4.6583e-02,  2.5490e-02, -1.1072e-01,  2.4828e-02,  8.5192e-03,\n",
      "         3.9141e-02, -3.3495e-02, -5.4616e-02, -6.0242e-02, -6.8974e-02,\n",
      "        -6.1572e-02, -3.6197e-02, -4.4994e-02, -1.1822e-01, -7.3932e-02,\n",
      "         6.0744e-02, -1.8210e-02, -4.6057e-02,  2.4372e-02, -8.1497e-02,\n",
      "        -1.9896e-02, -6.4916e-02, -2.2755e-02, -2.6630e-02, -2.3123e-02,\n",
      "        -8.8825e-02,  5.7744e-02, -4.2875e-02, -6.6395e-02,  2.4206e-02,\n",
      "         1.1318e-02,  3.7825e-02, -6.4148e-02, -2.1503e-03,  3.1020e-03,\n",
      "         3.1318e-02, -4.1199e-02,  1.6554e-02, -5.8110e-02, -1.4418e-01,\n",
      "        -1.7707e-02, -5.8449e-02,  3.8187e-03, -4.8630e-03,  6.1345e-02,\n",
      "         2.2302e-02, -2.5289e-03,  1.8271e-02,  3.2277e-03,  1.5547e-02,\n",
      "         2.3244e-02,  2.2120e-01, -2.4322e-02,  3.9570e-02, -6.5671e-02,\n",
      "        -9.2782e-02, -1.2887e-01,  3.2640e-02,  1.2645e-03, -1.0531e-01,\n",
      "        -5.4867e-02,  3.9308e-02, -1.5845e-02, -5.1894e-03, -1.8193e-01,\n",
      "        -1.0003e-01, -3.4393e-04, -5.5484e-03, -3.2396e-02, -8.3282e-02,\n",
      "        -4.0002e-02, -8.5788e-03, -9.3245e-03,  7.2407e-03, -1.2025e-02,\n",
      "        -1.9380e-02,  5.6746e-03,  1.0983e-02,  7.5599e-02, -5.0994e-02,\n",
      "        -2.5518e-02, -1.2547e-01, -8.4851e-02,  2.1724e-02, -1.2054e-02,\n",
      "        -4.9764e-02,  2.6792e-01, -4.6584e-02, -7.0650e-02, -1.0957e-02,\n",
      "        -6.2037e-02, -3.9381e-02, -3.3845e-02, -1.1210e-01, -6.3136e-02,\n",
      "        -7.0422e-02, -4.6300e-02,  1.2256e-02, -3.6279e-02,  3.3204e-02,\n",
      "         5.1644e-03,  5.0901e-03, -3.0334e-02, -7.9859e-02, -5.4791e-02,\n",
      "        -6.5934e-02, -3.5114e-02,  1.0987e-01, -8.3633e-03, -6.3777e-02,\n",
      "         4.3975e-02, -9.6053e-03, -2.1843e-02,  6.5172e-02, -4.4285e-02,\n",
      "        -8.9869e-02, -2.1756e-02, -8.1204e-02, -8.1096e-02, -7.9948e-03,\n",
      "        -6.7762e-03, -1.5982e-01, -1.0197e-02,  3.0636e-01, -2.9919e-02,\n",
      "        -2.7793e-02, -3.1374e-02, -5.4275e-02, -2.9579e-02, -2.5534e-02,\n",
      "        -5.3335e-02, -8.4534e-02, -6.0735e-02, -1.4872e-01, -1.7734e-01,\n",
      "        -1.2741e-01,  3.6952e-02,  9.1101e-03, -3.8113e-02, -1.1237e-01,\n",
      "         3.6389e-02, -8.8899e-02,  1.8833e-03,  5.4260e-03,  7.2291e-02,\n",
      "        -1.5393e-02, -5.1824e-02, -3.3237e-02, -5.0209e-02,  6.8716e-03,\n",
      "        -4.8676e-02, -8.8756e-02,  4.6612e-02,  1.8844e-02,  1.7585e-02,\n",
      "        -5.0383e-02, -1.2599e-02, -4.7820e-02, -1.8663e-01, -5.1702e-02,\n",
      "        -1.4921e-01, -9.6335e-03,  1.2103e-02,  3.0685e-02,  3.0352e-02,\n",
      "        -2.1195e-02, -2.4711e-03, -9.0981e-02,  1.1983e-02,  3.5333e-02,\n",
      "        -6.9706e-02,  1.5925e-02, -6.3060e-02, -6.2432e-02, -9.4320e-02,\n",
      "        -1.7329e-02, -4.5060e-02,  7.1435e-02, -1.0655e-02, -7.4438e-02,\n",
      "         6.6502e-02,  4.1318e-02,  2.0621e-02, -5.1678e-03, -1.1876e-01,\n",
      "        -3.4770e-02, -1.6749e-02,  6.1672e-03, -5.1676e-02, -5.3567e-02,\n",
      "         1.2554e-05, -2.8438e-02, -4.2415e-02, -6.5369e-02, -9.1313e-02,\n",
      "         1.4895e-01,  5.7033e-02,  2.4034e-02, -5.5296e-02, -9.1598e-02,\n",
      "        -9.9122e-02,  9.4740e-03, -1.2651e-04,  1.4616e-02, -7.7334e-02,\n",
      "        -4.1774e-02,  1.0062e-01,  7.2942e-02, -5.5272e-02, -1.0987e-01,\n",
      "        -1.3215e-01, -2.2844e-02, -5.0691e-02, -5.9310e-02, -2.5046e-02,\n",
      "        -1.8706e-02, -1.2242e-01,  1.8694e-03, -5.3649e-02,  2.8097e-02,\n",
      "        -1.6853e-02,  9.6950e-03, -8.9545e-02,  6.1089e-02, -5.9101e-02,\n",
      "         2.0775e-02,  1.7811e-02,  2.4559e-05, -3.5435e-02, -2.1790e-02,\n",
      "        -5.1729e-02, -2.8350e-02,  2.7353e-02,  3.2815e-02, -4.7801e-02,\n",
      "        -4.5665e-02, -3.0335e-02,  7.1102e-02, -2.3421e-02, -2.4585e-02,\n",
      "        -3.8568e-02,  4.8141e-02, -5.6275e-02, -9.0299e-02, -8.9027e-02,\n",
      "         8.1501e-02,  3.8192e-02, -5.2298e-02,  1.0761e-02, -1.3175e-01,\n",
      "        -1.2143e-01, -4.1844e-02,  2.8340e-02, -3.9659e-02, -5.4983e-02,\n",
      "        -2.1362e-03,  1.7008e-02,  6.0489e-03,  7.9683e-02,  6.7162e-02,\n",
      "         9.3820e-04, -8.2810e-02, -4.3401e-02,  2.9462e-03,  1.5532e-01,\n",
      "         6.5555e-03, -1.7711e-02,  4.8494e-02, -4.4949e-03, -5.9552e-02,\n",
      "        -4.2894e-02, -6.8025e-02,  2.4817e-02, -1.1210e-01,  1.1861e-01,\n",
      "         3.1344e-02, -6.8008e-02,  1.2910e-02, -1.0509e-01,  4.4614e-02,\n",
      "         4.2147e-01,  1.6330e-02,  8.0202e-03, -1.2491e-01, -1.3559e-01,\n",
      "         3.1113e-02, -6.3279e-01,  6.8115e-02,  3.6168e-02,  1.7875e-02,\n",
      "        -8.1228e-02, -6.2449e-02,  3.2123e-02, -7.8249e-02, -9.3366e-02,\n",
      "         1.3892e-02, -2.1611e-02, -4.2074e-02, -6.4484e-02, -6.7390e-02,\n",
      "         2.1605e-02, -7.0341e-02, -3.1387e-02,  6.3311e-03,  1.1214e-02,\n",
      "        -5.0530e-02,  3.0926e-02,  5.0763e-02,  1.8203e-02, -6.5921e-02,\n",
      "        -8.7810e-03,  7.1257e-02,  4.4433e-02, -3.3470e-02, -2.7934e-02,\n",
      "        -1.3825e-01,  4.8040e-01,  3.1286e-02, -1.0295e-01,  2.2391e-02,\n",
      "        -4.2006e-02, -6.0025e-02, -2.2851e-02, -5.5924e-02, -5.6203e-02,\n",
      "        -1.9982e-02, -2.1840e-02, -2.8656e-02, -5.4728e-02, -7.8870e-02,\n",
      "        -4.9127e-02,  6.8188e-03,  3.3024e-02, -6.6694e-02,  4.2575e-02,\n",
      "        -6.7785e-02, -9.6941e-02, -2.1352e-02,  1.2755e-02, -8.3566e-02,\n",
      "        -1.6348e-02,  5.0766e-02, -2.7858e-02, -5.6821e-02,  1.1644e-02,\n",
      "        -1.3513e-01,  4.3935e-02,  5.4233e-02,  1.1033e-01,  5.3408e-02,\n",
      "        -6.9473e-02,  5.8710e-02,  9.8714e-02, -3.4468e-02, -5.9605e-02,\n",
      "         3.7019e-02,  5.7318e-03,  6.5052e-02, -1.7053e-02, -7.5478e-02,\n",
      "        -1.6166e-02,  1.8315e-02,  2.1609e-02, -6.8240e-02, -3.1293e-02,\n",
      "         9.0833e-03, -8.1078e-02,  3.9054e-02, -2.6686e-02,  2.6615e-02,\n",
      "         3.0577e-02,  1.8515e-02,  3.2200e-02,  4.5368e-02, -1.1967e+00,\n",
      "         4.1958e-02, -6.5099e-02,  2.1903e-02, -2.9189e-02, -1.4306e-02,\n",
      "        -3.8941e-02, -1.1132e-02, -7.8461e-02, -1.8412e-01, -3.6884e-01,\n",
      "        -1.1931e-01, -7.6967e-04, -3.2537e-02,  1.6576e-02,  4.5781e-02,\n",
      "        -9.1758e-02, -6.2901e-02, -5.1317e-02, -4.6586e-03,  1.2417e-01,\n",
      "         3.7494e-02,  9.6095e-03, -1.5207e-01,  1.9810e-02,  2.3642e-01,\n",
      "        -5.5954e-02,  1.0302e-01,  9.2853e-02, -7.2965e-02, -1.1074e-01,\n",
      "        -9.5064e-02, -5.1718e-02, -5.9940e-02, -3.4892e-02, -9.4589e-02,\n",
      "        -2.5599e-02,  3.8062e-02,  7.3381e-02, -3.2211e-02, -6.3919e-02,\n",
      "        -1.9516e-02, -5.8133e-02, -7.5650e-02,  3.5600e-02,  3.8519e-02,\n",
      "         5.2089e-02, -2.2283e-02, -1.0407e-01,  5.8947e-02, -5.8199e-03,\n",
      "         2.8756e-02, -1.5350e-03, -2.8560e-02, -1.0930e-02,  4.2543e-03,\n",
      "        -1.3260e-02,  1.2006e-02, -4.6029e-02, -3.5495e-02,  1.9008e-02,\n",
      "         1.3497e-03, -1.6296e-02, -1.7104e-03,  1.8720e-02, -1.5387e-01,\n",
      "        -1.3008e-01,  5.7722e-02])\n",
      "trainable parameters: bert.encoder.layer.0.attention.self.query.weight tensor([[ 0.0230,  0.0121,  0.0046,  ...,  0.0184,  0.0145, -0.0003],\n",
      "        [-0.0261, -0.0170, -0.0003,  ...,  0.0394,  0.0072, -0.0154],\n",
      "        [ 0.0217, -0.0019, -0.0392,  ...,  0.0578,  0.0270,  0.0082],\n",
      "        ...,\n",
      "        [ 0.0147, -0.0233, -0.0298,  ..., -0.0502, -0.0093, -0.0407],\n",
      "        [ 0.0066, -0.0423, -0.0063,  ..., -0.0530,  0.1126, -0.0212],\n",
      "        [ 0.0545,  0.0115,  0.0502,  ...,  0.0809,  0.0293,  0.0284]])\n",
      "trainable parameters: bert.encoder.layer.0.attention.self.query.bias tensor([-1.6933e-01,  8.9006e-02, -4.9604e-01, -2.0936e-01,  4.1094e-01,\n",
      "         2.6905e-01, -1.6684e-02, -2.3718e-01,  3.7331e-02, -1.2162e-01,\n",
      "        -9.0775e-02, -2.4751e-01,  2.6336e-03, -1.0602e-01, -9.2359e-02,\n",
      "        -1.7045e-01, -9.3205e-02,  5.3410e-01, -3.1275e-01,  2.6807e-01,\n",
      "        -1.0452e-01, -1.0590e-01,  2.4789e-01, -2.8186e-01, -9.4146e-02,\n",
      "         2.4216e-02,  2.0869e-01, -2.1260e-01, -1.5701e-01,  6.9978e-02,\n",
      "        -2.9586e-01, -2.7654e-01, -5.9033e-02, -2.5648e-01,  2.9604e-01,\n",
      "         9.9537e-02, -8.8383e-02,  1.1198e-02,  4.7875e-01, -2.2201e-02,\n",
      "        -5.1350e-01,  3.6990e-01, -2.2698e-01,  2.9177e-01,  5.3782e-01,\n",
      "        -3.6513e-01, -8.2247e-04, -9.5650e-02,  3.4088e-01,  2.1879e-01,\n",
      "         1.3851e-04, -2.3732e-01, -1.8268e-01, -1.3252e-01,  3.7451e-01,\n",
      "         2.8396e-01, -1.8898e-02,  9.0960e-02, -1.9585e-01,  1.9241e-01,\n",
      "         2.8958e-01,  2.3072e-01, -7.1103e-02, -9.2184e-02, -3.4290e-01,\n",
      "         4.4845e-01, -8.3871e-02,  1.2754e-01,  6.5569e-02,  1.3911e-01,\n",
      "         1.1861e-01, -4.4048e-01, -2.0176e-01, -3.1422e-01,  1.6586e-01,\n",
      "         1.1943e-01, -2.3469e-01,  5.4162e-01,  4.9294e-01,  1.8193e-01,\n",
      "        -7.6671e-02,  2.0324e-01,  5.1218e-01,  6.1902e-02, -1.2107e-01,\n",
      "         5.1480e-01,  7.2448e-02, -7.1883e-02,  1.6355e-01, -1.0289e-01,\n",
      "         7.0453e-01, -1.7373e-01,  3.1112e-01,  2.5909e-01, -2.6008e-01,\n",
      "         1.6158e-01,  2.5238e-01,  1.5542e-01,  5.3734e-01,  3.1363e-01,\n",
      "         7.7012e-03,  4.7833e-02, -4.7841e-01, -1.3652e-01,  1.5396e-01,\n",
      "        -2.1200e-01, -2.5695e-01, -1.2230e-01, -1.2063e-01,  1.2180e-01,\n",
      "         3.6387e-01,  8.2250e-02, -5.0468e-01, -1.7466e-01, -3.2944e-02,\n",
      "         5.0837e-02,  1.4137e-01,  3.1729e-01, -2.9563e-01, -1.1485e-02,\n",
      "         2.2250e-01,  1.3780e-01,  4.3152e-02, -4.0497e-01,  2.8089e-01,\n",
      "        -1.6593e-02, -7.1085e-02,  2.3639e-01, -1.6636e-01,  3.1891e-01,\n",
      "         3.3011e-01, -5.2379e-03,  2.2199e-02,  1.2825e-01,  1.4573e-01,\n",
      "         8.4687e-02, -8.7092e-02,  2.1087e-01,  1.8292e-01, -3.3802e-01,\n",
      "         1.4704e-01, -5.5180e-02, -4.7735e-01,  1.0251e-01, -4.9789e-02,\n",
      "        -9.5893e-02, -2.0784e-01, -3.9305e-02, -1.8045e-02, -3.0336e-01,\n",
      "        -2.1960e-01,  3.0566e-02, -2.5635e-01, -1.0204e-01,  2.9617e-01,\n",
      "         6.2898e-03, -2.7154e-01, -4.3694e-02, -7.0097e-03, -1.4812e-01,\n",
      "         5.3207e-02,  8.7672e-02,  2.1147e-01,  2.4217e-01, -2.2603e-01,\n",
      "        -1.4657e-01, -5.5025e-02,  1.0542e-01,  1.1444e-01,  3.3070e-01,\n",
      "         2.1512e-01,  1.4788e-01, -9.2510e-02,  4.8238e-01, -1.2334e-01,\n",
      "        -4.0225e-01,  2.0798e-01, -2.7149e-02, -7.4189e-02, -1.4373e-01,\n",
      "        -3.7752e-03,  2.4453e-01,  1.0803e-01,  3.3438e-02, -1.4184e-01,\n",
      "         5.1278e-02,  6.0257e-02,  5.8629e-02,  4.0558e-01,  9.1997e-02,\n",
      "         4.3973e-01, -2.1796e-01, -3.1555e-01, -1.7863e-01,  1.2845e-01,\n",
      "        -1.3185e-01,  2.7748e-01,  3.3719e-03,  2.8363e-01, -1.0706e-01,\n",
      "         1.8683e-01,  3.9582e-01, -1.6565e-01,  4.8738e-01,  1.1937e-01,\n",
      "         1.0120e-01, -2.9895e-01,  1.6352e-01,  4.6982e-02, -2.7053e-01,\n",
      "        -4.3776e-01,  1.2998e-02,  6.5742e-02, -2.7153e-02, -1.4316e-01,\n",
      "        -1.7862e-01,  1.5056e-01,  4.3675e-01, -4.1144e-01, -2.5343e-01,\n",
      "         5.4993e-01, -6.0246e-01, -3.9272e-02,  6.2444e-01, -5.7146e-01,\n",
      "        -4.6260e-01, -9.4312e-02,  3.4282e-01, -1.3154e-01, -6.9298e-02,\n",
      "        -1.4884e-03,  1.2475e-01,  1.1370e-01, -7.1036e-01, -3.9423e-01,\n",
      "        -6.4763e-02,  1.5763e-01,  2.6624e-03, -1.3973e-01,  4.2417e-01,\n",
      "        -3.5006e-01,  1.2569e-01, -4.7700e-01, -3.6232e-02,  3.3385e-03,\n",
      "         1.2540e-01, -3.7149e-01, -4.9189e-01, -3.7827e-01,  3.3987e-01,\n",
      "        -3.3025e-01,  2.4615e-01,  5.8056e-01,  1.1565e-01, -3.2660e-01,\n",
      "         5.8365e-01,  2.3400e-02, -1.1588e-01,  7.0129e-02,  2.4361e-01,\n",
      "         1.2491e-01, -2.7997e-01, -1.9998e-01, -1.7968e-01,  2.3230e-01,\n",
      "         2.3272e-02,  8.2269e-02, -1.9610e-01, -3.8369e-01, -2.2745e-01,\n",
      "        -1.7903e-02,  6.1207e-02,  3.8003e-02,  3.2529e-01,  1.5732e-01,\n",
      "         2.1450e-03,  9.2829e-02, -1.7873e-01, -1.7901e-01, -3.6894e-01,\n",
      "         2.1775e-01, -4.3290e-01,  8.3605e-02,  1.9322e-01,  6.9987e-02,\n",
      "        -9.3836e-02, -3.3886e-02, -2.3277e-01, -2.0711e-01,  1.8510e-01,\n",
      "        -9.6587e-02, -7.2226e-02, -2.7750e-02, -2.4081e-01, -2.1880e-01,\n",
      "        -1.2558e-01, -1.8266e-01,  1.1249e-01, -2.8947e-01,  9.2275e-02,\n",
      "         2.1610e-01, -3.2807e-02, -8.6888e-02, -1.6960e-01, -2.0499e-01,\n",
      "        -1.2218e-01, -1.6911e-01,  1.8260e-01, -1.4936e-02, -1.9741e-01,\n",
      "         1.8945e-01, -1.3898e-01, -2.2775e-01, -8.3099e-03, -1.0006e-01,\n",
      "         6.9353e-02, -2.1829e-01, -1.5250e-01,  7.0505e-02, -1.2583e-01,\n",
      "        -7.7359e-02, -1.1214e-01,  1.0447e-01,  1.1055e-01,  7.4525e-02,\n",
      "        -1.5437e-01,  5.5249e-02,  4.5825e-01, -1.6811e-01, -1.9214e-01,\n",
      "         2.0664e-01, -1.2792e-01,  3.0334e-01, -4.6689e-02,  6.7952e-02,\n",
      "         5.8499e-02, -1.2233e-02, -3.0664e-01, -1.6882e-01,  1.1755e-01,\n",
      "         2.1509e-01,  3.1587e-02, -3.1931e-02, -8.3802e-02,  3.5662e-01,\n",
      "        -1.3782e-02, -2.8935e-01, -2.3118e-01,  1.0809e-01, -1.2342e-01,\n",
      "        -1.7877e-01, -1.5930e-01,  1.7529e-02, -1.4859e-02, -8.3643e-02,\n",
      "        -9.7481e-02, -2.6924e-01, -3.9065e-01,  8.2877e-03,  1.0706e-02,\n",
      "         4.7061e-02, -1.2570e-01,  1.8162e-01, -2.0579e-02,  4.1147e-02,\n",
      "        -9.1429e-02,  2.1477e-01, -4.8779e-02,  4.8817e-01, -3.3283e-03,\n",
      "        -9.1260e-02,  7.1171e-02,  1.4709e-01, -3.3393e-02,  5.3103e-02,\n",
      "        -2.9920e-01, -1.9387e-01, -1.8317e-01,  1.9187e-01, -3.1561e-02,\n",
      "         1.0694e-01, -2.5241e-01,  2.3572e-01, -8.9739e-02, -5.7522e-01,\n",
      "        -4.1754e-01, -7.6157e-01, -1.0469e+00,  4.6815e-01, -7.7262e-02,\n",
      "         5.4200e-01, -1.3244e-01, -2.0940e-01,  1.2628e-01, -8.0613e-01,\n",
      "         5.8859e-01, -3.3428e-01,  4.5012e-01, -3.0365e-01,  2.3146e-01,\n",
      "         3.2999e-01,  6.7370e-01,  3.4220e-01,  2.6293e-01,  4.6840e-01,\n",
      "        -1.7206e-01,  5.2678e-01, -4.2941e-01,  3.6885e-01,  1.0919e-01,\n",
      "         8.6175e-01, -4.8775e-01, -9.9875e-01,  1.4800e-02,  5.3218e-01,\n",
      "        -3.6917e-01, -4.3797e-01, -9.5630e-01,  5.9976e-01,  4.0395e-01,\n",
      "         7.5532e-01,  3.6756e-01,  7.6799e-02,  2.6854e-01,  5.4441e-01,\n",
      "         3.0764e-01,  4.5341e-01,  3.2464e-01,  7.3691e-02, -1.0824e-01,\n",
      "        -4.4202e-01,  3.6687e-01,  3.3949e-01,  6.2416e-01,  9.2010e-01,\n",
      "         5.6695e-01,  1.9931e-01, -2.2939e-01, -7.0753e-01, -5.6164e-02,\n",
      "         9.0578e-03,  3.2020e-01,  3.8324e-01,  3.9488e-02, -2.9725e-01,\n",
      "        -2.9818e-01,  7.1385e-01, -1.1301e-01, -1.0997e-01, -7.8262e-02,\n",
      "         4.8358e-02, -3.5358e-02, -4.9831e-02, -8.5256e-02,  4.3528e-01,\n",
      "         1.6916e-01, -1.1744e-01,  1.4026e-01, -1.0170e-01,  2.6589e-02,\n",
      "        -3.8847e-02,  1.1787e-01,  2.3542e-01, -2.6051e-01, -1.1186e-01,\n",
      "        -1.8835e-01,  7.9394e-02,  9.8102e-02, -1.3427e-01, -1.1482e-01,\n",
      "         1.8718e-01,  1.9421e-02, -1.3829e-01,  4.3205e-01,  3.5610e-02,\n",
      "         2.3517e-01,  4.1469e-02,  2.5552e-01,  3.2519e-01, -6.4077e-02,\n",
      "         2.2367e-01,  1.7411e-01, -2.6403e-01, -2.3555e-01, -2.6319e-02,\n",
      "        -3.0182e-01, -2.7465e-01, -3.7852e-02,  1.3710e-01, -1.1306e-01,\n",
      "         4.6749e-01, -6.1143e-02, -1.2273e-01, -2.5370e-01, -1.8995e-01,\n",
      "         2.7751e-02,  9.3374e-02,  8.6454e-02,  4.6625e-01,  7.7482e-02,\n",
      "         2.5095e-01, -4.5469e-02,  2.2037e-01, -1.2070e-01, -1.9021e-02,\n",
      "         5.3879e-02,  1.4295e-01, -2.3238e-01, -2.6831e-01, -1.3519e-01,\n",
      "        -2.4956e-01, -8.8014e-02])\n",
      "trainable parameters: bert.encoder.layer.0.attention.self.key.weight tensor([[-0.0382, -0.0680, -0.0677,  ..., -0.0162,  0.0007,  0.0247],\n",
      "        [-0.0220,  0.0537, -0.0172,  ..., -0.0174,  0.0100, -0.0196],\n",
      "        [ 0.0330, -0.0219,  0.0213,  ..., -0.0149,  0.0494, -0.0334],\n",
      "        ...,\n",
      "        [-0.0350, -0.0542,  0.0609,  ..., -0.0085, -0.0086, -0.0377],\n",
      "        [ 0.0738,  0.0538, -0.0081,  ..., -0.0231, -0.0236, -0.0209],\n",
      "        [-0.0751,  0.0571,  0.0001,  ..., -0.0696,  0.0105, -0.0648]])\n",
      "trainable parameters: bert.encoder.layer.0.attention.self.key.bias tensor([ 2.5954e-02, -1.5505e-02, -3.1803e-02,  1.4301e-02,  8.9960e-03,\n",
      "         4.0196e-02,  1.0242e-02, -2.1582e-02, -2.8775e-02,  3.1651e-03,\n",
      "        -1.0712e-02,  1.3570e-02,  1.7186e-02, -4.6719e-03,  5.7447e-03,\n",
      "         2.2994e-02,  1.3016e-02,  2.9177e-02,  5.3743e-03,  1.7928e-03,\n",
      "        -1.2118e-02,  7.5808e-03,  2.1738e-02,  1.7793e-02, -1.4030e-02,\n",
      "         2.5700e-02,  1.4638e-03,  1.0416e-03, -3.6505e-02,  3.9761e-03,\n",
      "        -6.2257e-02, -3.0033e-02,  4.8822e-03, -1.5685e-02, -1.6718e-02,\n",
      "        -3.1217e-02,  2.6885e-02,  6.2278e-03, -1.7048e-02, -3.8705e-02,\n",
      "         1.5701e-05, -1.8577e-02,  1.3718e-02, -1.0645e-02, -1.3064e-02,\n",
      "         4.0183e-02, -5.3212e-02, -4.5218e-02, -6.1777e-03,  4.4089e-03,\n",
      "        -6.0919e-02, -4.6112e-02, -2.3733e-03,  8.3712e-03,  1.9650e-02,\n",
      "        -3.7695e-02, -6.4349e-03, -1.0794e-02, -5.7684e-03, -4.5816e-03,\n",
      "        -2.3461e-02, -4.1871e-03,  1.1892e-03,  1.7242e-02, -4.5906e-03,\n",
      "         1.0162e-02,  6.8980e-02,  2.9520e-02,  8.6350e-03,  4.0812e-02,\n",
      "         1.2800e-02,  4.4305e-03,  1.7657e-02, -3.8631e-02, -4.9408e-03,\n",
      "        -9.3107e-03,  2.5461e-03,  3.6694e-02, -3.2375e-03, -5.0727e-02,\n",
      "         3.2659e-02, -4.5165e-02,  8.6002e-03,  1.4012e-02, -2.5666e-02,\n",
      "         3.4989e-02,  4.3784e-02, -4.2929e-02, -1.6706e-02,  1.1049e-02,\n",
      "         9.9168e-03,  3.1387e-02,  2.0984e-03, -5.6742e-03,  2.3150e-03,\n",
      "        -2.8091e-02, -3.3156e-02, -4.6522e-03, -5.4099e-02, -1.3472e-02,\n",
      "         2.3562e-02, -5.3341e-02,  2.1365e-02, -4.1322e-02, -1.6595e-02,\n",
      "        -1.0355e-02, -5.2200e-02, -2.0761e-03, -3.9469e-02,  1.5694e-02,\n",
      "         2.6688e-02, -1.6718e-02, -3.3594e-02,  4.6667e-02,  4.4625e-02,\n",
      "        -4.8703e-02, -7.3904e-04,  1.1155e-02,  4.1614e-02, -2.3442e-02,\n",
      "        -2.6368e-02, -6.3190e-03,  1.0797e-02,  4.1401e-03, -7.5338e-02,\n",
      "         2.5161e-02,  4.3735e-03,  1.8686e-02,  7.0254e-02,  1.0133e-02,\n",
      "        -2.7822e-02,  7.0392e-03, -8.8080e-04, -1.1083e-02,  3.0590e-02,\n",
      "        -3.6633e-02, -2.9233e-02, -5.2544e-03, -1.7500e-02, -1.7096e-03,\n",
      "         1.0455e-02, -3.5470e-02, -6.0722e-03,  2.0390e-03, -9.1880e-03,\n",
      "        -1.8820e-02, -7.7810e-03, -6.0609e-03, -2.6345e-02,  1.1440e-02,\n",
      "         8.4864e-03,  1.7331e-02, -2.9346e-02,  1.4779e-02, -1.1232e-02,\n",
      "         1.2843e-02,  1.4041e-02, -2.7785e-02, -2.7132e-02,  7.6276e-03,\n",
      "        -8.2773e-03,  1.8383e-02,  1.7684e-02,  2.4321e-02,  2.2023e-02,\n",
      "        -2.7909e-03, -3.5927e-02,  1.5104e-02, -1.8416e-02,  1.1419e-02,\n",
      "        -4.1476e-02,  3.2916e-04, -7.0774e-03, -5.3998e-02,  3.0888e-02,\n",
      "         5.6157e-03, -2.9666e-02,  2.3414e-02,  1.2558e-02,  6.7324e-03,\n",
      "         1.4967e-02, -5.7187e-02,  3.1081e-02, -1.0015e-02, -1.9099e-02,\n",
      "        -1.4226e-02,  1.4073e-02, -4.2979e-02, -6.3846e-02,  3.1249e-02,\n",
      "         9.5964e-03,  2.0573e-02, -4.9684e-02,  1.7607e-02,  6.7054e-02,\n",
      "        -2.6672e-02, -6.9095e-02, -1.8959e-02, -4.9754e-02, -3.1605e-03,\n",
      "        -6.7919e-03, -2.3173e-02,  1.2065e-02,  2.3569e-02, -4.2838e-02,\n",
      "         4.6952e-02,  2.1638e-02,  2.0158e-02, -7.9454e-03,  2.7629e-02,\n",
      "        -5.1309e-04, -2.7201e-02,  1.4258e-02,  4.6736e-03, -3.5780e-02,\n",
      "        -3.5514e-03,  8.8688e-03, -3.5861e-02, -3.1089e-02, -3.2468e-02,\n",
      "        -2.5113e-02, -2.9177e-02,  1.0235e-02,  2.4796e-02, -6.5527e-02,\n",
      "        -8.7981e-02, -1.6396e-02,  6.5084e-02, -4.7018e-02,  2.9794e-02,\n",
      "         3.5627e-02,  5.6038e-03, -1.5808e-03,  1.1213e-02,  3.2827e-03,\n",
      "        -4.1496e-02, -6.0127e-02, -1.8360e-02,  5.7716e-02,  4.2615e-02,\n",
      "        -1.6808e-02,  4.1826e-02, -7.0470e-03,  5.8446e-03, -2.0418e-02,\n",
      "         3.4613e-02, -2.4900e-02,  9.6890e-03, -3.5477e-02,  5.3131e-03,\n",
      "         6.4505e-02, -1.3172e-02, -1.9276e-03, -1.2039e-02, -2.1333e-03,\n",
      "         1.8123e-02,  6.7896e-02, -1.3493e-02,  4.2852e-03,  2.7503e-02,\n",
      "         5.2203e-02, -4.9879e-02,  5.4400e-02,  5.0763e-02, -4.0113e-02,\n",
      "        -2.1134e-02, -3.5179e-02,  1.3824e-02, -2.5944e-02,  5.2112e-02,\n",
      "        -1.6391e-02, -1.8320e-03, -8.7291e-03,  1.2242e-02,  2.2128e-03,\n",
      "         1.3013e-02,  8.8323e-03,  3.5695e-02,  8.0471e-03, -2.0855e-03,\n",
      "         2.0166e-02,  7.5702e-03, -1.9059e-02,  2.6132e-02, -3.5766e-02,\n",
      "         1.6787e-02, -2.0818e-02,  1.6496e-02,  2.4854e-02, -2.5298e-02,\n",
      "         7.9676e-03, -4.1774e-02,  7.6365e-03, -2.4096e-02, -2.1690e-03,\n",
      "         1.2948e-02, -1.2096e-02, -2.2629e-02, -2.8705e-02, -3.8855e-02,\n",
      "         5.6952e-02, -3.2157e-03,  4.2761e-02, -1.7997e-02,  8.9505e-03,\n",
      "         2.9624e-03,  3.7954e-02, -3.5293e-02,  7.0791e-03,  1.9369e-02,\n",
      "         8.3599e-02, -1.4178e-02,  3.8908e-02,  8.1354e-03,  2.7931e-02,\n",
      "        -6.1829e-02,  6.9221e-03,  6.2706e-03,  4.8488e-02, -4.0292e-02,\n",
      "        -1.0324e-02,  8.1872e-03, -1.0715e-02, -3.0483e-02, -2.3080e-02,\n",
      "         1.0937e-02,  4.3968e-03, -1.7529e-02,  1.2523e-02, -4.0425e-02,\n",
      "         4.9178e-03,  2.9599e-04, -1.6416e-02,  6.3922e-03,  3.9216e-03,\n",
      "        -9.3955e-03, -1.2697e-03,  1.3848e-02,  5.5548e-03, -2.3169e-02,\n",
      "         4.4438e-02, -3.7171e-02, -1.0854e-02, -3.7521e-03,  2.4710e-02,\n",
      "        -1.2998e-02, -8.5659e-04, -1.9894e-03,  1.7251e-02, -1.3134e-04,\n",
      "         2.2886e-04,  1.6053e-02, -2.4008e-02,  3.4653e-02,  2.4197e-02,\n",
      "         3.4488e-02,  4.3198e-03, -2.3438e-03,  2.6041e-02,  5.0856e-04,\n",
      "         6.9928e-03, -1.5935e-03, -3.4169e-03,  4.9433e-03,  4.1909e-03,\n",
      "         1.7588e-02,  4.1691e-03,  3.6921e-02,  4.9744e-03,  7.2669e-05,\n",
      "        -1.7540e-03,  7.1708e-03,  1.5987e-02,  1.1760e-02,  6.6922e-04,\n",
      "         8.6808e-03,  2.0905e-02,  2.9474e-03, -9.1137e-03,  4.2932e-03,\n",
      "         1.8937e-02,  6.4948e-03,  1.2336e-02, -1.1543e-02, -2.3313e-02,\n",
      "         4.7564e-02, -4.8759e-02, -2.8008e-03,  4.1267e-03,  2.2762e-04,\n",
      "         4.1408e-02,  4.3170e-02,  1.7593e-02,  2.2820e-02,  3.1833e-02,\n",
      "        -2.7070e-02,  1.4575e-02, -3.1919e-02,  2.5726e-02,  4.6078e-02,\n",
      "         4.4052e-03,  7.9034e-03, -6.8560e-03, -2.7359e-02,  7.1212e-03,\n",
      "        -2.0468e-02,  6.7030e-03, -1.0740e-02, -2.4647e-02, -2.9769e-02,\n",
      "         4.7024e-04, -2.1443e-03, -1.0185e-02,  5.3182e-03, -3.2920e-03,\n",
      "        -7.3521e-03,  1.4608e-03,  1.5637e-02,  2.7584e-02, -3.7405e-02,\n",
      "        -4.0278e-02, -1.0206e-02, -2.6968e-02, -1.0605e-02, -1.7959e-02,\n",
      "        -4.1662e-02,  9.6716e-03,  2.9459e-03,  1.8565e-02, -5.4100e-02,\n",
      "         2.8058e-02, -7.1320e-03, -1.4232e-03,  6.2780e-03,  2.2710e-02,\n",
      "         3.5083e-03,  3.5468e-02,  1.1180e-02,  1.3108e-02,  1.3321e-02,\n",
      "        -2.7922e-03, -2.2881e-02, -4.1806e-03, -1.3435e-02, -2.5339e-02,\n",
      "         6.2354e-02, -1.8841e-02, -6.1781e-03, -1.1035e-02, -2.5330e-02,\n",
      "        -9.0524e-04,  3.3810e-02,  2.6732e-02, -2.4793e-02,  4.5994e-02,\n",
      "         4.6284e-03, -3.4182e-03, -1.4814e-02, -2.0692e-02, -1.9275e-02,\n",
      "        -2.1788e-02, -2.9049e-02,  1.4747e-02,  1.7728e-02, -2.2861e-02,\n",
      "         1.7311e-02,  4.5705e-02,  4.7079e-04, -7.4692e-03,  2.0765e-02,\n",
      "         2.4263e-02,  2.5585e-02,  3.9226e-02,  3.0518e-02, -2.1942e-03,\n",
      "         5.7495e-03, -1.8559e-02,  4.0140e-02,  6.5238e-03,  2.1692e-02,\n",
      "        -9.9386e-03, -1.8434e-03,  3.2284e-02, -2.4398e-02, -3.4118e-02,\n",
      "        -8.8781e-03, -5.3312e-02,  1.0913e-02,  3.2435e-02,  1.7428e-02,\n",
      "         2.7909e-02, -1.7488e-02, -1.9765e-02,  4.0930e-03,  1.4911e-02,\n",
      "         1.3294e-02,  4.6750e-03,  1.9541e-02, -7.1180e-03,  5.1751e-03,\n",
      "         3.7772e-03, -3.5965e-02, -3.7131e-03,  1.4912e-02,  2.0613e-02,\n",
      "        -1.1246e-02, -2.5809e-02, -1.6148e-02, -2.9468e-03, -2.8755e-02,\n",
      "        -9.3062e-03, -2.7857e-03])\n",
      "trainable parameters: bert.encoder.layer.0.attention.self.value.weight tensor([[ 0.0355,  0.0644,  0.0555,  ..., -0.0328,  0.0173, -0.0132],\n",
      "        [ 0.0108,  0.0023, -0.0892,  ..., -0.0329,  0.0548,  0.0183],\n",
      "        [ 0.0043,  0.0384,  0.0433,  ..., -0.0671,  0.0118, -0.0066],\n",
      "        ...,\n",
      "        [-0.0196,  0.0179, -0.0238,  ..., -0.0101, -0.0084,  0.0402],\n",
      "        [-0.0134,  0.0614, -0.0104,  ..., -0.0592, -0.0159, -0.0019],\n",
      "        [-0.0286,  0.0286,  0.0429,  ..., -0.0293,  0.0387,  0.0151]])\n",
      "trainable parameters: bert.encoder.layer.0.attention.self.value.bias tensor([ 2.1432e-02,  1.2144e-01,  1.0548e-01,  5.4462e-02,  5.0101e-02,\n",
      "         2.8854e-02, -3.4198e-02,  8.3599e-03,  8.5209e-02,  7.8742e-02,\n",
      "        -9.7359e-03, -1.2004e-01,  6.0762e-02, -2.5852e-02,  5.4395e-02,\n",
      "         3.8327e-03, -9.1077e-02,  1.4884e-01,  8.6110e-02,  1.2953e-01,\n",
      "         1.5209e-02,  1.8557e-02, -9.2409e-02, -4.0663e-02,  2.8417e-02,\n",
      "         6.1241e-02, -7.9665e-02,  3.1599e-02,  2.2427e-02,  4.5534e-03,\n",
      "        -7.9700e-02, -4.4579e-02,  1.8957e-03,  4.3897e-02, -1.2819e-01,\n",
      "         4.9836e-03,  1.0010e-01,  1.0970e-01, -8.8721e-02,  3.0270e-02,\n",
      "         2.3783e-02,  4.0327e-03,  4.0315e-03, -2.9256e-02,  2.9919e-02,\n",
      "         1.0102e-01, -3.5792e-02, -1.0155e-01,  1.4838e-01, -8.5045e-02,\n",
      "        -1.1984e-01, -7.3750e-03, -1.0435e-01,  8.1557e-02,  1.2155e-01,\n",
      "         8.2566e-03, -1.8966e-02,  2.7510e-02,  7.6278e-02, -8.6778e-02,\n",
      "         4.6725e-02, -8.2810e-02, -9.9267e-03, -6.6920e-02,  4.8908e-02,\n",
      "         2.9372e-02, -9.0482e-02,  9.8640e-03, -9.1939e-02, -1.2368e-01,\n",
      "        -2.1343e-02, -6.1696e-02, -1.4558e-01, -6.7540e-02, -2.3731e-02,\n",
      "        -9.2783e-02,  8.8616e-02, -2.8636e-02,  3.1143e-02,  8.3283e-02,\n",
      "        -4.7748e-02, -1.9555e-01,  1.7486e-02, -6.1355e-02,  1.0441e-01,\n",
      "        -2.4254e-02, -8.0242e-02,  1.4439e-02,  6.6634e-02,  4.9578e-03,\n",
      "         1.8977e-02, -2.4509e-02,  7.2953e-02, -1.6059e-01,  2.5990e-02,\n",
      "        -9.9052e-03,  5.8777e-02,  1.9681e-02,  1.7911e-01, -3.3765e-02,\n",
      "         1.2096e-01,  4.8916e-02, -3.0881e-02,  1.3869e-02,  1.6860e-02,\n",
      "         1.7929e-01, -5.5530e-02,  4.2567e-04,  8.9294e-02,  1.2439e-02,\n",
      "        -1.2231e-01, -5.1044e-02, -2.3871e-02, -1.7526e-02,  5.5901e-02,\n",
      "        -4.8497e-02,  1.6856e-01, -1.3891e-02, -4.2731e-02, -1.6683e-02,\n",
      "         1.1183e-01, -4.2397e-03,  4.3843e-02, -4.9742e-02,  5.8694e-02,\n",
      "        -7.1107e-02, -5.7531e-02, -3.9422e-02, -3.1688e-02, -7.1623e-02,\n",
      "         3.4092e-02,  4.0518e-02, -8.5770e-02,  5.2499e-02, -1.0825e-02,\n",
      "        -1.2525e-02,  9.5827e-02,  8.6384e-02,  6.1961e-02, -7.9966e-02,\n",
      "        -5.0582e-02,  6.7226e-02,  5.6495e-02,  4.1257e-03,  5.9647e-02,\n",
      "        -2.7425e-02, -2.2680e-02,  3.0409e-02, -7.4019e-02, -6.8303e-02,\n",
      "         7.3876e-02,  3.9680e-03,  6.0130e-02, -8.4559e-03, -5.3026e-04,\n",
      "        -7.4020e-02, -9.6953e-03,  6.8704e-02, -2.5627e-02, -1.4358e-02,\n",
      "         2.1637e-02,  4.1602e-02, -2.9399e-02,  5.4213e-02,  4.7162e-02,\n",
      "        -1.8110e-02, -2.0980e-02, -2.0272e-02, -1.1620e-01, -8.3041e-03,\n",
      "         1.3268e-02, -1.0253e-01,  2.9183e-02, -6.5199e-02, -5.0689e-02,\n",
      "         6.4023e-02,  5.2845e-02,  1.1148e-01, -2.1182e-02,  1.1348e-01,\n",
      "        -1.9729e-02, -4.4331e-02, -1.2897e-02, -2.0788e-02,  6.8884e-02,\n",
      "         5.3199e-02,  2.9625e-02, -2.9459e-02,  4.2917e-02, -4.1380e-03,\n",
      "         1.1706e-02, -6.2324e-02, -9.1391e-02, -1.0612e-01,  1.0173e-02,\n",
      "        -1.0079e-01,  5.3355e-02,  1.6589e-02,  1.0085e-02, -4.1896e-02,\n",
      "        -3.8880e-02, -1.7009e-02, -4.3695e-02, -8.9939e-02,  3.1676e-02,\n",
      "        -1.5237e-01,  1.2098e-01,  1.4041e-01, -8.6873e-03, -1.6561e-01,\n",
      "        -1.2113e-01, -4.9293e-02, -1.5033e-01, -1.2518e-02,  9.3044e-02,\n",
      "        -1.3505e-01,  2.1686e-01,  2.5056e-01,  1.9226e-01, -1.9234e-01,\n",
      "        -7.2822e-02,  1.6635e-01,  7.4394e-02, -1.5785e-01, -1.5998e-02,\n",
      "        -9.6999e-02, -1.6405e-02, -1.3530e-01,  4.1454e-04, -1.5201e-01,\n",
      "         2.0428e-01, -2.1326e-01,  1.4338e-01, -2.0846e-01, -2.4621e-02,\n",
      "         1.5354e-01, -1.4297e-01, -2.0365e-01, -8.5880e-02, -1.7200e-01,\n",
      "         8.5588e-02,  2.0865e-01, -1.9558e-01,  6.1028e-02, -2.1613e-02,\n",
      "        -1.9550e-01,  1.1037e-01, -1.6703e-01,  7.4488e-02,  1.6094e-01,\n",
      "        -1.8819e-01, -1.2731e-01,  4.9715e-03, -1.6573e-01, -2.5532e-01,\n",
      "         2.8764e-01, -5.9079e-03,  6.7141e-02, -4.1669e-02, -1.4143e-01,\n",
      "         1.0593e-02,  4.8869e-02,  3.2582e-03,  1.0928e-01, -2.8220e-02,\n",
      "         1.2489e-02, -3.3323e-02,  7.2266e-03,  5.9159e-03,  1.3805e-02,\n",
      "        -6.9483e-02,  8.2835e-02,  1.8277e-01, -1.0432e-01,  5.0973e-02,\n",
      "        -4.0514e-02,  1.4590e-01,  3.4265e-03, -2.1174e-02,  3.7086e-02,\n",
      "        -3.8122e-03,  1.4714e-03, -6.6632e-03,  2.1093e-02,  4.7640e-03,\n",
      "        -5.9038e-03,  2.5442e-02,  2.2198e-02, -2.7069e-02, -4.9395e-02,\n",
      "         1.8202e-02,  2.5494e-02, -2.1536e-02, -2.6211e-02, -2.3742e-02,\n",
      "         1.1416e-02, -1.7161e-02,  8.6871e-02,  2.8010e-02, -7.3544e-03,\n",
      "         2.1696e-02,  2.0730e-02, -9.7069e-02, -1.1312e-02, -1.0014e-02,\n",
      "        -1.7980e-02,  1.0399e-01, -4.3617e-02,  1.9023e-02, -8.1355e-02,\n",
      "         8.8747e-02,  2.2664e-03,  5.2953e-02, -9.7674e-03,  1.1011e-02,\n",
      "        -6.5764e-02, -3.3302e-02, -1.5158e-03, -6.4857e-02,  1.2871e-02,\n",
      "        -1.0184e-02,  3.3031e-02, -1.2308e-02, -5.0110e-02,  4.6084e-02,\n",
      "         8.7410e-02,  4.7742e-02,  1.1995e-02, -7.4390e-03,  5.2192e-03,\n",
      "        -1.4091e-03,  3.5398e-02,  4.1369e-02,  1.1212e-01, -1.0311e-01,\n",
      "         7.2784e-02, -1.0837e-02,  3.1842e-02,  4.0121e-02, -7.3168e-02,\n",
      "        -3.3292e-02,  5.0265e-02,  4.6695e-02, -3.8451e-02, -1.3752e-02,\n",
      "         2.4086e-02,  3.7676e-02,  3.8367e-02, -4.4587e-02, -2.4129e-02,\n",
      "         2.2539e-02, -4.0589e-02,  7.2208e-02,  2.7689e-02,  8.5943e-02,\n",
      "         3.0191e-02,  5.0328e-02, -3.4370e-02,  1.1273e-03,  7.5363e-02,\n",
      "        -1.4171e-02, -2.3374e-02, -4.5653e-02, -2.9568e-02,  5.4801e-03,\n",
      "        -2.6586e-02, -6.9480e-02,  2.6079e-02,  2.5609e-02, -3.0863e-02,\n",
      "        -2.7638e-02, -9.6561e-02,  6.2489e-02, -3.2193e-02,  7.5695e-03,\n",
      "        -3.5127e-02,  9.1404e-03, -3.5020e-02, -5.7532e-03,  5.0025e-02,\n",
      "        -2.4835e-02, -4.8822e-02,  2.6949e-02, -4.9755e-02, -2.1683e-03,\n",
      "         3.1331e-01, -3.8523e-01, -2.4788e-01,  1.1909e-01, -2.9310e-01,\n",
      "        -2.2845e-01,  2.9713e-01,  3.5023e-01,  1.6343e-01,  2.9635e-01,\n",
      "        -1.6967e-02,  1.4941e-01,  4.0564e-02,  2.6120e-01, -6.5350e-02,\n",
      "        -1.4217e-01,  1.7541e-01,  6.4802e-03,  1.9266e-01, -8.9923e-02,\n",
      "        -6.2504e-03,  8.1560e-02,  1.8542e-01, -1.4996e-01,  1.1200e-01,\n",
      "        -7.0374e-02,  3.0272e-01, -4.9482e-02, -8.3694e-02, -1.0147e-01,\n",
      "         9.5823e-02, -1.1522e-01, -1.3452e-01,  3.6260e-01, -1.0324e-01,\n",
      "        -2.1766e-01, -7.3027e-02, -8.9461e-02,  1.7005e-01,  8.8273e-03,\n",
      "        -3.3122e-02, -3.3590e-02, -3.6162e-01,  9.3815e-02,  1.2683e-01,\n",
      "         2.2373e-01,  1.4990e-02, -1.0771e-01, -3.0602e-02,  1.4979e-01,\n",
      "         2.7145e-01,  7.6019e-03,  1.3816e-01,  1.2074e-01, -7.2910e-02,\n",
      "         3.3045e-01,  1.6545e-01, -6.3627e-03, -3.4410e-01, -4.5782e-02,\n",
      "         3.2574e-01,  1.6910e-02,  1.1762e-01,  4.2682e-02,  7.1575e-03,\n",
      "         2.3776e-02, -7.9071e-03,  2.9146e-03,  1.6712e-02, -4.0113e-02,\n",
      "        -1.0349e-02, -2.2861e-02, -6.5986e-02,  6.1129e-02,  1.7948e-02,\n",
      "        -1.1961e-02,  3.9689e-02,  7.8075e-02, -2.0442e-02,  9.9339e-03,\n",
      "         1.1353e-03, -9.6946e-04,  4.5397e-02, -1.7040e-02,  2.5632e-03,\n",
      "         8.8847e-02,  5.2879e-02,  3.1502e-03, -1.0468e-02, -3.0652e-02,\n",
      "         2.0658e-02, -1.9287e-02,  3.6399e-02,  4.3583e-03,  3.7125e-03,\n",
      "        -3.1109e-03,  3.9996e-03,  7.1040e-02,  1.4048e-02, -8.5586e-03,\n",
      "         2.5188e-03,  5.1351e-02,  4.5945e-02,  6.2694e-02, -7.2819e-02,\n",
      "        -2.2866e-02, -2.1463e-02, -2.5187e-02,  6.4525e-03, -2.0556e-02,\n",
      "        -2.4677e-02,  1.1186e-02,  9.5250e-03,  1.2078e-02, -2.0531e-04,\n",
      "         3.3977e-02,  5.2748e-02,  2.0331e-03,  8.0750e-03, -3.3353e-02,\n",
      "        -1.9574e-02,  5.5878e-02, -3.8050e-02, -8.2076e-02, -7.8753e-02,\n",
      "        -1.3913e-02,  2.0524e-02])\n",
      "trainable parameters: bert.encoder.layer.0.attention.output.dense.weight tensor([[ 0.0350, -0.0161, -0.0542,  ..., -0.0791, -0.0097, -0.0150],\n",
      "        [-0.0717,  0.0477,  0.0172,  ...,  0.0864,  0.0162,  0.0720],\n",
      "        [-0.0151,  0.0038,  0.0691,  ..., -0.0057,  0.0269,  0.0228],\n",
      "        ...,\n",
      "        [ 0.0169,  0.0582,  0.0550,  ...,  0.0016,  0.0017, -0.0436],\n",
      "        [-0.0456, -0.0136,  0.0292,  ..., -0.0153,  0.0088,  0.0467],\n",
      "        [-0.0361,  0.0279, -0.0301,  ...,  0.0274, -0.0052,  0.0307]])\n",
      "trainable parameters: bert.encoder.layer.0.attention.output.dense.bias tensor([-1.0675e-02, -3.3530e-02,  4.4628e-02,  5.9671e-02, -3.3624e-02,\n",
      "        -9.4947e-02,  1.2977e-02,  1.8110e-02,  2.8926e-02, -4.2131e-02,\n",
      "         1.0692e-02, -7.1722e-02, -1.2407e-01, -1.1857e-02,  1.1689e-01,\n",
      "        -1.8668e-03,  4.9227e-02, -1.9278e-02,  1.1161e-02,  1.6821e-03,\n",
      "        -1.1653e-01, -7.4728e-03,  1.1264e-02, -5.1552e-02,  5.5179e-02,\n",
      "         5.9609e-02, -2.5834e-02,  4.3821e-02,  5.4656e-02,  2.0405e-02,\n",
      "         1.1812e-01, -3.6845e-01,  4.1841e-02,  2.3812e-02, -2.9366e-02,\n",
      "         8.2810e-02, -1.2599e-01, -2.7206e-02, -7.4345e-02,  1.2841e-01,\n",
      "         1.3944e-02, -1.5751e-02,  1.7688e-02,  1.2094e-01,  2.8270e-02,\n",
      "        -5.5070e-02, -4.8276e-02, -1.4390e-01, -2.3260e-03, -5.9366e-02,\n",
      "         1.0529e-01,  1.8512e-02,  2.0138e-02,  7.7863e-02,  3.5016e-02,\n",
      "         3.6682e-02,  1.0324e-02,  1.9496e-02, -1.0250e-01, -2.5717e-02,\n",
      "         8.5348e-02,  4.1335e-02,  9.3892e-02,  1.3423e-02, -3.4107e-02,\n",
      "        -3.3500e-02, -3.7638e-04, -1.1864e-02,  1.4081e-02, -2.0026e-04,\n",
      "         3.8450e-02, -8.2590e-02,  5.3056e-02, -1.2103e-01, -2.5841e-02,\n",
      "         1.3654e-03, -2.7673e-03,  6.3826e-02,  7.2472e-02,  7.3124e-02,\n",
      "         8.2984e-02, -3.1282e-03,  3.1692e-04, -6.7702e-02,  3.2466e-02,\n",
      "         6.6338e-02, -3.0331e-02, -2.9221e-02,  1.4100e-02, -2.8150e-02,\n",
      "         4.9811e-02,  2.9499e-03,  7.8831e-02,  1.0061e-03, -1.0747e-03,\n",
      "         7.9928e-02, -5.8661e-03, -1.1490e-01, -4.8613e-02,  7.0144e-02,\n",
      "         4.3034e-02, -4.6734e-02,  3.3948e-02, -2.1022e-03, -2.3061e-03,\n",
      "         8.5714e-02,  2.8436e-02,  7.8207e-02, -4.6925e-02,  8.4283e-02,\n",
      "        -2.5005e-02,  7.0285e-02, -8.5980e-03, -2.8128e-02,  8.7992e-03,\n",
      "        -1.0272e-02, -5.1583e-02, -7.0679e-02, -8.6673e-02, -1.0013e-01,\n",
      "        -1.6021e-01, -2.0062e-01, -2.5410e-02,  7.7618e-02, -1.3406e-02,\n",
      "        -2.4582e-02, -1.3577e-01, -3.1720e-02,  1.7887e-02, -3.1115e-02,\n",
      "         4.8163e-02, -6.9923e-02, -2.5994e-02,  3.8252e-02,  7.1386e-03,\n",
      "         1.1575e-01, -1.4970e-01,  5.2060e-02,  1.0994e-01,  7.6559e-02,\n",
      "        -5.5346e-03, -1.6498e-01,  5.4890e-02, -8.0279e-02,  1.2255e-02,\n",
      "         2.0011e-02,  1.7655e-03, -6.9572e-02, -2.9639e-02, -4.7883e-02,\n",
      "         2.1544e-02, -2.5889e-02,  1.0468e-01, -4.0176e-02,  5.1177e-02,\n",
      "        -5.4967e-02,  1.1214e-01, -1.4367e-01, -1.2513e-01,  9.3325e-02,\n",
      "        -8.3927e-02, -7.7945e-03, -3.6959e-02,  1.1959e-01,  2.9268e-02,\n",
      "         7.6250e-02, -1.1764e-01, -6.5974e-02,  4.9455e-02,  4.5899e-02,\n",
      "         1.2594e-02, -4.8191e-02, -8.3128e-02,  5.8944e-02,  4.8622e-02,\n",
      "        -1.2183e-01,  4.3631e-03,  1.6700e-02,  2.8556e-02, -1.3876e-01,\n",
      "         2.6316e-02,  5.3537e-02, -6.0860e-02,  1.5399e-02,  1.6861e-01,\n",
      "         1.0498e-01,  4.7089e-03, -1.0495e-02,  9.2003e-02,  2.7005e-02,\n",
      "        -8.1871e-02, -2.2836e-02,  7.0023e-02, -4.0281e-01, -3.1748e-02,\n",
      "         6.0649e-02,  3.2832e-02,  1.8093e-02,  2.2225e-02,  1.1466e-01,\n",
      "         6.1359e-02, -3.6848e-02,  9.1991e-02, -1.1057e-01, -9.1183e-02,\n",
      "         1.6710e-02,  1.0225e-03, -9.0512e-02, -6.6443e-02, -2.0085e-02,\n",
      "         1.3058e-01,  1.0926e-01,  1.0981e-01, -3.3073e-02,  8.4100e-02,\n",
      "         5.3463e-02,  7.6916e-02,  8.1287e-02,  2.5581e-02, -7.3028e-02,\n",
      "         2.1324e-01, -2.3757e-02, -1.3719e-01, -9.1675e-02, -2.9170e-02,\n",
      "        -1.6264e-01, -2.5221e-02,  1.3400e-01,  1.2748e-02,  7.1623e-02,\n",
      "        -3.5970e-02, -7.1796e-02, -5.6478e-02, -1.8193e-02,  3.9296e-02,\n",
      "         8.1148e-03,  8.9550e-02, -3.0232e-02, -8.6085e-02, -8.9876e-02,\n",
      "        -3.2088e-03,  7.3720e-02, -1.9388e-02,  7.1268e-02, -7.9084e-02,\n",
      "         5.3243e-02,  6.0815e-02,  4.3912e-02, -7.9602e-02, -5.3456e-02,\n",
      "         1.4570e-01, -2.8714e-02, -9.8226e-03,  2.0505e-03, -4.6092e-02,\n",
      "         3.6026e-03,  1.4947e-01, -6.9178e-02, -7.5163e-02,  2.9745e-02,\n",
      "         7.0242e-02, -6.8873e-02, -3.8254e-01,  3.9777e-02,  2.3337e-02,\n",
      "        -1.5620e-01,  1.2238e-02,  4.0232e-02,  4.9004e-02, -1.3870e-02,\n",
      "        -4.7946e-02, -1.0625e-01,  6.7030e-02,  6.0920e-02,  4.0078e-03,\n",
      "        -1.3700e-01,  8.9732e-02,  6.0629e-02, -9.9050e-02, -3.5603e-03,\n",
      "        -9.1501e-02,  2.2243e-02, -3.8647e-04,  9.6019e-02, -3.3435e-02,\n",
      "        -5.2757e-02, -2.6399e-03,  8.7840e-02, -2.4562e-02, -6.7071e-03,\n",
      "        -3.7438e-02, -4.8695e-02, -6.1713e-02, -3.9283e-02, -2.6008e-02,\n",
      "        -2.9445e-02,  7.3580e-02,  6.4646e-02,  7.0401e-04,  4.9296e-02,\n",
      "        -2.0877e-02, -1.0168e-02, -2.8283e-02,  6.7426e-02,  4.0161e-02,\n",
      "         4.6676e-02,  3.9241e-02,  8.6325e-02, -2.8054e-02, -4.3393e-03,\n",
      "        -9.0427e-02,  2.0319e-02,  1.0818e-02, -1.3766e-03, -3.2095e-02,\n",
      "        -1.4208e-01,  2.2342e-02, -5.2475e-02, -3.7163e-02, -8.1505e-02,\n",
      "        -4.8926e-02,  1.1316e-02,  7.7428e-02,  3.5442e-03, -2.1167e-02,\n",
      "         2.8548e-03,  1.2960e-01,  2.4285e-02,  8.0024e-02,  1.0842e-01,\n",
      "         1.0296e-02, -4.9206e-02, -1.6595e-02,  2.1019e-02,  1.1018e-01,\n",
      "         3.5728e-02,  1.0813e-01, -7.5716e-03, -5.9783e-03,  2.6876e-02,\n",
      "         8.1893e-02,  1.5465e-01,  1.1357e-01, -3.8232e-02, -5.9372e-02,\n",
      "        -2.8996e-02,  8.0143e-02,  6.8635e-02, -1.1073e-01, -6.6530e-02,\n",
      "        -1.8683e-01, -4.4586e-02,  7.9534e-02, -8.5190e-03,  5.8983e-02,\n",
      "         8.6090e-03, -7.4072e-02, -6.0405e-02, -9.3671e-02,  1.5239e-01,\n",
      "         7.9310e-02, -7.0929e-02,  5.5800e-02, -1.1270e-01, -7.5184e-02,\n",
      "        -7.5464e-02, -2.8341e-02, -5.7189e-02,  6.1294e-02, -2.3803e-02,\n",
      "         3.3558e-02, -2.3749e-02,  6.3735e-02,  7.8340e-02, -3.5646e-02,\n",
      "        -7.8755e-02, -2.5370e-02,  1.2988e-01,  8.2129e-02, -8.4520e-02,\n",
      "        -4.8923e-02, -5.4268e-02, -1.2524e-02, -1.2805e-01, -3.4503e-02,\n",
      "        -2.4704e-02, -1.1030e-01, -6.3641e-02,  6.1906e-02, -1.5443e-01,\n",
      "         6.1768e-02,  7.5456e-03,  2.5523e-02,  8.4809e-02,  5.2740e-02,\n",
      "         1.0771e-02, -1.1576e-02,  2.4763e-02, -1.1425e-03, -1.9188e-02,\n",
      "         2.5628e-04, -2.4009e-02, -1.0411e-01, -2.4693e-03,  2.5831e-02,\n",
      "        -1.6268e-03, -7.8446e-02, -5.3222e-02, -5.3239e-02,  2.5200e-02,\n",
      "        -1.2553e-01, -1.1935e-01,  5.1660e-03, -4.1622e-02, -9.6167e-02,\n",
      "         2.4294e-02,  2.8308e-02, -2.3837e-02,  1.5290e-02, -6.6122e-02,\n",
      "         8.0216e-02, -2.2971e-02, -1.4490e-01,  1.1367e-01, -2.0333e-01,\n",
      "        -9.7551e-02, -3.5378e-02, -6.2521e-02,  6.0775e-02,  1.3383e-02,\n",
      "         6.0984e-02, -8.2290e-02,  1.4814e-01, -3.5236e-02, -4.2750e-02,\n",
      "         1.6476e-02, -6.4738e-02,  4.6168e-02, -3.2097e-03, -1.4133e-01,\n",
      "        -5.2245e-02, -6.7218e-02, -1.8109e-02, -4.9594e-03, -1.5656e-02,\n",
      "        -4.9922e-02,  5.7346e-03,  1.5916e-02,  6.6464e-02, -4.3842e-02,\n",
      "        -3.9730e-02,  2.6693e-02,  1.2306e-01,  1.0437e-01,  7.6489e-03,\n",
      "        -7.5542e-03,  9.7519e-02, -8.7918e-02, -4.7447e-02,  4.1338e-02,\n",
      "        -1.3719e-02,  5.8739e-02, -1.0385e-01, -1.5167e-01, -3.9973e-02,\n",
      "        -1.7150e-02,  3.9206e-02,  8.1437e-02,  3.9987e-02,  1.1733e-01,\n",
      "        -8.6637e-02,  1.9996e-02, -4.2925e-02, -4.9195e-02,  6.6860e-02,\n",
      "         1.5036e-01, -1.0436e-01,  5.1541e-02,  1.4848e-02, -1.1995e-01,\n",
      "         6.5475e-02, -3.3349e-02, -3.0054e-02,  6.8193e-02,  1.0290e-01,\n",
      "        -9.3473e-02,  1.8275e-02,  6.7032e-02, -1.2252e-02,  5.9011e-02,\n",
      "        -6.6202e-02, -4.4816e-02,  9.1144e-02,  6.6103e-02, -6.5524e-02,\n",
      "         9.1697e-02, -1.2182e-02, -9.6975e-02, -4.3094e-02, -2.8458e-02,\n",
      "         6.4503e-03,  7.9385e-02,  1.3934e-01,  1.6263e-01, -1.0648e-02,\n",
      "         8.0036e-02,  4.8232e-02, -1.3051e-02,  1.3746e-01,  1.4880e-02,\n",
      "        -8.1980e-02,  4.8130e-02])\n",
      "trainable parameters: bert.encoder.layer.0.attention.output.LayerNorm.weight tensor([0.8392, 0.7954, 0.7884, 0.8291, 0.8604, 0.8388, 0.8241, 0.8217, 0.7767,\n",
      "        0.8363, 0.8256, 0.8539, 0.8354, 0.8126, 0.8889, 0.8301, 0.8423, 0.8299,\n",
      "        0.8337, 0.8333, 0.8240, 0.8391, 0.8237, 0.6022, 0.8497, 0.8421, 0.8559,\n",
      "        0.8261, 0.8421, 0.8363, 0.8143, 0.7520, 0.8717, 0.8493, 0.8329, 0.8347,\n",
      "        0.8155, 0.7966, 0.8897, 0.8470, 0.8156, 0.8596, 0.8417, 0.8285, 0.8368,\n",
      "        0.8261, 0.8130, 0.8394, 0.8451, 0.9323, 0.8534, 0.8263, 0.8262, 0.8239,\n",
      "        0.8227, 0.8178, 0.7904, 0.8489, 0.8169, 0.7808, 0.8639, 0.8883, 0.7773,\n",
      "        0.8483, 0.8106, 0.8107, 0.8009, 0.8366, 0.8278, 0.8041, 0.8364, 0.8302,\n",
      "        0.8245, 0.8226, 0.8242, 0.8346, 0.8233, 0.8226, 0.8240, 0.8044, 0.8148,\n",
      "        0.8340, 0.8270, 0.8286, 0.8644, 0.8059, 0.7762, 0.8044, 0.8442, 0.8309,\n",
      "        0.8263, 0.8077, 0.8076, 0.8033, 0.8238, 0.8366, 0.8178, 0.8331, 0.8585,\n",
      "        0.8298, 0.8141, 0.7982, 0.7919, 0.8071, 0.8591, 0.8101, 0.8417, 0.8382,\n",
      "        0.7882, 0.8724, 0.8168, 0.7969, 0.8172, 0.8700, 0.8499, 0.8249, 0.8299,\n",
      "        0.8585, 0.8240, 0.9116, 0.8365, 0.6048, 0.8306, 0.8367, 0.8449, 0.8283,\n",
      "        0.8350, 0.8406, 0.8230, 0.8406, 0.8972, 0.8643, 0.8109, 0.8224, 0.6226,\n",
      "        0.8299, 0.9182, 0.8570, 0.8123, 0.8754, 0.8318, 0.8249, 0.8298, 0.8176,\n",
      "        0.8131, 0.8233, 0.8060, 0.8114, 0.8221, 0.8817, 0.7783, 0.8229, 0.8414,\n",
      "        0.8175, 0.7972, 0.8421, 0.7245, 0.8628, 0.8328, 0.8179, 0.8409, 0.8279,\n",
      "        0.8273, 0.8599, 0.8165, 0.8414, 0.8991, 0.8391, 0.8231, 0.8358, 0.8282,\n",
      "        1.0291, 0.8349, 0.8628, 0.8504, 0.8434, 0.8207, 0.8530, 0.8421, 0.8484,\n",
      "        0.8361, 0.8103, 0.8441, 0.8468, 0.8770, 0.8467, 0.8031, 0.8029, 0.8498,\n",
      "        0.7995, 0.8315, 0.8528, 0.7901, 0.8262, 0.7938, 0.8608, 0.8386, 0.8115,\n",
      "        0.8527, 0.8662, 0.8360, 0.8308, 0.8742, 0.8077, 0.8321, 0.8514, 0.8729,\n",
      "        0.8266, 0.8176, 0.8413, 0.8742, 0.8315, 0.8490, 0.8645, 0.8117, 0.8369,\n",
      "        0.8173, 0.8865, 0.8289, 0.8280, 0.7986, 0.7785, 0.8351, 0.8114, 0.8142,\n",
      "        0.8171, 0.8516, 0.8939, 0.8436, 0.8487, 0.8119, 0.8507, 0.8564, 0.8579,\n",
      "        0.8085, 0.8441, 0.8559, 0.9155, 0.8442, 0.8147, 0.8456, 0.8546, 0.8635,\n",
      "        0.7369, 0.8423, 0.7661, 0.8246, 0.8354, 0.8249, 0.8406, 0.8192, 0.8225,\n",
      "        0.8159, 0.8140, 0.8425, 0.8210, 0.8643, 0.7939, 0.7903, 0.8482, 0.8108,\n",
      "        0.8487, 0.5680, 0.8811, 0.8563, 0.8375, 0.8639, 0.7944, 0.8765, 0.8648,\n",
      "        0.8495, 0.8181, 0.8199, 0.8211, 0.8468, 1.2361, 1.3206, 0.8550, 0.8578,\n",
      "        0.8725, 0.8339, 0.8402, 0.8614, 0.8045, 0.8284, 0.8362, 0.8320, 0.8104,\n",
      "        0.8213, 0.8611, 0.8133, 0.8607, 0.8420, 0.8467, 0.8480, 0.8124, 0.8280,\n",
      "        0.8733, 0.8138, 0.7784, 0.8166, 0.8294, 0.8067, 0.8156, 0.8272, 0.8081,\n",
      "        0.8235, 0.8268, 0.8392, 0.8065, 0.8335, 0.7993, 0.8469, 0.8539, 0.8169,\n",
      "        0.8327, 0.8419, 0.8579, 0.8463, 0.8350, 0.7975, 0.8111, 0.8096, 0.8570,\n",
      "        0.8263, 0.8287, 0.8650, 0.8335, 0.6417, 0.8370, 0.8350, 0.8647, 0.8258,\n",
      "        0.8154, 0.7161, 0.8477, 0.8365, 0.8257, 0.8517, 0.8412, 0.8419, 0.8322,\n",
      "        0.8296, 0.8394, 0.8383, 0.8163, 0.7930, 0.8303, 0.8598, 0.8720, 0.7363,\n",
      "        0.8347, 0.8749, 0.8705, 0.8478, 0.8431, 0.8717, 0.7998, 0.8524, 0.8365,\n",
      "        0.8436, 0.8023, 0.8257, 0.8157, 0.8881, 0.8049, 0.8377, 0.8588, 0.8333,\n",
      "        0.8464, 0.8452, 0.8518, 0.8612, 0.8122, 0.8484, 0.8886, 0.8416, 0.8522,\n",
      "        0.8611, 0.8393, 0.8323, 0.8247, 0.8349, 0.8398, 0.8257, 0.8351, 0.7566,\n",
      "        0.8146, 0.8157, 0.8629, 0.8156, 0.8524, 0.8317, 0.8453, 0.8245, 0.8317,\n",
      "        0.8769, 0.8659, 0.8344, 0.8022, 0.7922, 0.7913, 0.8053, 0.8428, 0.9239,\n",
      "        0.8265, 0.8511, 0.8571, 0.8283, 0.8345, 0.8142, 0.8142, 0.8499, 0.8563,\n",
      "        0.8454, 0.8319, 0.8321, 0.8567, 0.8335, 0.8578, 0.8881, 0.6676, 0.8236,\n",
      "        0.8123, 0.7864, 0.8469, 0.8301, 0.8336, 0.8472, 0.8124, 0.8242, 0.8486,\n",
      "        0.8511, 0.8212, 0.8810, 0.8923, 0.8377, 0.8397, 0.7985, 0.8506, 0.8515,\n",
      "        0.8071, 0.8310, 0.8122, 2.0313, 0.8201, 1.0727, 0.8281, 0.8392, 0.8641,\n",
      "        0.8391, 0.8199, 0.8526, 0.8573, 0.7324, 0.8200, 0.8030, 0.8469, 0.8264,\n",
      "        0.8186, 0.8701, 0.8511, 0.8405, 0.9858, 0.7936, 0.8536, 0.8506, 0.8551,\n",
      "        0.8400, 0.6681, 0.9000, 0.8700, 0.8510, 0.8141, 0.8961, 0.8476, 0.8510,\n",
      "        0.8224, 0.8390, 0.8030, 0.8429, 0.8216, 0.8351, 0.8556, 0.8378, 0.8177,\n",
      "        0.8191, 0.8428, 0.7912, 0.8568, 0.7648, 0.8535, 0.8479, 0.8434, 0.8243,\n",
      "        0.7812, 0.8249, 0.9034, 0.8431, 0.8153, 0.8561, 0.7937, 0.8197, 0.9070,\n",
      "        0.8460, 0.8538, 0.8523, 0.8506, 0.8269, 0.8297, 0.8423, 0.8284])\n",
      "trainable parameters: bert.encoder.layer.0.attention.output.LayerNorm.bias tensor([ 7.4981e-02,  1.7161e-01,  1.3057e-02, -1.7239e-01, -3.8021e-02,\n",
      "         1.4732e-01,  4.0768e-02, -5.3902e-05, -4.0054e-01,  2.9430e-02,\n",
      "        -1.1543e-01, -1.2781e-01, -1.4105e-01, -1.8866e-01, -7.2046e-03,\n",
      "         4.7046e-02,  7.3254e-02, -2.0212e-02, -3.6348e-02,  2.0893e-02,\n",
      "        -3.5708e-02, -1.3772e-01, -1.4713e-02,  1.1017e-01, -7.2116e-02,\n",
      "        -3.7948e-01, -3.6206e-01,  7.7766e-02, -7.9186e-02,  1.3621e-01,\n",
      "        -1.2616e-01, -3.6860e-01, -7.7862e-03, -1.2572e-01,  9.4991e-02,\n",
      "         2.7147e-01,  2.8313e-02,  9.5609e-03, -1.0391e-01, -6.4793e-02,\n",
      "        -6.6908e-02,  1.2505e-01,  1.5379e-01,  1.5011e-01,  1.1516e-01,\n",
      "        -2.2832e-02,  8.0233e-02,  3.4043e-02, -2.7603e-01, -1.3217e-02,\n",
      "        -1.2409e-01,  1.1597e-01,  1.1015e-01, -1.0047e-01,  1.4640e-02,\n",
      "         1.4231e-01, -7.6890e-02, -2.1269e-01,  8.6082e-02,  1.9426e-01,\n",
      "         2.1690e-01, -1.1000e-02,  1.3005e-01, -2.8730e-03,  6.2799e-02,\n",
      "        -7.1197e-02,  9.5276e-03,  2.5012e-02, -1.7028e-02, -1.0072e-01,\n",
      "         1.7408e-01, -8.0700e-02, -7.5013e-02, -3.1027e-01,  2.8243e-02,\n",
      "         4.0590e-02, -6.9578e-02, -3.1549e-01,  2.1546e-01,  1.0320e-02,\n",
      "         1.3299e-01, -1.2743e-02,  2.1226e-03, -2.0730e-02, -6.1603e-02,\n",
      "         3.1800e-01,  5.8430e-02, -1.8505e-01,  1.6777e-02, -2.2072e-03,\n",
      "         1.8169e-01, -2.9019e-02,  4.3446e-03,  1.0412e-01, -2.0980e-02,\n",
      "        -1.7854e-01, -1.2989e-01,  1.9360e-02, -4.0341e-01, -1.8696e-02,\n",
      "        -1.0376e-01, -3.7917e-02,  4.2194e-02, -7.3110e-03, -1.6728e-02,\n",
      "        -1.0804e-01, -5.1701e-03, -2.0998e-01,  2.6711e-02, -3.6120e-02,\n",
      "        -1.1636e-02, -1.0080e-01, -2.5021e-01, -1.1737e-01, -2.5840e-01,\n",
      "        -4.0843e-01,  9.1412e-02, -3.6644e-01, -9.9447e-02,  3.7687e-01,\n",
      "         9.5046e-02,  1.7934e-01, -2.6654e-02,  3.4460e-02, -2.0383e-01,\n",
      "        -1.2458e-01, -6.5271e-02, -1.2900e-01, -7.0792e-02,  5.4685e-02,\n",
      "        -5.5165e-03, -1.0503e-01, -9.9829e-02, -4.9119e-02,  6.0527e-01,\n",
      "         3.6553e-02, -1.8169e+00,  1.4906e-01,  5.9812e-02,  1.2244e-01,\n",
      "        -4.7814e-03, -8.1587e-02, -1.1311e-01, -1.3845e-01,  1.3938e-01,\n",
      "         1.6236e-01, -7.4199e-02, -2.5333e-02,  1.5543e-02, -1.0915e-03,\n",
      "         4.5498e-01, -4.9284e-02,  7.2495e-04, -7.9772e-03,  4.5903e-02,\n",
      "         2.8080e-02,  6.2014e-01, -4.0957e-02,  1.0668e-01,  1.9874e-01,\n",
      "        -1.2460e-01, -2.5971e-01, -1.3423e-01,  1.8633e-01,  3.5402e-02,\n",
      "         1.8703e-02,  1.9607e-01,  1.0752e-01, -7.6282e-02, -4.2106e-02,\n",
      "        -1.3881e-01,  7.1017e-02,  2.5298e-02,  2.9795e-02, -1.0412e-01,\n",
      "         4.5823e-02,  1.7355e-02, -2.0676e-01,  1.5137e-01, -1.4885e-01,\n",
      "        -1.0453e-01,  2.5475e-01,  1.9989e-01, -6.8226e-02,  6.5799e-02,\n",
      "         1.6223e-01, -1.3110e-02, -2.2049e-02, -1.2965e-01,  6.2382e-02,\n",
      "         5.6045e-03,  3.5406e-02,  7.1994e-02, -4.4235e-01, -1.3758e-01,\n",
      "         1.0714e-01,  6.6510e-02,  1.4223e-02, -8.5371e-02,  2.2903e-02,\n",
      "         4.0011e-02,  6.4827e-02, -5.8735e-02, -1.5160e-01, -9.8495e-02,\n",
      "         2.8508e-01, -7.7577e-02, -6.3965e-02, -7.0661e-03,  9.1238e-02,\n",
      "        -7.8119e-02,  5.1809e-01,  2.6376e-02, -3.3936e-02, -2.2952e-01,\n",
      "         1.2678e-01,  3.2059e-02, -8.1177e-02, -1.3652e-01, -8.0947e-02,\n",
      "         2.4087e-01, -9.2850e-03, -3.7527e-02, -2.7710e-01, -6.0618e-03,\n",
      "         1.4521e-01, -9.3688e-02, -6.1161e-02,  2.5982e-01,  1.6109e-02,\n",
      "         3.3527e-02, -4.7621e-02,  1.0305e-01, -8.6295e-02, -1.2675e-01,\n",
      "        -1.1752e-01, -5.0597e-02,  3.8195e-02,  4.7955e-02,  2.3171e-02,\n",
      "        -9.3431e-02,  2.7740e-02, -3.4426e-02, -1.9124e-01,  1.0431e-01,\n",
      "        -4.5111e-02,  1.0222e-01, -1.1323e-01,  1.9349e-01, -7.0545e-02,\n",
      "         1.9769e-01,  3.9597e-02, -1.4692e-02,  1.2617e-02,  7.7935e-02,\n",
      "         4.3581e-02, -3.0834e-01,  9.5256e-02,  1.0977e-01,  1.7141e-03,\n",
      "         7.1164e-02, -1.7034e-01,  3.8951e-01, -3.6300e-02,  5.8865e-02,\n",
      "        -1.8111e-01,  6.2315e-03, -9.7399e-02,  2.5545e-02, -1.3326e-01,\n",
      "        -9.1206e-02, -1.3642e-01,  9.8706e-02, -1.3827e-01, -3.1649e-02,\n",
      "         3.3285e-01, -1.3343e+00, -6.5227e-02, -8.7432e-02,  7.5882e-02,\n",
      "         2.6915e-01, -7.0566e-02, -8.2825e-03,  1.5960e-01, -1.0063e-01,\n",
      "        -3.1509e-02, -1.1829e-01, -6.0959e-02,  1.1788e-01, -6.3588e-02,\n",
      "        -2.1429e-01, -6.4494e-03,  3.5589e-02,  4.5282e-02, -1.3792e-01,\n",
      "         7.1870e-02,  1.6250e-01, -3.5973e-01, -2.4659e-02, -2.2009e-01,\n",
      "        -1.2482e-01,  1.2782e-02, -4.6564e-02, -2.9694e-02,  1.9187e-01,\n",
      "         3.6563e-02, -5.8943e-02,  5.0716e-02, -1.3039e-04,  3.6918e-01,\n",
      "        -2.3964e-01, -7.2282e-02, -8.6279e-02, -6.3594e-02, -1.7983e-01,\n",
      "        -3.9762e-02,  9.7547e-02,  4.7022e-02, -5.2354e-02,  2.0697e-01,\n",
      "        -7.9864e-02, -2.5195e-02, -2.6681e-02, -2.1926e-04, -6.1587e-02,\n",
      "         1.3303e-01,  4.3220e-02, -4.6840e-02, -1.8059e-01,  5.4014e-01,\n",
      "        -5.4847e-01, -1.2804e-01, -3.7819e-02,  2.4421e-02,  3.1180e-01,\n",
      "         8.4833e-02,  1.1518e-01, -1.1523e-01, -1.6927e-01,  1.1888e-01,\n",
      "         9.6574e-02,  7.3251e-02,  1.4738e-01,  1.7579e-01, -1.6526e-03,\n",
      "         1.4952e-02,  1.2230e-01,  1.5250e-02,  1.6247e-01,  2.0223e-01,\n",
      "        -2.0403e-01, -1.1992e-02, -1.9003e-01,  5.0050e-03,  2.6056e-01,\n",
      "        -2.1081e-01,  1.4387e+00, -7.9328e-02, -5.0276e-02,  1.8180e-01,\n",
      "         2.7224e-01, -1.3442e-01,  4.3232e-02, -6.2172e-02,  2.7115e-01,\n",
      "         9.9289e-02, -4.1950e-02, -4.4091e-03, -9.2402e-02,  4.7378e-02,\n",
      "         8.6540e-02, -5.1889e-02, -3.3048e-02,  1.8614e-01, -8.5523e-02,\n",
      "        -1.5678e-01,  1.5349e-01,  1.8419e-01,  1.1288e-01, -1.9794e-01,\n",
      "        -6.9432e-03, -9.8860e-02,  4.7748e-02, -4.4186e-02, -2.1080e-02,\n",
      "         7.7585e-02, -1.9532e-01,  1.2706e-02,  1.6908e-01, -8.9835e-02,\n",
      "         1.2106e-01,  1.6337e-01,  3.6606e-02,  1.2980e-01,  5.9150e-02,\n",
      "         5.5622e-02, -6.3438e-02, -8.2094e-02, -1.9932e-01,  3.6054e-02,\n",
      "         1.5089e-01, -1.3397e-01, -2.8864e-02, -1.1333e-01, -8.9826e-03,\n",
      "         1.0331e-01,  9.4731e-02, -6.7486e-02,  2.5121e-02,  2.2608e-02,\n",
      "         9.7641e-02, -2.3964e-01, -3.0428e-02, -1.8063e-01,  3.6529e-03,\n",
      "        -5.4369e-02,  1.0631e-01, -1.0088e-01,  9.2119e-02,  1.2437e-01,\n",
      "         3.9782e-02, -3.7108e-01, -6.1513e-02,  1.6500e-01,  6.2654e-02,\n",
      "        -4.9282e-02,  5.3968e-02, -1.0792e-01,  1.6719e-01,  2.4188e-01,\n",
      "         1.1923e-01, -5.0928e-02,  5.7949e-02,  4.2601e-02, -1.0627e-01,\n",
      "        -2.9166e-02, -5.2063e-01,  2.2534e-01, -1.8055e-02, -1.8821e-01,\n",
      "        -5.6818e-02, -2.6211e-01, -3.8772e-02, -1.0609e-01,  5.2442e+00,\n",
      "        -1.1868e-01, -2.0815e-01,  6.4110e-02,  5.3552e-02, -1.7126e-01,\n",
      "         1.8265e-01,  4.0115e-02,  7.1084e-02,  6.0825e-02,  6.1885e-01,\n",
      "         1.6296e-01, -9.0671e-02, -9.9208e-02,  8.6991e-02, -2.0616e-02,\n",
      "        -1.6785e-01, -9.8439e-02, -1.5518e-01,  9.8391e-02, -6.5346e-02,\n",
      "        -6.5537e-02,  5.0985e-02,  6.5057e-02,  1.6550e-01,  2.3038e-01,\n",
      "        -1.1079e-01, -7.7739e-03,  2.3138e-02, -5.5267e-02, -1.0170e-01,\n",
      "         9.7331e-02,  9.4008e-02,  1.9317e-02, -1.0862e-02, -1.0754e-01,\n",
      "         2.5461e-01,  1.8035e-01,  1.7923e-01,  3.4015e-02,  6.6199e-02,\n",
      "        -1.4826e-01,  2.8216e-01, -5.7907e-02, -8.6928e-02,  1.1885e-01,\n",
      "        -7.4732e-02,  9.2368e-02,  2.9036e-01, -1.8474e-02,  1.3819e-01,\n",
      "         1.6136e-01, -7.1790e-02, -1.9442e-01, -1.9748e-01, -7.5315e-02,\n",
      "         4.1108e-01,  3.6993e-02,  6.0524e-02, -1.4187e-02,  1.4489e-01,\n",
      "         2.1989e-01,  2.7608e-01,  4.2406e-02,  3.9320e-02, -1.9020e-01,\n",
      "         4.0231e-02,  1.0524e-01])\n",
      "trainable parameters: bert.encoder.layer.0.intermediate.dense.weight tensor([[ 0.0863,  0.0280,  0.0011,  ..., -0.0107,  0.0074, -0.0171],\n",
      "        [ 0.0018, -0.0308,  0.0020,  ...,  0.0287,  0.0354,  0.0644],\n",
      "        [-0.0070,  0.0388,  0.0171,  ..., -0.0195, -0.0098, -0.0314],\n",
      "        ...,\n",
      "        [ 0.0060,  0.0016, -0.0378,  ..., -0.0699, -0.0136,  0.0339],\n",
      "        [ 0.0265,  0.0359,  0.0049,  ...,  0.0756,  0.0079, -0.0141],\n",
      "        [-0.0233, -0.0030, -0.0459,  ...,  0.0306,  0.0359, -0.0105]])\n",
      "trainable parameters: bert.encoder.layer.0.intermediate.dense.bias tensor([-0.0622, -0.1757,  0.0103,  ..., -0.1034, -0.0627, -0.0010])\n",
      "trainable parameters: bert.encoder.layer.0.output.dense.weight tensor([[-0.0135, -0.0385, -0.0136,  ...,  0.1207, -0.0553,  0.0157],\n",
      "        [-0.0667,  0.0120, -0.0610,  ...,  0.0483, -0.0556, -0.0485],\n",
      "        [ 0.0508,  0.0508, -0.0272,  ..., -0.0138, -0.0283,  0.0127],\n",
      "        ...,\n",
      "        [-0.0255, -0.0075,  0.0171,  ...,  0.0627, -0.1043, -0.0453],\n",
      "        [-0.0558,  0.0213, -0.0093,  ..., -0.0062, -0.0280, -0.0274],\n",
      "        [ 0.0130,  0.0119,  0.0210,  ..., -0.0165, -0.0031,  0.0024]])\n",
      "trainable parameters: bert.encoder.layer.0.output.dense.bias tensor([-7.1711e-02,  3.0261e-02, -5.7315e-02,  1.2706e-02,  1.1689e-03,\n",
      "        -7.5017e-02, -4.4981e-02, -2.9934e-02,  4.5705e-02,  2.3623e-02,\n",
      "        -1.7888e-02,  4.8135e-02, -3.4359e-02,  5.0038e-02, -2.5253e-03,\n",
      "         2.8158e-02, -7.1628e-03,  1.3266e-02,  6.5529e-02, -4.4770e-02,\n",
      "         4.6920e-02, -2.2810e-02,  2.9483e-02,  5.6315e-02,  9.5039e-04,\n",
      "         6.6608e-03, -7.1861e-02, -1.3733e-03, -3.0679e-02, -7.8626e-03,\n",
      "         2.1582e-02,  4.3984e-02, -2.9022e-02, -1.8849e-02, -1.9029e-02,\n",
      "         1.5254e-02, -2.1076e-02, -2.0966e-02, -1.3709e-02, -2.0683e-02,\n",
      "         2.8558e-03,  3.9834e-02, -8.8671e-03,  1.2235e-01,  5.5245e-02,\n",
      "         5.4826e-02,  2.2670e-03, -7.0135e-02, -1.2915e-01,  1.6393e-02,\n",
      "         1.1119e-01, -9.1258e-02, -9.8270e-02, -7.0969e-02, -8.4669e-02,\n",
      "        -3.4275e-02, -2.0242e-03, -1.4601e-02,  4.5923e-02, -2.2120e-02,\n",
      "         1.4789e-02, -1.1165e-02, -3.3752e-02,  4.4320e-02,  4.3444e-02,\n",
      "        -5.9969e-02,  6.3750e-02, -5.8611e-02,  4.6545e-02, -8.4423e-03,\n",
      "        -4.5487e-02,  1.1908e-02, -2.7165e-02, -5.7054e-02, -2.6317e-02,\n",
      "        -5.8883e-02, -6.7638e-02,  1.0803e-01, -5.4850e-02, -1.4430e-03,\n",
      "         1.4450e-01, -2.4243e-03, -6.2158e-02,  1.8876e-02, -9.5963e-02,\n",
      "         2.6829e-02,  4.8638e-03,  2.4927e-03,  8.0139e-02, -2.5275e-02,\n",
      "        -5.3170e-02,  5.1475e-02,  5.5668e-02, -2.0778e-02,  3.4756e-02,\n",
      "         2.9086e-02, -1.2615e-02, -6.1654e-02, -5.3507e-02,  4.0222e-02,\n",
      "         4.6600e-03,  3.1720e-02, -8.6688e-03, -3.0409e-02,  2.1019e-02,\n",
      "         5.0491e-02,  1.8981e-03, -1.6627e-02, -6.0766e-02,  9.2823e-02,\n",
      "        -1.0468e-01,  2.9816e-02, -2.5639e-02,  1.4806e-03,  5.0516e-02,\n",
      "        -4.8922e-03,  2.2382e-02, -1.1885e-02, -3.9045e-02, -5.6008e-02,\n",
      "         6.6120e-02,  2.3923e-02, -2.8359e-02,  6.9843e-02,  3.5211e-02,\n",
      "         3.8819e-02, -1.8137e-02, -3.0202e-02, -4.0679e-02, -3.1035e-02,\n",
      "        -3.9180e-02, -4.7131e-02,  3.6271e-02,  4.7132e-02,  1.4897e-01,\n",
      "         3.5256e-02,  1.1871e-01,  3.1396e-03, -3.1654e-02,  4.5502e-02,\n",
      "        -5.3563e-02,  3.9284e-02, -2.1966e-03,  2.8068e-02,  1.3266e-02,\n",
      "        -1.7513e-02, -3.2845e-02, -3.1781e-02,  3.3346e-02, -9.5989e-02,\n",
      "        -6.9615e-03,  8.2806e-02, -1.4955e-02,  1.1319e-02,  3.9095e-02,\n",
      "         6.6072e-02, -2.0224e-02,  5.9397e-02,  6.4223e-02, -2.6737e-02,\n",
      "         5.4409e-02, -1.1522e-02, -1.9561e-02, -6.8296e-02,  3.2693e-02,\n",
      "         6.5686e-02, -1.0903e-03,  3.7849e-03, -6.1769e-03,  1.1661e-02,\n",
      "         2.4797e-02, -7.3512e-02, -3.0164e-02,  7.3768e-02,  2.2023e-02,\n",
      "        -4.0801e-02, -3.3635e-02, -5.9976e-02, -7.1081e-02, -9.7134e-03,\n",
      "         3.6532e-02,  6.4829e-02, -6.9297e-02,  3.4954e-02,  9.1495e-02,\n",
      "         2.8851e-02,  5.7782e-02,  1.9632e-02, -1.1298e-02,  3.8193e-03,\n",
      "        -3.7918e-02,  4.1577e-03,  2.8274e-02,  1.9805e-01,  4.4011e-02,\n",
      "         1.7000e-02, -5.3706e-02,  2.5733e-02, -3.7013e-02,  1.7267e-02,\n",
      "         3.9810e-02,  6.6512e-02, -1.5113e-02,  3.7158e-02, -2.8191e-03,\n",
      "         8.8376e-02,  5.2905e-02, -6.5360e-02,  5.1843e-02, -5.8789e-03,\n",
      "         2.4404e-02,  1.4059e-02, -3.1755e-02, -4.4863e-02,  7.0132e-02,\n",
      "        -8.9450e-02, -2.4433e-02, -7.4850e-04, -2.2241e-02, -6.3747e-02,\n",
      "         6.9201e-02,  3.1063e-03,  1.6278e-02, -9.5555e-02, -1.4333e-02,\n",
      "        -7.9564e-02,  5.2284e-02, -2.8202e-02,  6.4277e-02, -1.8217e-02,\n",
      "         7.0569e-02, -1.6371e-02, -4.3638e-02,  1.0884e-02,  7.2888e-02,\n",
      "        -3.2570e-03,  6.2420e-02,  1.6222e-02, -8.4026e-02,  1.8417e-02,\n",
      "         4.9777e-02,  6.6753e-04,  6.4217e-02, -1.7510e-02, -7.8092e-02,\n",
      "        -8.4101e-02,  1.5003e-02,  1.0353e-01,  4.5247e-02,  3.1005e-02,\n",
      "         7.0653e-02, -2.8743e-02,  2.8325e-02, -6.7292e-04,  5.2034e-03,\n",
      "        -3.4279e-02, -9.3437e-02,  4.8285e-02, -1.0250e-01,  2.6348e-02,\n",
      "         3.4638e-02, -1.8595e-02,  1.9340e-01, -2.7431e-02,  1.4577e-02,\n",
      "        -5.0407e-02, -5.2142e-02, -3.7879e-02, -1.9512e-02,  4.8687e-03,\n",
      "         3.6148e-02, -5.7380e-02, -1.1124e-02, -3.8443e-02,  4.7291e-03,\n",
      "        -1.2469e-01,  1.1140e-01,  9.6633e-03,  2.3783e-02,  2.0030e-02,\n",
      "        -1.0417e-01, -1.1799e-02, -4.9880e-04,  4.4092e-02,  3.8800e-02,\n",
      "         3.8763e-02, -1.4316e-02,  3.7828e-03, -3.0100e-03, -1.6675e-02,\n",
      "         5.6516e-02, -7.3429e-02,  2.1087e-03,  1.4336e-02, -4.0279e-02,\n",
      "         7.7580e-02,  5.4710e-02,  6.3011e-02, -3.3571e-02,  9.6074e-02,\n",
      "        -1.7598e-02, -2.8100e-02, -4.4680e-02, -3.7491e-02, -3.4144e-02,\n",
      "         8.6305e-02,  1.1665e-01,  2.0674e-02, -3.1130e-02, -3.3642e-03,\n",
      "         1.7294e-02,  3.3558e-02,  2.5312e-02, -2.3774e-02, -4.9949e-03,\n",
      "        -6.9434e-02, -1.1785e-01, -1.0197e-02,  1.3407e-03,  4.4305e-05,\n",
      "         4.9131e-02,  3.3571e-02, -2.3014e-02, -3.6936e-02,  1.3267e-02,\n",
      "         3.1569e-02,  1.0734e-01, -5.3106e-02, -3.5765e-02, -5.4492e-02,\n",
      "         2.1677e-02,  1.5950e-02,  2.1068e-02,  3.9475e-02,  1.0360e-01,\n",
      "        -3.9696e-02,  1.8344e-02,  6.8690e-02,  3.2909e-03,  3.3556e-02,\n",
      "        -2.5378e-02, -2.2469e-02,  7.0111e-02,  1.9563e-02, -2.8358e-02,\n",
      "        -2.9680e-02, -9.3145e-02, -4.5119e-02, -3.4181e-02, -4.7108e-02,\n",
      "        -6.0882e-03, -4.9737e-03,  1.5102e-02, -1.0466e-01,  1.2254e-03,\n",
      "        -3.6100e-02, -8.7016e-02, -2.3740e-02, -2.7340e-02,  4.6676e-02,\n",
      "         3.7654e-02,  3.6205e-02, -4.0299e-02, -3.2866e-02, -1.5950e-02,\n",
      "        -7.2740e-03,  7.6082e-02, -1.5311e-02, -4.6131e-02,  2.8975e-02,\n",
      "         4.3433e-02,  9.9027e-03, -3.0497e-02,  3.6722e-02,  1.8344e-02,\n",
      "        -3.1437e-02, -7.7857e-02,  4.5419e-02, -1.1887e-02,  2.0769e-02,\n",
      "        -6.8573e-02, -4.8698e-02,  1.8040e-02, -2.3225e-02,  2.3423e-02,\n",
      "        -4.5521e-03,  8.5032e-02,  2.0363e-02,  9.7927e-03, -8.8420e-02,\n",
      "        -1.4598e-02, -7.1249e-02, -1.6887e-02, -5.5087e-02, -4.9412e-02,\n",
      "        -2.6462e-02, -2.6716e-02,  3.5022e-02,  4.7334e-03,  6.7670e-02,\n",
      "         1.1734e-02,  2.6837e-02, -5.9239e-02,  1.4261e-02, -5.5945e-02,\n",
      "         7.2510e-02, -4.5410e-02, -3.3947e-02,  1.2062e-02, -1.4439e-02,\n",
      "        -2.2169e-02,  1.2485e-04,  3.1842e-02, -2.4185e-02, -5.4474e-02,\n",
      "        -2.2130e-02, -3.3234e-02, -2.8719e-02,  5.9870e-02, -7.6146e-02,\n",
      "         6.2805e-02, -5.4294e-02, -5.9438e-02,  3.0830e-02,  5.0928e-04,\n",
      "         9.0235e-03,  2.9114e-02,  6.0211e-02,  2.5500e-03, -8.9091e-02,\n",
      "        -3.3731e-02, -6.6045e-02, -2.7705e-02,  2.8724e-02,  2.0033e-02,\n",
      "        -4.3999e-02, -3.1995e-02, -3.9538e-02, -6.8582e-02,  3.6547e-02,\n",
      "         8.5709e-03, -7.1146e-02, -8.9756e-02,  5.2595e-02,  3.7472e-02,\n",
      "         2.5005e-02,  7.5686e-02,  2.9985e-02,  2.0377e-02, -2.9884e-02,\n",
      "        -1.0966e-02, -8.6574e-03,  4.1776e-02, -6.2582e-02,  2.2024e-01,\n",
      "         6.5419e-02,  3.3934e-02,  1.7847e-02,  6.3685e-03,  5.6625e-02,\n",
      "         5.2985e-02, -3.5474e-02,  7.2699e-02, -5.4790e-02, -4.3788e-02,\n",
      "         4.5421e-02, -1.2265e-02,  8.1660e-02,  2.9057e-02,  2.2213e-01,\n",
      "        -5.8041e-02, -1.1535e-02, -4.3470e-03, -7.4138e-02,  6.3249e-02,\n",
      "        -7.3912e-03, -1.1711e-01, -4.7634e-02, -4.7106e-02, -3.4812e-02,\n",
      "        -1.4923e-02,  5.7913e-02, -3.0943e-02, -2.4102e-02, -6.3130e-03,\n",
      "         8.1823e-02, -3.4265e-02,  8.4048e-02,  2.1579e-02, -4.7743e-02,\n",
      "        -7.0541e-02, -9.7231e-02,  3.3672e-02,  1.0045e-01,  5.7392e-03,\n",
      "        -1.2655e-02,  3.2022e-02, -1.1702e-02, -4.0795e-02,  1.2203e-02,\n",
      "         5.5855e-02, -1.2973e-02,  2.7965e-02, -3.3293e-02,  8.1654e-02,\n",
      "         5.0593e-03,  4.2876e-02, -9.6300e-02,  3.7924e-02,  6.6336e-02,\n",
      "         3.2018e-02,  2.2434e-02])\n",
      "trainable parameters: bert.encoder.layer.0.output.LayerNorm.weight tensor([1.0295, 1.0231, 1.0493, 1.0259, 1.0769, 1.0339, 1.0545, 0.9982, 0.8771,\n",
      "        1.0548, 1.0945, 1.0321, 1.0440, 1.0671, 1.0323, 1.0705, 1.0082, 1.0939,\n",
      "        1.0712, 1.0652, 1.0652, 1.0321, 1.0431, 0.7075, 1.0408, 0.9932, 1.0336,\n",
      "        1.0232, 1.0599, 1.0697, 1.0668, 0.8059, 0.9865, 1.0322, 1.0137, 1.0206,\n",
      "        1.0174, 0.9423, 1.0481, 1.0739, 1.0765, 0.9992, 1.0067, 1.0154, 1.0873,\n",
      "        1.0285, 1.0748, 1.0343, 1.0239, 0.8825, 1.0820, 1.0406, 1.0497, 1.0436,\n",
      "        1.0624, 1.0509, 1.0605, 1.0769, 1.0240, 1.0562, 1.0316, 1.0865, 1.0764,\n",
      "        1.0369, 1.0470, 1.0250, 1.0516, 1.0484, 1.0065, 1.0754, 1.1125, 1.0717,\n",
      "        0.9954, 1.0219, 1.0591, 1.0042, 1.0821, 1.1248, 1.0735, 1.0100, 0.9770,\n",
      "        1.0313, 1.0729, 1.0563, 1.0433, 1.0252, 1.0596, 1.0187, 1.0513, 1.0273,\n",
      "        1.0353, 1.0324, 1.0690, 1.0826, 1.0642, 1.0527, 1.0248, 1.0390, 1.0380,\n",
      "        1.0256, 1.0680, 1.0410, 1.0618, 1.0564, 1.0309, 1.0021, 1.0536, 1.0589,\n",
      "        1.0026, 1.0617, 1.0479, 1.0403, 1.0253, 1.0589, 0.9929, 1.0190, 1.0508,\n",
      "        1.0579, 1.0011, 0.9994, 0.9876, 0.5165, 1.0623, 1.0518, 1.0645, 1.0298,\n",
      "        1.0406, 1.0602, 1.0280, 1.0221, 0.9579, 1.0432, 1.0737, 1.0978, 0.6192,\n",
      "        1.0809, 0.9564, 1.0540, 1.0768, 1.0699, 1.0678, 1.0250, 1.0459, 1.0185,\n",
      "        1.0238, 1.0267, 0.9965, 1.0750, 0.9890, 1.0317, 1.0855, 1.0187, 1.0645,\n",
      "        1.0276, 1.0678, 1.0265, 0.9107, 0.9976, 1.0005, 1.0798, 1.0446, 1.0062,\n",
      "        1.0834, 1.0910, 1.0347, 1.0442, 0.9116, 1.0282, 1.0423, 0.9922, 1.0555,\n",
      "        0.8146, 1.0228, 1.0540, 1.0388, 0.9839, 1.0201, 1.0147, 1.0508, 1.0044,\n",
      "        1.0484, 1.0153, 1.0824, 0.9754, 1.0306, 1.0572, 1.0646, 1.0032, 0.9925,\n",
      "        1.0575, 1.0253, 1.0779, 1.0125, 0.5085, 1.0568, 1.0160, 0.9895, 1.0510,\n",
      "        1.0204, 1.0751, 1.0736, 1.0352, 1.0722, 0.9814, 1.0681, 1.0177, 1.0212,\n",
      "        0.9900, 1.0445, 1.0433, 1.0626, 1.0432, 1.0638, 1.0750, 1.0411, 1.0632,\n",
      "        1.0386, 1.0419, 0.9815, 1.0563, 0.9758, 1.0246, 1.0550, 1.0274, 1.0534,\n",
      "        1.0480, 1.0533, 1.0052, 1.0469, 1.0594, 1.0747, 1.0085, 1.0662, 1.0561,\n",
      "        1.0672, 1.0578, 1.0358, 0.9170, 1.0404, 1.0388, 1.0497, 0.9909, 1.0149,\n",
      "        0.8424, 1.0264, 1.0538, 1.0168, 1.0629, 1.0521, 1.0262, 1.0781, 1.0622,\n",
      "        1.0596, 1.0454, 1.0724, 1.0742, 0.9900, 1.0087, 0.9874, 1.0370, 0.9952,\n",
      "        1.0341, 0.4943, 1.0792, 1.0053, 1.0135, 1.0198, 1.0462, 1.1082, 1.0666,\n",
      "        1.0298, 1.0301, 1.0251, 1.0880, 1.0315, 0.7878, 0.8643, 1.0291, 1.0404,\n",
      "        1.0633, 1.0806, 1.0320, 1.0415, 1.0277, 1.0588, 1.0207, 1.0376, 1.0139,\n",
      "        1.0240, 1.0217, 0.9985, 1.0651, 0.9857, 1.0123, 1.0678, 1.0184, 1.0785,\n",
      "        0.8935, 1.0255, 1.0652, 1.1088, 1.0413, 1.0674, 1.0590, 1.0388, 1.0377,\n",
      "        1.0491, 1.0387, 1.0212, 1.0106, 1.0487, 1.0428, 1.0483, 1.0478, 1.0538,\n",
      "        1.0333, 1.0595, 1.0016, 1.0463, 1.0411, 1.0201, 1.0433, 1.0395, 1.0977,\n",
      "        1.0748, 1.0653, 1.0418, 1.0302, 0.6917, 1.0897, 1.0113, 1.0275, 1.0473,\n",
      "        1.0277, 0.8118, 1.0203, 1.0102, 1.0119, 1.0470, 1.0677, 1.0721, 1.0432,\n",
      "        1.0377, 1.0693, 1.0627, 1.0256, 1.0570, 1.0892, 1.0556, 1.0663, 0.7203,\n",
      "        1.0531, 1.0315, 1.0099, 1.0499, 1.0222, 1.1008, 1.0803, 1.0157, 1.0537,\n",
      "        1.0424, 1.0222, 1.0461, 1.0682, 1.0324, 1.0632, 1.0780, 1.0412, 1.0373,\n",
      "        1.0247, 1.0094, 1.0357, 1.1015, 1.0458, 1.0084, 0.9990, 1.0851, 1.0582,\n",
      "        1.0176, 1.0196, 1.0844, 1.0673, 1.0781, 1.0426, 1.0289, 1.0679, 0.7182,\n",
      "        1.0515, 1.0430, 1.0173, 1.0674, 1.0259, 1.0545, 1.0232, 1.0671, 1.0501,\n",
      "        1.0380, 1.0681, 1.0507, 1.0780, 1.0286, 1.0737, 1.0678, 1.0292, 0.9843,\n",
      "        1.0740, 1.0551, 1.0476, 1.0156, 1.0479, 1.0078, 1.0223, 1.0296, 1.0555,\n",
      "        1.0570, 1.0981, 1.0578, 1.0802, 1.0253, 1.0441, 1.0510, 0.7938, 1.0492,\n",
      "        0.9954, 0.9097, 1.0842, 1.0462, 1.0258, 1.0711, 1.0273, 1.0390, 1.0794,\n",
      "        0.9889, 1.0690, 0.9977, 0.9791, 1.0627, 1.0578, 1.0282, 1.0058, 1.0697,\n",
      "        0.9572, 1.0462, 1.0520, 0.5544, 1.0498, 0.8173, 1.0361, 1.0180, 1.0638,\n",
      "        1.0578, 1.0483, 1.0350, 0.9747, 0.7340, 1.0437, 1.0789, 1.0652, 1.0553,\n",
      "        1.0490, 1.0012, 1.0661, 1.0183, 0.8875, 1.0319, 0.9989, 1.0533, 1.0180,\n",
      "        1.0251, 0.7073, 0.9847, 1.0351, 1.0289, 1.0211, 0.9316, 1.0600, 1.0788,\n",
      "        1.0230, 1.0684, 1.0063, 1.0467, 1.0970, 1.0120, 1.0991, 1.0635, 1.0572,\n",
      "        1.0433, 1.0435, 1.0277, 1.0897, 0.9553, 1.0802, 0.9991, 1.0524, 1.0217,\n",
      "        1.0698, 1.0373, 0.9456, 1.0541, 1.0640, 0.9928, 1.0752, 1.0714, 0.9923,\n",
      "        1.0796, 1.0763, 0.9847, 0.9839, 1.0573, 1.0584, 1.0672, 1.0877])\n",
      "trainable parameters: bert.encoder.layer.0.output.LayerNorm.bias tensor([-7.6898e-02, -2.1598e-02,  2.0776e-02,  8.2926e-02, -6.4401e-03,\n",
      "         2.8873e-02, -3.7233e-02, -5.3179e-02,  1.2724e-01, -1.7728e-02,\n",
      "         4.6830e-02,  4.7809e-02,  2.8214e-02,  1.3409e-01, -6.4536e-03,\n",
      "        -2.9485e-02,  1.6137e-02,  3.6944e-02,  2.2526e-02,  4.7403e-02,\n",
      "         3.5974e-03,  6.2128e-02,  2.9911e-02,  1.7093e-01,  3.8048e-02,\n",
      "         1.3242e-01,  4.5502e-02, -2.0167e-02,  9.1877e-02,  1.9800e-03,\n",
      "        -9.5422e-03,  2.3891e-01,  7.3233e-02,  6.1897e-02, -3.6713e-02,\n",
      "        -3.8842e-02, -3.0479e-02,  3.9798e-02,  5.5011e-02,  9.2604e-02,\n",
      "         1.4804e-02,  2.8293e-02, -1.6972e-01, -4.0503e-02,  2.0551e-03,\n",
      "         7.1214e-02, -8.9523e-03,  1.9036e-02,  1.3386e-02, -5.6813e-02,\n",
      "         2.8649e-02, -2.2455e-02, -2.4961e-02, -1.9456e-02,  2.2038e-02,\n",
      "        -3.8281e-02,  6.6960e-02,  1.4725e-01, -1.9728e-02, -5.1516e-02,\n",
      "         2.4648e-02,  5.2947e-02, -6.6827e-02,  6.6240e-02, -5.3636e-02,\n",
      "         5.3083e-02,  1.6837e-02, -6.8602e-02, -2.2485e-02,  1.4289e-02,\n",
      "         6.6306e-04,  4.7262e-02, -2.2164e-02,  1.1948e-01, -4.4014e-02,\n",
      "         2.5750e-02,  3.5312e-03,  1.4547e-01, -8.0804e-02,  5.5222e-02,\n",
      "        -4.8926e-02,  3.1779e-03, -3.2427e-02,  1.2295e-02,  1.3002e-02,\n",
      "         5.0902e-05,  1.1493e-02,  2.8694e-02,  1.1382e-02,  3.4579e-02,\n",
      "         4.6654e-02,  8.7397e-02,  2.1468e-02, -1.4549e-02, -1.6396e-02,\n",
      "         5.2576e-02,  2.3607e-02, -1.7884e-02,  4.2225e-02,  5.6043e-02,\n",
      "         3.3468e-02,  2.8562e-02,  6.0357e-03,  3.0037e-02,  1.6544e-03,\n",
      "         1.0466e-01, -2.7909e-02, -4.3745e-03, -2.2857e-02,  5.4699e-02,\n",
      "        -2.6957e-02,  1.2749e-01,  1.1709e-01,  4.6771e-02,  1.7900e-01,\n",
      "        -2.8270e-02,  4.1006e-02,  9.6315e-02,  8.4901e-02, -9.8071e-02,\n",
      "         3.4453e-02,  1.7470e-01,  7.3096e-03,  1.8933e-02,  6.2969e-02,\n",
      "         8.3229e-02,  2.7591e-02,  4.2106e-02, -2.1779e-02, -3.7040e-02,\n",
      "        -2.9105e-02,  3.5496e-02,  5.7037e-02,  4.3471e-03, -4.9921e-02,\n",
      "         4.7772e-04, -6.1066e-01, -3.6684e-02,  6.3271e-03, -3.7695e-02,\n",
      "         1.2656e-02,  1.0770e-01,  6.7272e-02,  9.8325e-03, -8.0366e-02,\n",
      "         2.3354e-03,  2.4323e-02,  4.6255e-02,  1.6607e-02,  3.7114e-02,\n",
      "        -1.0269e-02,  7.1530e-02, -9.3920e-03,  3.9820e-02, -2.8291e-02,\n",
      "         6.0188e-02, -3.9455e-03,  1.2583e-01, -1.5549e-02, -2.3288e-02,\n",
      "         1.1309e-01,  1.1278e-01,  4.7377e-02, -8.3970e-02,  5.1019e-02,\n",
      "        -9.0246e-03, -7.7729e-02, -6.2276e-02,  4.5629e-02,  1.4324e-02,\n",
      "         3.5442e-02, -1.6642e-01, -4.1184e-02, -8.5565e-04, -1.7954e-03,\n",
      "        -1.6172e-02, -1.1601e-02,  4.0046e-02, -7.2393e-02,  1.1847e-01,\n",
      "         6.6816e-02, -6.1189e-02, -4.6328e-02,  7.4694e-02, -3.7913e-02,\n",
      "        -9.4788e-02,  6.5856e-03,  5.0076e-02,  6.5278e-02,  2.0729e-02,\n",
      "         6.2861e-02, -1.6794e-02, -3.4613e-02,  3.6687e-01,  7.9372e-02,\n",
      "        -3.6362e-02,  3.5987e-02, -3.6899e-02,  7.0570e-02, -5.2319e-02,\n",
      "         1.7137e-02,  9.7212e-03,  9.2461e-02,  6.1080e-02,  2.1074e-02,\n",
      "         4.9468e-03,  6.1087e-03,  4.6684e-02,  1.1778e-02, -8.8461e-02,\n",
      "        -2.6735e-02, -2.2506e-02, -3.3728e-02, -2.7579e-03,  1.3735e-01,\n",
      "        -2.7420e-02, -3.7328e-02, -5.9102e-03,  7.4752e-02,  1.9067e-02,\n",
      "        -1.5610e-01,  2.3022e-02,  4.4037e-02,  8.9207e-02, -2.4214e-02,\n",
      "        -9.2409e-02,  7.0684e-02, -5.3472e-02, -7.8517e-02,  6.0142e-02,\n",
      "         3.4680e-02,  9.3432e-02, -7.8203e-02,  6.7538e-02,  2.2558e-02,\n",
      "         2.0643e-03,  3.5693e-02,  1.1277e-01,  2.6047e-02,  5.3084e-02,\n",
      "        -2.2105e-02,  2.6980e-02,  6.1528e-02, -2.6779e-02, -2.2994e-02,\n",
      "         2.7057e-02, -6.0577e-02,  7.3944e-02, -4.2458e-02,  3.2515e-02,\n",
      "         3.7285e-02, -8.3656e-02,  2.2911e-02,  5.9172e-02,  1.8832e-02,\n",
      "         2.2290e-02,  1.7667e-02, -8.2473e-02, -4.6857e-02, -1.1758e-02,\n",
      "         2.6862e-03,  1.1364e-01,  4.7289e-02, -6.5940e-02, -2.8112e-02,\n",
      "         5.4023e-02, -4.9053e-02,  4.8493e-02, -6.5311e-02,  6.4669e-02,\n",
      "         3.5402e-02,  2.9980e-02, -4.0136e-02, -4.4313e-02,  7.7567e-02,\n",
      "        -2.4643e-01, -2.7457e-01,  5.2517e-03,  9.5909e-02, -1.7394e-02,\n",
      "        -7.9668e-02,  1.0925e-02, -5.1439e-02, -3.2390e-02,  1.0928e-01,\n",
      "        -6.0803e-03,  3.7242e-02,  2.0278e-03, -7.8545e-02,  1.2798e-02,\n",
      "         7.5338e-02,  6.4858e-02, -1.4090e-02,  8.1926e-02,  4.8635e-02,\n",
      "        -2.2903e-02, -5.1527e-02,  3.6152e-02, -7.4041e-02,  7.7188e-02,\n",
      "        -1.9737e-02,  4.3345e-02,  9.4626e-02, -3.3040e-02, -1.1442e-02,\n",
      "        -4.0699e-03,  8.1114e-02,  3.7756e-02,  2.6199e-02, -5.8546e-02,\n",
      "         1.2688e-01,  1.0725e-01,  4.6814e-02,  8.2683e-02,  9.4158e-02,\n",
      "         6.3237e-03, -7.8504e-02,  6.2282e-02,  1.2619e-02,  3.1878e-02,\n",
      "         5.4484e-02, -8.2782e-02,  2.9801e-02,  3.7157e-02, -1.0532e-02,\n",
      "        -7.7536e-03, -1.9857e-02,  8.5826e-02,  9.4705e-02,  6.0285e-02,\n",
      "        -5.8786e-03,  1.0906e-01,  6.0185e-03, -5.0823e-02, -2.6425e-02,\n",
      "        -5.3035e-02, -3.3581e-02,  8.8832e-02,  1.8169e-02, -3.9014e-02,\n",
      "        -1.4618e-02, -3.9109e-02, -2.6883e-02,  2.6644e-02,  3.6626e-02,\n",
      "        -2.9981e-02, -8.0491e-03,  4.0034e-03, -6.2216e-02, -6.1254e-02,\n",
      "         2.2064e-01, -8.8301e-02,  3.1271e-02,  2.2282e-02, -1.2780e-01,\n",
      "         6.4529e-02,  2.5073e-01, -3.9136e-02, -2.3466e-02,  1.1379e-02,\n",
      "         4.8345e-04,  7.0000e-03, -1.8083e-02, -2.4352e-02, -3.7653e-02,\n",
      "        -2.1036e-02,  3.7148e-02,  1.1625e-01,  1.7357e-02,  6.1211e-02,\n",
      "        -5.3047e-02, -1.8531e-03,  3.1053e-02, -2.0436e-02, -5.8660e-02,\n",
      "         9.1110e-02, -2.8099e-02,  5.7151e-02, -1.3953e-03,  1.1525e-01,\n",
      "        -2.5654e-02,  4.7562e-03,  3.8902e-03, -5.5650e-02, -5.2240e-02,\n",
      "        -4.4458e-02,  2.3323e-01, -6.5320e-02, -4.5255e-02, -2.7421e-03,\n",
      "        -7.3420e-02, -1.9187e-03,  3.5631e-02, -8.7036e-02, -7.4391e-02,\n",
      "         2.9318e-02,  1.6890e-02, -1.4788e-02,  5.9195e-02, -3.9931e-03,\n",
      "        -3.6287e-02,  2.7858e-02,  6.6688e-02,  2.8891e-02, -1.0143e-01,\n",
      "        -4.0012e-02,  4.2539e-03,  6.5553e-02, -7.4710e-03, -5.9373e-02,\n",
      "        -6.4947e-02,  4.5729e-02, -2.3900e-02,  8.2037e-03, -4.2775e-02,\n",
      "        -3.6852e-02,  4.4777e-02,  2.7551e-02,  2.9033e-02, -6.8897e-02,\n",
      "        -1.3815e-02,  1.4222e-01,  4.5060e-02, -8.1677e-02,  1.0154e-01,\n",
      "        -8.4798e-02,  2.0840e-02,  5.4931e-02, -3.9871e-02, -1.4801e-01,\n",
      "        -2.4207e-02, -4.1493e-02,  1.3306e-02,  1.2767e-03,  6.5871e-02,\n",
      "        -5.8168e-02, -1.8027e-01,  9.7558e-02,  8.0188e-03,  1.4597e-01,\n",
      "         9.8407e-03,  5.1202e-02,  4.9299e-02,  1.0874e-01,  1.2514e+00,\n",
      "         7.0727e-02,  1.8231e-01,  4.7346e-02, -4.2967e-02,  5.8860e-02,\n",
      "        -7.9058e-02,  1.1371e-03, -1.2825e-02, -1.0870e-01, -2.8077e-02,\n",
      "         2.3407e-02,  2.5537e-02,  7.9294e-02, -4.9029e-02,  5.6652e-03,\n",
      "         1.1575e-02, -1.7669e-02,  1.1287e-01, -9.7114e-02,  2.5295e-02,\n",
      "         1.2663e-01, -1.6842e-02, -4.6637e-02, -4.1712e-02,  6.3853e-02,\n",
      "         8.5783e-02,  4.1267e-02, -4.6452e-02,  5.7759e-02,  1.5904e-01,\n",
      "         7.8994e-03, -3.1979e-02, -8.8309e-05,  4.0212e-02,  3.1109e-02,\n",
      "        -3.1226e-02,  5.0487e-02,  4.4461e-02, -3.4391e-02,  3.0778e-02,\n",
      "         5.8903e-02, -2.9665e-02, -1.0600e-02,  9.2606e-03,  1.7026e-02,\n",
      "         1.0151e-01, -6.2253e-02, -5.4425e-02,  8.1303e-02, -2.4679e-02,\n",
      "         2.7364e-02,  9.5735e-02,  2.1431e-01,  6.9692e-02,  4.2386e-02,\n",
      "         1.0149e-02, -2.3402e-02, -5.1348e-02, -8.5895e-02, -8.2025e-03,\n",
      "        -1.1780e-02, -5.5620e-02, -1.1116e-01, -3.8392e-02,  9.6567e-02,\n",
      "        -4.3926e-03, -4.7284e-03])\n",
      "trainable parameters: bert.encoder.layer.1.attention.self.query.weight tensor([[-0.0224,  0.0820, -0.0108,  ...,  0.0063,  0.0079,  0.0471],\n",
      "        [-0.0196, -0.0592, -0.0532,  ...,  0.0111,  0.0283,  0.0101],\n",
      "        [-0.0090, -0.0002, -0.0881,  ..., -0.0654,  0.0542, -0.0025],\n",
      "        ...,\n",
      "        [-0.0221,  0.0673, -0.0317,  ...,  0.0486, -0.0242, -0.0057],\n",
      "        [-0.0427,  0.0141,  0.0036,  ...,  0.0151, -0.0022, -0.0513],\n",
      "        [-0.0641, -0.0034,  0.0192,  ...,  0.0118,  0.0424, -0.0521]])\n",
      "trainable parameters: bert.encoder.layer.1.attention.self.query.bias tensor([-6.4413e-03,  9.8964e-02, -7.5424e-03,  5.5024e-02,  6.5489e-02,\n",
      "        -6.7446e-02, -2.7451e-02,  3.3870e-02,  8.6893e-02, -4.2157e-02,\n",
      "        -6.0731e-02, -3.5651e-03,  1.3311e-02, -2.4789e-02, -4.4557e-02,\n",
      "        -1.5378e-02,  2.4330e-02, -8.0341e-02, -1.0027e-02,  5.8621e-02,\n",
      "         5.7527e-02, -7.1246e-02, -3.6864e-03,  3.7886e-02, -3.2345e-02,\n",
      "        -1.9461e-02,  9.0653e-03,  4.7313e-02,  1.0659e-02,  5.1041e-02,\n",
      "        -6.9075e-04,  2.4365e-02, -1.6273e-02,  8.0018e-03,  3.9278e-02,\n",
      "         2.0535e-02,  3.0743e-02, -8.1839e-03, -8.9687e-02,  6.6607e-02,\n",
      "         4.2140e-02, -2.9585e-02, -7.9892e-02, -4.1455e-04, -2.1144e-02,\n",
      "        -3.9149e-03,  1.7878e-02, -5.5493e-03, -2.0305e-02, -2.2100e-02,\n",
      "         5.7278e-02,  1.2766e-02,  3.7615e-03, -7.9399e-02, -9.0821e-03,\n",
      "         8.5112e-03,  4.0033e-02,  2.1518e-02,  3.6954e-02, -6.4291e-02,\n",
      "         3.7991e-02,  1.6739e-02, -1.4677e-01,  1.0047e-02,  1.0213e-02,\n",
      "        -8.9570e-02, -6.8973e-02, -7.6205e-02, -1.7249e-02,  1.6775e-01,\n",
      "        -2.7800e-02, -2.0241e-02, -1.3874e-01,  1.8531e-01,  1.4439e-01,\n",
      "        -1.7807e-01, -1.7646e-01,  1.2676e-01, -5.1113e-02,  1.7551e-02,\n",
      "        -8.2763e-02, -1.1054e-01,  2.6407e-02,  3.7802e-02,  1.3003e-02,\n",
      "        -2.4600e-01,  7.5668e-02, -6.4871e-02,  9.7345e-02, -1.2762e-01,\n",
      "        -3.0111e-02, -2.1160e-01, -1.4269e-01, -1.6960e-01,  2.4021e-01,\n",
      "        -1.3254e-01,  1.4091e-01, -1.6057e-01,  2.6391e-02, -7.9078e-02,\n",
      "        -4.4859e-02, -2.3820e-02, -1.4008e-01, -7.3018e-02, -7.6383e-02,\n",
      "        -7.3890e-02, -1.5138e-01,  5.5086e-02, -2.1765e-02, -9.0949e-02,\n",
      "         8.2006e-02,  1.6049e-01, -1.3741e-01, -1.1774e-01,  9.8545e-02,\n",
      "         1.0248e-01, -6.8123e-02, -8.1729e-02,  8.4460e-02,  2.5662e-01,\n",
      "        -1.1310e-04, -8.8921e-02, -7.7224e-03,  6.0812e-02,  1.2228e-02,\n",
      "         3.9947e-02, -1.6231e-01,  4.1278e-02, -7.0736e-02,  8.6182e-02,\n",
      "        -5.0040e-02,  3.6183e-02,  1.1144e-01, -6.8718e-02, -2.2647e-01,\n",
      "         2.1214e-02, -2.0048e-01, -1.8407e-02, -3.8015e-02, -2.2412e-01,\n",
      "         1.2043e-01,  1.4387e-02,  6.9208e-02,  2.2899e-01, -6.2544e-02,\n",
      "         9.8606e-02, -6.4329e-02, -1.5058e-01, -2.1116e-01,  1.1878e-01,\n",
      "         3.3503e-02,  2.6470e-02,  1.0921e-01, -1.7266e-01, -1.1368e-01,\n",
      "         4.8045e-02, -2.3474e-01, -1.3665e-01, -3.5110e-02, -2.1502e-01,\n",
      "         2.6086e-02, -4.5482e-02, -2.4211e-02,  7.1276e-02, -5.9592e-02,\n",
      "        -8.0405e-02, -1.1730e-01, -4.2965e-02,  1.3924e-01,  2.0439e-01,\n",
      "        -1.0637e-01,  3.2219e-02, -2.4609e-02,  1.2990e-01, -1.2314e-01,\n",
      "         4.1818e-02, -7.1103e-02,  4.5771e-02, -6.7976e-02, -3.5237e-03,\n",
      "        -7.1025e-02,  1.9654e-01, -6.1464e-02, -1.2933e-01, -1.3505e-01,\n",
      "         6.9042e-02, -3.6486e-02, -1.6169e-01,  9.7553e-02,  4.9326e-02,\n",
      "         7.4024e-02,  1.2349e-02, -5.1631e-02, -4.5203e-02,  1.2484e-01,\n",
      "        -1.9166e-01,  1.9964e-01,  7.1407e-02,  3.1866e-02,  3.1246e-02,\n",
      "         1.5771e-01, -1.6005e-01,  1.0169e-01,  1.0106e-02,  6.5299e-02,\n",
      "         3.0050e-02, -9.4651e-03,  1.4123e-01,  1.3606e-01, -1.2832e-02,\n",
      "        -5.8248e-02, -2.5483e-02, -2.4594e-01,  7.5472e-02,  9.7702e-02,\n",
      "         1.6884e-01, -7.5662e-02,  6.5882e-02, -1.5202e-01, -7.0509e-02,\n",
      "         4.2682e-02, -9.9492e-02,  8.6590e-02,  6.5052e-03, -1.6251e-01,\n",
      "        -1.2738e-01, -7.0412e-02, -6.3077e-02, -8.3906e-02, -9.6508e-02,\n",
      "         8.8475e-02,  1.3830e-01, -1.2278e-01,  4.1633e-03,  1.5025e-01,\n",
      "        -1.5423e-01,  6.5256e-02,  9.4156e-02, -1.5150e-01,  1.1308e-01,\n",
      "         2.8662e-02,  3.8648e-02,  1.4438e-01, -1.8065e-02, -2.3217e-02,\n",
      "         1.7223e-01, -1.1268e-01, -1.4644e-01, -1.2772e-01,  1.5379e-01,\n",
      "         1.3075e-01,  1.6039e-01, -7.3194e-02,  5.2088e-02, -6.8639e-02,\n",
      "         3.0829e-02, -5.6458e-02,  7.8808e-02,  4.4003e-03, -1.4727e-01,\n",
      "         7.6901e-02, -2.3365e-01, -2.2577e-02, -1.3554e-01,  5.7350e-02,\n",
      "        -7.8166e-02, -2.6489e-01, -2.1462e-02, -1.5242e-01,  1.5279e-01,\n",
      "        -6.0530e-02,  5.4501e-02,  1.6420e-01, -1.6761e-01,  9.2933e-02,\n",
      "        -4.1571e-02, -2.0530e-01,  1.5909e-01,  6.4582e-02,  5.5450e-02,\n",
      "        -2.1163e-02,  1.8916e-01, -5.8858e-02, -1.6933e-01, -5.2921e-02,\n",
      "        -6.2918e-02, -5.1809e-02,  2.1461e-02,  1.7035e-01, -1.0806e-01,\n",
      "         8.8863e-02, -1.1013e-01, -1.2360e-03,  1.2905e-01, -5.0350e-02,\n",
      "        -1.3970e-01, -1.0462e-01, -9.2018e-02, -1.9915e-02, -1.3839e-01,\n",
      "        -9.8283e-03, -1.5579e-01,  1.7610e-01,  2.2536e-02, -8.7341e-02,\n",
      "        -1.6239e-01,  7.9973e-03, -5.8664e-02,  1.4603e-01,  1.7399e-01,\n",
      "         1.0918e-01,  9.2768e-02, -2.5487e-01, -1.4076e-01, -2.5230e-01,\n",
      "        -8.0593e-02, -2.3013e-01, -1.4668e-01, -1.1780e-01,  1.5909e-02,\n",
      "        -1.0257e-02, -7.3424e-02,  2.0090e-02,  9.7659e-02,  1.4712e-02,\n",
      "        -8.1121e-02,  9.5631e-02,  4.2936e-02, -3.2975e-02, -3.2394e-04,\n",
      "         8.3046e-02,  5.0790e-02,  1.7116e-02, -6.9020e-02,  4.9635e-02,\n",
      "        -2.0966e-02, -5.6007e-02,  5.9857e-02,  7.6914e-03,  2.4928e-02,\n",
      "         5.5572e-02, -5.3266e-02,  5.6904e-02, -1.3989e-02, -8.6092e-02,\n",
      "         2.2412e-02,  1.2219e-01,  4.4849e-02,  4.5322e-02,  1.4385e-02,\n",
      "         1.3411e-01,  6.5524e-02,  3.8779e-02, -4.2690e-02, -2.2550e-02,\n",
      "        -1.5669e-01,  1.1349e-01, -8.7453e-02,  2.3928e-02, -1.7063e-02,\n",
      "         4.1669e-02,  8.1923e-02, -8.5998e-03,  1.9957e-02,  3.7225e-02,\n",
      "        -2.9763e-02, -1.0320e-02,  1.2845e-01, -6.9300e-03,  2.5712e-02,\n",
      "        -1.1416e-01, -6.7605e-02, -1.1639e-01, -2.6252e-03,  9.9341e-03,\n",
      "         5.9810e-03,  3.0463e-02,  1.6228e-02, -1.7207e-03,  7.8110e-03,\n",
      "        -9.2872e-03,  2.9911e-02, -2.5420e-02,  7.8314e-03,  8.8509e-02,\n",
      "         1.3203e-01,  9.0477e-02,  2.3817e-01,  2.6246e-01,  2.4084e-01,\n",
      "        -4.1228e-02, -1.3786e-02,  2.2725e-01, -2.1654e-01,  3.6398e-01,\n",
      "         2.3997e-01,  7.2171e-02,  3.4982e-01,  3.3301e-02,  8.7283e-02,\n",
      "        -1.7249e-01,  3.3420e-01,  8.0163e-02, -5.7849e-02,  1.4390e-01,\n",
      "        -3.2487e-02,  2.2853e-02, -1.0579e-01,  1.4437e-01, -3.8741e-03,\n",
      "        -1.4356e-01, -4.9852e-02,  1.0765e-01,  8.7182e-02,  2.8873e-01,\n",
      "         1.5580e-01, -1.9351e-02, -1.2793e-01, -2.5441e-02, -1.6925e-03,\n",
      "        -1.3920e-01,  7.0758e-02,  1.2336e-01,  1.9031e-01, -1.6878e-01,\n",
      "         1.2715e-01, -5.4699e-02, -1.3348e-01,  1.4376e-01, -2.3142e-01,\n",
      "         2.9214e-01, -2.4954e-01, -3.6923e-01,  1.2599e-01,  3.7043e-02,\n",
      "        -2.1964e-01,  6.5338e-02,  2.1681e-02, -3.5245e-01,  1.4575e-01,\n",
      "         3.0291e-02,  2.6754e-01,  3.0486e-01,  2.5618e-01,  1.9046e-03,\n",
      "         1.9330e-01, -2.3514e-01,  1.2837e-01,  6.5734e-02, -1.1270e-01,\n",
      "        -1.8864e-01, -9.4289e-02,  1.1496e-01, -7.1460e-02, -1.6234e-01,\n",
      "         4.2961e-02, -1.5725e-02, -1.5557e-01,  5.1220e-02, -1.4936e-01,\n",
      "        -1.1704e-01, -2.1506e-01,  9.4144e-04,  8.8992e-02,  9.8551e-02,\n",
      "        -2.7087e-01, -2.0003e-01, -3.3357e-01,  2.2735e-01, -7.7022e-02,\n",
      "         4.8831e-02,  1.1928e-01, -3.0174e-02, -1.8053e-01, -3.7184e-01,\n",
      "         9.1472e-02,  2.9966e-01,  1.3605e-03, -1.3096e-01,  1.5538e-02,\n",
      "         2.1208e-01, -1.9880e-01,  1.7289e-02,  2.9623e-01, -4.1584e-02,\n",
      "         2.5416e-01,  9.5650e-02,  1.5207e-02, -7.5991e-02, -1.3845e-01,\n",
      "        -2.4552e-01,  7.6155e-02,  2.2117e-01,  2.2240e-01,  1.9652e-01,\n",
      "         1.6788e-02,  2.8429e-01, -8.3493e-02, -2.0288e-01,  1.0022e-01,\n",
      "         8.0043e-02,  1.0578e-01,  2.4315e-01,  7.3066e-02,  2.0243e-01,\n",
      "        -2.4419e-01,  1.0748e-01, -1.5483e-01, -1.4288e-01,  3.3406e-02,\n",
      "         2.5141e-01,  8.6534e-02])\n",
      "trainable parameters: bert.encoder.layer.1.attention.self.key.weight tensor([[ 0.0002, -0.0509,  0.0262,  ..., -0.0120, -0.0289, -0.0461],\n",
      "        [ 0.0473, -0.0550,  0.0497,  ..., -0.0128, -0.0964, -0.0872],\n",
      "        [-0.0502, -0.0555,  0.0214,  ...,  0.0010, -0.0494,  0.0249],\n",
      "        ...,\n",
      "        [-0.0014,  0.0734,  0.0296,  ...,  0.0646, -0.0267,  0.1188],\n",
      "        [ 0.0258,  0.0106, -0.0633,  ..., -0.0356,  0.0762, -0.0015],\n",
      "        [-0.0003, -0.0224,  0.0457,  ..., -0.0595, -0.0543, -0.0130]])\n",
      "trainable parameters: bert.encoder.layer.1.attention.self.key.bias tensor([-6.2835e-03,  8.9905e-03, -4.3575e-02, -4.5035e-02,  1.8895e-02,\n",
      "         6.3034e-04, -2.7765e-02,  2.1509e-02, -8.6544e-03, -1.6887e-02,\n",
      "         2.8395e-03,  2.1256e-02, -2.5340e-02, -6.5205e-03, -2.5020e-02,\n",
      "         2.7114e-03,  3.1637e-02,  2.6797e-03,  1.7831e-02, -9.1362e-03,\n",
      "         1.4499e-02, -8.1546e-03,  2.3169e-02, -1.4706e-02, -2.9048e-02,\n",
      "         2.0407e-02, -1.2026e-03,  8.2882e-02, -1.5727e-02,  1.2240e-02,\n",
      "         5.1947e-04, -8.2255e-02,  8.0159e-04,  5.6218e-02,  1.4109e-02,\n",
      "         3.5172e-02,  1.7941e-02,  6.5662e-02,  5.2189e-02, -1.4520e-03,\n",
      "        -3.4042e-02,  6.4421e-03, -6.7636e-03, -1.2247e-02,  4.3243e-03,\n",
      "         3.4491e-02, -3.8045e-02, -2.8730e-02, -6.5142e-03,  1.2205e-02,\n",
      "        -1.1312e-03, -4.6727e-03, -5.0215e-03, -1.4796e-02, -1.4549e-02,\n",
      "        -7.9812e-02, -1.9462e-02, -3.2008e-02, -1.4511e-02,  2.3484e-03,\n",
      "        -5.1851e-02, -5.3501e-03,  7.2776e-03, -2.8059e-03, -2.7273e-02,\n",
      "         3.1230e-02, -1.1474e-02, -2.0834e-03,  4.0485e-04,  2.4832e-02,\n",
      "         1.2668e-02, -1.0394e-02, -2.1578e-02,  3.5292e-02,  6.5639e-03,\n",
      "        -1.6300e-02, -1.8129e-02,  2.8511e-02, -2.0028e-02, -1.5928e-03,\n",
      "        -1.0938e-03, -8.1107e-03, -7.8041e-03,  4.7637e-02,  6.7304e-04,\n",
      "        -2.6842e-02,  8.2838e-03,  1.4049e-02, -1.6936e-02, -6.2080e-03,\n",
      "         3.7679e-02,  2.0829e-03, -2.7506e-03, -5.7669e-02, -6.2911e-02,\n",
      "        -5.0059e-02, -5.2514e-05, -8.9535e-03, -4.8577e-02, -4.4367e-03,\n",
      "         5.5035e-02, -8.7821e-03, -3.1324e-03,  4.4251e-03,  5.0748e-02,\n",
      "        -1.2423e-02, -5.3860e-03, -6.6423e-03, -4.7341e-02,  8.7301e-03,\n",
      "        -2.0214e-04,  2.4042e-02, -1.8993e-02, -9.8108e-03,  1.7621e-02,\n",
      "         2.2165e-02, -1.9043e-02,  4.5252e-02, -2.4751e-02,  9.6996e-03,\n",
      "         6.0474e-03, -3.2516e-02,  3.2196e-02,  3.9659e-02, -4.5840e-03,\n",
      "        -4.9768e-02,  5.2647e-03, -2.8324e-03, -5.1425e-02, -2.5686e-02,\n",
      "         1.0950e-02,  1.6925e-03, -2.8258e-02,  2.0749e-02,  1.5404e-02,\n",
      "        -3.0293e-02,  9.0360e-03, -2.3180e-02,  1.8971e-02,  3.4535e-02,\n",
      "         1.7368e-02,  2.2520e-02,  3.2043e-02, -1.5084e-03,  2.3404e-02,\n",
      "         3.8191e-05, -2.0158e-02,  2.1671e-02,  3.7240e-03, -3.3511e-02,\n",
      "        -1.5817e-02, -7.8653e-03,  1.3263e-02, -2.0050e-02, -5.2392e-03,\n",
      "        -1.0867e-02,  3.9646e-03,  4.2296e-02, -1.6255e-02, -1.9216e-02,\n",
      "        -3.5319e-02,  5.0942e-02,  4.5797e-02,  1.2959e-02,  2.4132e-02,\n",
      "         1.4733e-02,  2.9930e-02, -6.4624e-02,  1.2429e-02, -7.0308e-02,\n",
      "        -2.2761e-02, -2.7872e-02, -1.0122e-02,  4.5482e-03, -7.5036e-03,\n",
      "         6.0878e-03,  1.2747e-03, -1.6928e-02, -3.6951e-02,  1.8288e-02,\n",
      "         2.1515e-02,  7.8427e-03,  2.9336e-03,  2.4583e-03, -1.6521e-02,\n",
      "         1.9890e-03,  4.7379e-02,  6.6170e-02, -1.0716e-02,  2.8764e-03,\n",
      "         3.5828e-02,  2.0081e-02,  2.8747e-02, -2.7877e-02, -3.3556e-02,\n",
      "         2.9360e-02, -7.2276e-02, -2.4761e-02, -5.4722e-03,  3.8415e-02,\n",
      "        -3.3937e-02,  4.1185e-02, -5.1763e-02, -5.7587e-02,  2.5000e-03,\n",
      "         2.0663e-03,  1.6174e-02,  2.2804e-02,  3.2592e-03, -4.6329e-02,\n",
      "         9.5078e-04, -3.3447e-02,  7.5429e-03, -4.2948e-02, -7.3664e-02,\n",
      "         2.1035e-02,  2.5987e-02, -5.4097e-02,  1.7513e-02,  6.7513e-02,\n",
      "         3.7913e-02, -1.8184e-02, -5.8340e-03,  6.1231e-03,  4.4311e-02,\n",
      "         5.1790e-03,  2.1883e-02, -4.0057e-02,  1.0923e-03, -1.6246e-02,\n",
      "         1.1586e-02,  2.8704e-02, -1.6433e-02,  1.4769e-02,  2.0695e-03,\n",
      "         4.3736e-02, -7.0453e-03,  4.0182e-02,  4.2159e-02, -5.6043e-02,\n",
      "        -1.9577e-02, -3.8105e-02, -4.7701e-02, -3.7874e-03, -1.4157e-02,\n",
      "        -5.1235e-02,  1.2708e-02, -2.3909e-02,  3.1268e-02, -7.5768e-02,\n",
      "         3.1109e-02, -2.9492e-02,  4.0302e-02,  2.1355e-03, -2.2057e-02,\n",
      "         4.7935e-03, -4.6120e-02, -4.8975e-02, -4.0332e-02,  1.5256e-02,\n",
      "         4.7994e-03, -2.7097e-02, -6.9302e-02,  1.0483e-02, -2.2266e-02,\n",
      "        -1.4352e-02, -4.1214e-02, -2.8732e-02, -2.1868e-02,  1.2095e-02,\n",
      "         1.3356e-02,  2.6689e-02,  1.3216e-02, -2.6465e-02, -2.0772e-02,\n",
      "         4.0256e-03,  6.1302e-03,  8.1685e-02,  1.1819e-02, -4.3201e-02,\n",
      "        -4.3822e-03,  3.6363e-02,  1.2214e-02,  3.8679e-02, -2.3181e-02,\n",
      "         2.8496e-02,  1.8823e-02, -2.1650e-02,  1.2246e-02,  2.4532e-02,\n",
      "         2.3464e-02,  2.7095e-02,  8.7416e-03,  3.2218e-02,  4.2649e-02,\n",
      "        -1.0057e-02, -2.1096e-02,  3.0414e-02,  1.7997e-02, -4.9642e-02,\n",
      "         1.9147e-02, -1.1822e-02,  2.3829e-03,  1.9832e-02,  7.0851e-02,\n",
      "        -8.3866e-03,  1.8700e-02, -5.4830e-02,  2.6085e-02,  3.3225e-02,\n",
      "         1.9755e-02,  6.4044e-02, -4.9756e-02, -8.0170e-03, -5.6246e-02,\n",
      "        -4.4163e-02, -2.7517e-03, -5.0282e-02, -2.8037e-02,  4.9471e-02,\n",
      "        -3.2156e-02,  2.7117e-02, -8.1951e-03,  1.6077e-03,  2.4706e-02,\n",
      "        -2.4955e-03,  1.7029e-02,  1.0245e-02, -1.1361e-02, -2.1354e-02,\n",
      "        -6.1679e-03, -2.1860e-02,  2.9686e-02,  2.4777e-02, -2.2189e-05,\n",
      "        -7.9536e-03,  6.4158e-03,  3.5932e-02,  1.1248e-02, -8.6443e-03,\n",
      "         6.1226e-03,  1.0026e-03,  2.8563e-02, -1.1541e-02,  1.4657e-03,\n",
      "         2.2781e-02, -3.3359e-02, -1.4195e-02, -7.4242e-03,  1.4035e-02,\n",
      "         1.1329e-04, -2.8715e-02,  1.5307e-02,  3.4642e-02, -1.1604e-02,\n",
      "        -9.2971e-03, -1.4480e-02,  2.0354e-02,  4.5028e-02,  1.1072e-03,\n",
      "        -1.6441e-02,  2.4579e-02,  2.8736e-02, -3.0938e-02,  1.4416e-02,\n",
      "         2.1364e-02,  1.4886e-02,  2.4038e-02, -1.2901e-02,  3.5864e-02,\n",
      "         1.8102e-02, -4.4957e-03, -2.1623e-03,  1.0667e-02,  4.3133e-03,\n",
      "         1.0962e-02,  6.8904e-03,  1.4687e-02,  9.7746e-03,  4.0679e-03,\n",
      "         3.9750e-03,  4.9398e-03,  1.3847e-03, -4.5472e-03,  9.2623e-02,\n",
      "        -6.3731e-04,  2.6298e-02, -7.2152e-02, -2.0069e-03, -1.6085e-02,\n",
      "        -4.4078e-02, -2.4799e-02, -2.0198e-03, -2.3305e-02, -2.5162e-02,\n",
      "        -2.8548e-02, -9.6851e-02,  3.3733e-02, -1.0237e-01,  4.1651e-02,\n",
      "         1.1217e-01,  1.9307e-02,  2.1866e-03,  1.7203e-02,  8.8871e-04,\n",
      "        -2.5634e-02, -2.7991e-02, -9.8872e-03, -6.0497e-02,  8.3501e-03,\n",
      "        -2.1105e-02, -2.6764e-02,  3.5208e-02,  9.3845e-03,  1.1789e-02,\n",
      "         3.2855e-02, -2.4588e-02, -3.9528e-02,  3.9114e-02, -5.5285e-02,\n",
      "         2.8910e-02, -6.4170e-02,  2.2595e-02,  9.6509e-03,  9.9532e-05,\n",
      "        -5.1384e-02,  4.5248e-03, -1.8130e-02,  1.5256e-02,  9.7672e-02,\n",
      "        -1.4062e-02,  3.2671e-02,  4.2575e-02,  8.3690e-05, -2.2101e-02,\n",
      "         1.1230e-02, -2.0791e-03,  3.0307e-03,  1.8685e-02,  4.2426e-02,\n",
      "         5.5273e-02, -3.8494e-02, -7.1408e-02, -3.4900e-02,  2.8449e-02,\n",
      "         1.2893e-02,  6.4510e-02,  1.5134e-02, -4.3223e-02, -4.5898e-02,\n",
      "         3.1960e-03, -2.0972e-02,  8.1332e-03, -3.9139e-02,  2.8910e-03,\n",
      "         2.4431e-03,  8.4023e-03, -1.3634e-03,  3.6796e-03,  4.2264e-02,\n",
      "        -1.3228e-02,  2.2835e-02, -2.6347e-02,  1.9161e-02, -8.0845e-03,\n",
      "        -2.5228e-02, -4.1902e-03, -4.4084e-03, -2.8560e-02,  4.5785e-03,\n",
      "         2.6541e-03,  2.0854e-02, -3.2010e-02,  1.7809e-04, -5.7324e-03,\n",
      "        -4.9005e-02, -9.0558e-03, -3.0363e-02,  3.2673e-02, -3.1649e-02,\n",
      "         2.5836e-02,  1.6647e-02,  3.4495e-03, -2.5591e-02, -1.0630e-02,\n",
      "        -2.2785e-03,  3.0770e-02, -4.1535e-02, -2.7052e-02, -6.5431e-03,\n",
      "         1.9704e-02, -7.9182e-03, -5.6499e-02, -2.1914e-02,  3.6539e-02,\n",
      "        -2.2714e-02,  1.6525e-03, -1.2795e-02, -4.1844e-02,  6.8920e-02,\n",
      "        -3.1876e-03, -1.9567e-02, -3.4387e-02,  1.9342e-02, -5.7198e-02,\n",
      "         1.0129e-02,  1.8372e-02,  5.5283e-03,  1.1235e-02, -8.4886e-03,\n",
      "        -6.9974e-03, -1.4988e-02])\n",
      "trainable parameters: bert.encoder.layer.1.attention.self.value.weight tensor([[-0.0042, -0.0270, -0.0429,  ..., -0.0554,  0.0374, -0.0697],\n",
      "        [ 0.0402, -0.0359,  0.0115,  ...,  0.0078, -0.0128,  0.0178],\n",
      "        [ 0.0231,  0.0323,  0.0052,  ...,  0.0168, -0.0030,  0.0280],\n",
      "        ...,\n",
      "        [-0.0218, -0.0033,  0.0633,  ...,  0.0345,  0.0826,  0.0056],\n",
      "        [-0.0290, -0.0449,  0.0382,  ...,  0.0822,  0.0033, -0.0310],\n",
      "        [ 0.0020,  0.1051, -0.0178,  ..., -0.1055,  0.0464,  0.0445]])\n",
      "trainable parameters: bert.encoder.layer.1.attention.self.value.bias tensor([ 1.0953e-02, -1.2484e-02,  1.5802e-03, -3.1219e-03, -4.9531e-04,\n",
      "         9.4733e-03,  1.4745e-02, -1.0328e-02, -3.1464e-03,  6.5122e-03,\n",
      "         4.9235e-03,  4.7976e-03, -1.8568e-02, -2.6349e-03, -5.1050e-03,\n",
      "        -5.8765e-03, -4.8461e-03, -9.8837e-03,  9.9112e-04, -5.5341e-03,\n",
      "        -2.8030e-03, -1.3286e-03, -8.0932e-03,  5.3847e-03, -6.4861e-04,\n",
      "         2.2002e-03, -4.5254e-03, -3.0507e-03, -3.2594e-03,  1.2550e-02,\n",
      "         5.3250e-03, -1.1323e-02, -8.4505e-03, -4.4517e-03, -2.6473e-03,\n",
      "         1.5498e-02, -5.3465e-03,  5.6694e-03, -5.7157e-03,  9.2134e-03,\n",
      "         3.5211e-03, -7.6305e-03,  5.4643e-03,  3.0954e-03,  1.1919e-03,\n",
      "        -9.1451e-03,  2.2485e-02, -7.8062e-04,  8.0550e-03,  4.8138e-03,\n",
      "        -3.1587e-03, -6.1199e-02, -5.0241e-03,  6.9543e-04,  9.8496e-03,\n",
      "         4.2684e-04,  1.3346e-02, -3.2071e-03,  3.7287e-03,  4.8030e-03,\n",
      "         4.2357e-03, -7.0970e-04,  9.3795e-03,  1.5449e-02,  3.0553e-02,\n",
      "        -4.1382e-02, -8.3051e-02, -2.4011e-02, -6.7927e-02,  3.0120e-02,\n",
      "        -5.0266e-02, -2.8469e-03, -4.1076e-02, -4.3328e-02,  2.0183e-02,\n",
      "         4.8071e-02,  6.1032e-02, -9.6374e-02,  9.3704e-02, -7.2300e-02,\n",
      "         7.1270e-02,  2.1672e-02, -8.5132e-02,  5.5537e-02, -4.5024e-02,\n",
      "         4.1944e-02,  8.2251e-02, -1.1826e-03, -1.1325e-01,  1.6274e-01,\n",
      "        -1.4992e-02, -5.6302e-02, -1.0275e-01,  1.3901e-03, -1.1839e-01,\n",
      "         5.2403e-02, -4.7156e-02, -1.6315e-01, -2.5370e-02, -1.7996e-02,\n",
      "         4.0016e-02, -1.1116e-02, -9.5483e-02, -1.5470e-01,  5.3816e-02,\n",
      "         7.1379e-03, -8.6717e-02, -2.9154e-02, -8.1556e-02,  4.5305e-02,\n",
      "        -5.5537e-02, -1.4201e-02, -3.3139e-02, -1.3364e-01, -9.4842e-03,\n",
      "        -9.0750e-02,  4.0866e-02, -3.3438e-02, -1.5621e-01, -3.4804e-02,\n",
      "        -5.6225e-02, -2.3165e-02,  2.4673e-03,  2.3695e-03,  1.0082e-01,\n",
      "        -4.5542e-02, -1.9615e-02,  1.3163e-02,  3.9336e-02,  1.6750e-02,\n",
      "         2.1564e-02,  6.7757e-03, -5.4350e-02,  2.4983e-03,  3.0156e-02,\n",
      "         6.9517e-03, -5.0757e-03,  8.1668e-02,  1.8826e-02, -1.5757e-02,\n",
      "        -9.1277e-03, -3.2290e-02,  1.5916e-02,  1.3541e-03,  2.0652e-03,\n",
      "        -3.0213e-03,  1.7997e-03, -4.2742e-02, -7.2057e-03,  1.7516e-02,\n",
      "        -1.7627e-02, -9.4135e-03,  2.1932e-02, -1.1609e-02,  1.1705e-02,\n",
      "         2.3305e-02,  3.5109e-03,  7.4067e-02, -6.5255e-03,  3.6829e-02,\n",
      "        -4.2121e-03, -2.5513e-02, -5.2186e-02,  2.5263e-03,  1.2813e-02,\n",
      "         1.9836e-02,  4.7428e-02, -1.3242e-02, -2.0390e-02,  6.6881e-03,\n",
      "         1.9198e-02, -5.1088e-02, -5.2905e-03,  4.9265e-03,  1.4035e-02,\n",
      "        -9.7336e-03,  5.4674e-02,  2.0847e-02, -1.7420e-02,  2.3337e-02,\n",
      "         2.2089e-02, -3.4782e-02, -9.5525e-03,  1.4268e-02, -7.7323e-04,\n",
      "        -1.3355e-02,  3.0654e-04, -7.7314e-03, -6.3042e-03, -4.1682e-02,\n",
      "        -1.7016e-02,  1.0010e-02, -2.3412e-02, -2.8471e-02,  7.3649e-04,\n",
      "        -7.5835e-02, -2.1348e-02,  1.8537e-02,  1.9990e-02,  1.8624e-02,\n",
      "         1.5009e-02, -3.8582e-02,  2.2947e-02, -7.9628e-02, -3.5114e-02,\n",
      "         1.1164e-02,  5.9128e-03, -2.5274e-03,  2.1562e-02,  2.0165e-02,\n",
      "        -3.5722e-02,  4.5048e-02, -3.3172e-02, -1.3870e-03, -1.0002e-02,\n",
      "         5.2530e-03,  2.4758e-02, -2.8062e-02,  6.3615e-02,  1.3466e-02,\n",
      "         3.2792e-02, -2.1378e-02, -3.2627e-02,  2.6869e-03,  6.5000e-02,\n",
      "         2.3414e-02,  3.4749e-02, -3.3358e-02, -5.3190e-02,  1.1477e-03,\n",
      "        -7.0469e-02,  4.0476e-02, -4.2093e-02, -1.0249e-02, -2.4653e-02,\n",
      "         4.4690e-02,  3.7691e-03, -1.3515e-02, -2.4438e-02,  1.7364e-02,\n",
      "        -3.8139e-02,  4.9101e-02,  2.6779e-02, -1.9329e-02,  4.3761e-02,\n",
      "        -2.0350e-02,  5.8395e-03,  4.2903e-02,  4.9979e-02, -9.9896e-03,\n",
      "         4.6489e-02,  1.3606e-02, -6.9967e-03,  2.8389e-02,  3.0363e-02,\n",
      "         1.4612e-02,  8.0577e-02, -7.1443e-03, -8.1661e-03,  1.6789e-02,\n",
      "         2.2694e-02,  2.3768e-02,  1.8619e-02, -4.3388e-02,  1.1036e-02,\n",
      "         1.4190e-02, -3.8580e-02, -4.3810e-02,  4.8073e-02, -1.5528e-03,\n",
      "         2.6494e-02, -1.0031e-02,  1.1830e-03, -7.1957e-03,  3.9983e-04,\n",
      "         1.1015e-02,  2.3994e-02, -8.2426e-03, -1.7114e-02,  4.6796e-03,\n",
      "         5.2461e-02,  3.5487e-02, -2.8941e-02, -4.1740e-03,  5.6420e-02,\n",
      "        -1.4420e-02, -2.3101e-02,  3.7313e-03, -3.3571e-06, -5.0372e-02,\n",
      "         3.0437e-02, -3.5764e-02,  1.6824e-02, -4.8565e-02, -7.1506e-02,\n",
      "         9.7224e-03, -1.0062e-02,  2.7260e-02, -2.8394e-02, -2.3272e-02,\n",
      "         4.3070e-02, -4.2877e-02, -1.3823e-02, -2.0452e-02, -7.4260e-03,\n",
      "        -4.3961e-02, -3.4995e-03, -5.0330e-02, -3.3785e-02,  2.6390e-02,\n",
      "        -6.1279e-02,  9.9053e-03, -5.8952e-05,  3.7158e-02, -2.7471e-02,\n",
      "         1.4019e-02,  4.4864e-03, -4.0721e-02, -2.1845e-02, -1.2602e-02,\n",
      "         1.1809e-02,  1.3368e-02,  8.9218e-03,  4.6702e-03,  1.3233e-02,\n",
      "        -7.3622e-03, -6.6099e-03, -1.5781e-03,  2.3840e-03,  4.3555e-03,\n",
      "         1.5746e-02, -2.5207e-03, -9.5705e-04, -2.5034e-03, -7.0103e-03,\n",
      "        -9.5691e-03,  4.6913e-03, -5.0911e-03,  1.1777e-02, -3.8133e-03,\n",
      "         1.1479e-03,  1.9811e-03,  8.8485e-03, -5.7862e-04,  5.4609e-03,\n",
      "        -1.1463e-02,  3.6060e-03,  6.0976e-03,  3.0281e-04, -2.4932e-03,\n",
      "        -6.1247e-03,  1.1473e-02,  1.2178e-02,  4.6230e-03, -2.0551e-02,\n",
      "        -1.0091e-02,  3.2089e-03,  1.8502e-03,  6.3224e-03,  8.7672e-03,\n",
      "        -1.7199e-03, -2.2372e-02, -1.6990e-03,  1.4109e-02,  2.0068e-02,\n",
      "         5.9902e-03, -4.2061e-03, -4.6087e-03, -3.0465e-03, -9.2093e-03,\n",
      "         6.4817e-04,  6.0805e-03, -1.7381e-03,  4.1463e-03,  1.1674e-02,\n",
      "        -1.5564e-02, -1.2651e-02, -9.4983e-04,  7.3880e-03,  6.6756e-03,\n",
      "         9.1026e-03, -1.8699e-02,  9.0074e-03, -1.2290e-02,  4.0401e-02,\n",
      "        -1.6977e-02, -2.9554e-02,  7.2586e-03, -2.0628e-02, -1.2600e-02,\n",
      "        -1.4507e-02, -2.9555e-02,  2.7568e-02,  4.3403e-02,  1.8032e-02,\n",
      "         2.1848e-02, -1.2036e-02, -2.3548e-02, -1.4043e-01,  3.0883e-03,\n",
      "        -4.5004e-02,  9.4946e-02, -3.1749e-02, -4.6558e-02,  2.3937e-02,\n",
      "         4.4244e-02, -2.8946e-02,  2.5946e-02, -6.9060e-02, -2.1166e-02,\n",
      "        -3.3931e-02, -3.7852e-02,  3.3562e-02,  4.8443e-03, -2.3897e-02,\n",
      "         1.8169e-02, -4.5805e-02,  4.6369e-02,  9.3418e-03,  5.5404e-02,\n",
      "         4.5612e-02,  7.3135e-02,  1.9663e-02, -3.9329e-02, -3.2616e-02,\n",
      "        -5.8926e-02, -2.8258e-02,  6.0332e-03, -3.8172e-02,  3.8857e-03,\n",
      "         3.1500e-03, -4.1844e-02, -4.0175e-02,  3.4905e-02,  4.3419e-02,\n",
      "         5.9178e-02, -2.4899e-03,  6.2284e-03, -1.9454e-02, -3.1438e-03,\n",
      "        -1.7758e-02, -2.9784e-02, -2.8738e-02,  9.3364e-03, -1.1032e-02,\n",
      "        -9.4046e-03,  2.0210e-02,  1.6496e-02,  5.7029e-03, -8.8399e-03,\n",
      "         5.1225e-03, -3.6409e-03, -4.7893e-04, -2.0651e-02,  1.2959e-02,\n",
      "        -1.1118e-02, -5.7713e-03,  3.5406e-03, -2.1941e-02, -5.0684e-03,\n",
      "         1.6484e-03, -2.6625e-02, -2.3016e-02, -1.5619e-02, -8.7329e-04,\n",
      "        -2.1873e-03,  1.3762e-02, -6.8053e-03,  1.6920e-02,  2.1127e-03,\n",
      "         8.9264e-03, -2.7098e-02,  4.3503e-02, -5.7916e-03, -1.4130e-03,\n",
      "        -2.5770e-03, -1.5337e-02, -2.0895e-03,  1.5380e-03, -8.1979e-03,\n",
      "        -1.3403e-02, -2.2280e-03, -1.9601e-02, -8.8133e-03, -4.0549e-03,\n",
      "         1.3397e-02,  8.0415e-03,  2.1227e-02,  1.4642e-02,  4.9464e-03,\n",
      "        -5.4029e-03, -2.4527e-02, -1.8992e-02, -7.7134e-04, -1.7282e-02,\n",
      "        -5.3584e-03,  1.3102e-03,  2.3950e-02,  1.2295e-02, -8.7890e-03,\n",
      "        -1.8902e-02,  1.9349e-03, -2.2683e-02, -3.0203e-02, -3.0410e-02,\n",
      "         5.9015e-03, -1.0011e-02, -1.2157e-02, -1.0823e-03,  1.7959e-02,\n",
      "         1.1704e-02,  9.5138e-03])\n",
      "trainable parameters: bert.encoder.layer.1.attention.output.dense.weight tensor([[-0.0321,  0.0823,  0.0440,  ..., -0.0553, -0.0082, -0.0099],\n",
      "        [ 0.0199,  0.0384, -0.0168,  ..., -0.0284, -0.0095, -0.0155],\n",
      "        [ 0.0006,  0.0145, -0.0856,  ...,  0.0006,  0.0015, -0.0590],\n",
      "        ...,\n",
      "        [ 0.0212, -0.0443, -0.0474,  ...,  0.0116,  0.0275, -0.0742],\n",
      "        [ 0.0966,  0.0148,  0.0599,  ...,  0.0254,  0.0358,  0.0569],\n",
      "        [ 0.0525,  0.0326, -0.0669,  ..., -0.0355,  0.0010, -0.0438]])\n",
      "trainable parameters: bert.encoder.layer.1.attention.output.dense.bias tensor([-3.6088e-02,  7.0769e-03,  6.9791e-02,  1.3729e-01, -6.1567e-02,\n",
      "        -2.8739e-02,  1.3324e-01,  2.6846e-02,  6.9550e-02, -8.1374e-02,\n",
      "         1.1415e-02,  2.0003e-02, -9.2346e-02,  9.6970e-02,  5.0351e-02,\n",
      "         5.7273e-02, -1.6535e-02,  3.9472e-02, -1.0321e-01,  5.2576e-02,\n",
      "        -7.1037e-02,  2.2519e-02,  1.1450e-02,  2.9351e-02,  1.1666e-01,\n",
      "         4.2700e-02, -2.8152e-02,  5.5213e-03,  6.4721e-02,  3.9165e-02,\n",
      "         3.8167e-02, -1.2015e-01,  1.0884e-01,  7.6468e-02, -8.4985e-03,\n",
      "         3.4998e-02, -7.9927e-02,  6.8945e-02, -8.9643e-02,  2.9182e-02,\n",
      "         4.4819e-02, -4.5385e-02, -1.2568e-01,  1.4366e-01,  5.5297e-02,\n",
      "        -1.2553e-01, -6.0044e-02, -9.6435e-02,  9.1549e-02, -7.2227e-02,\n",
      "         2.4294e-02,  2.3321e-02,  2.3093e-02,  1.4785e-01,  1.0066e-01,\n",
      "        -1.1810e-01,  9.3371e-02,  9.8568e-03, -1.9275e-01, -5.1560e-02,\n",
      "         1.3602e-01, -2.1334e-02,  1.8743e-02,  4.6264e-02, -6.1308e-02,\n",
      "         6.2846e-02, -3.9445e-02,  3.1572e-02,  1.1103e-01, -2.2801e-02,\n",
      "         2.4541e-02, -9.0264e-02,  4.8144e-05,  2.6893e-02,  4.7123e-03,\n",
      "         2.5673e-02,  1.0269e-01,  8.8093e-02,  4.7039e-02,  4.7020e-02,\n",
      "        -8.0128e-02, -8.2588e-02,  1.3101e-04, -7.2059e-02,  1.2055e-01,\n",
      "        -8.3176e-02, -2.7352e-02, -7.4560e-02, -2.0396e-02,  1.1413e-01,\n",
      "         4.1765e-02,  9.1340e-03,  7.8809e-02,  5.6673e-02, -3.3373e-02,\n",
      "         1.3012e-01, -4.6776e-02, -1.4445e-01,  5.1561e-02,  1.0949e-01,\n",
      "         1.4723e-01, -5.7869e-02,  3.5303e-02,  4.1052e-02, -3.3231e-02,\n",
      "         9.1747e-02,  5.1103e-02, -2.3596e-02,  1.3769e-02, -1.5962e-03,\n",
      "        -3.8997e-02,  2.2539e-02, -1.0146e-02, -6.0261e-03,  5.8306e-02,\n",
      "        -2.0380e-02, -1.0370e-01, -9.7992e-04, -4.7218e-02, -8.3611e-02,\n",
      "        -1.6476e-01,  8.5967e-02,  2.9827e-02,  4.5819e-02, -5.4912e-02,\n",
      "        -1.1808e-02, -1.6279e-01,  3.9831e-03,  4.6301e-03,  2.5979e-02,\n",
      "         9.2188e-02, -1.1728e-01, -2.4628e-02,  1.2106e-02, -1.7294e-01,\n",
      "         8.5239e-02,  6.1365e-03,  3.3923e-02,  1.6249e-01, -2.0419e-02,\n",
      "        -3.8279e-02, -2.6957e-02,  7.5740e-02, -1.2492e-01, -2.6454e-02,\n",
      "        -1.0163e-02,  1.8111e-01, -2.8464e-02, -5.9183e-02,  6.5621e-03,\n",
      "        -6.7542e-02, -1.2884e-01,  3.9819e-02, -1.5750e-01, -5.2542e-03,\n",
      "        -9.6915e-02,  8.1777e-02,  2.3394e-02, -1.4682e-01,  9.7271e-03,\n",
      "        -6.8234e-02, -7.7203e-02, -3.7268e-03,  3.6461e-02,  6.2570e-02,\n",
      "        -3.7551e-03, -1.4569e-01, -1.0627e-01,  1.7767e-01, -8.4177e-03,\n",
      "         5.7753e-02,  4.3079e-02,  5.3925e-02, -9.0897e-03, -6.4477e-03,\n",
      "        -6.5987e-02,  8.7978e-04,  6.0768e-02,  1.5665e-02, -1.0832e-01,\n",
      "         3.6516e-02,  4.7693e-02, -3.2614e-02,  1.1148e-01, -3.5027e-02,\n",
      "         1.6589e-02, -8.0762e-02, -1.6205e-01,  4.8512e-02,  3.4951e-02,\n",
      "        -2.3081e-02,  5.2877e-02,  1.9969e-02,  2.7782e-01,  9.8535e-03,\n",
      "         5.0707e-02,  9.4723e-03, -6.2916e-02,  9.9815e-02,  1.1153e-01,\n",
      "         3.6560e-02,  5.2365e-02,  4.0613e-02,  1.0235e-01, -2.0239e-02,\n",
      "         1.0896e-02, -5.4257e-02,  8.1535e-02, -1.3241e-01,  6.3942e-02,\n",
      "         1.7994e-02,  2.4805e-02,  8.0554e-02,  9.1262e-02,  4.3084e-02,\n",
      "         5.7601e-02, -3.4634e-02,  7.8362e-02,  1.5619e-01, -4.8591e-02,\n",
      "         5.6784e-02, -8.3455e-02, -6.8325e-02, -1.7391e-03, -8.9505e-03,\n",
      "        -8.5707e-02,  4.7559e-02,  8.0674e-02,  2.8216e-02, -4.8675e-02,\n",
      "         2.8585e-02,  5.5951e-02, -5.9688e-02, -8.9346e-02, -2.9868e-02,\n",
      "         3.0203e-02,  3.6520e-02,  2.5905e-02, -1.4499e-02, -1.0434e-01,\n",
      "         1.4648e-02, -3.1353e-02,  7.2541e-02, -4.4377e-03,  2.1560e-02,\n",
      "         9.4050e-02,  1.8800e-02, -1.0108e-01, -9.0663e-02, -1.0009e-01,\n",
      "         1.0484e-01,  2.4932e-02, -1.6746e-02, -2.8467e-02,  1.1756e-02,\n",
      "         7.3861e-02,  2.2805e-01, -1.0495e-01, -4.3646e-02, -4.6384e-02,\n",
      "         3.9526e-02,  7.0331e-02, -1.5486e-01, -7.2932e-03,  1.1996e-01,\n",
      "        -7.3840e-02,  4.8101e-02, -6.7526e-02,  6.8437e-02,  1.1661e-02,\n",
      "        -5.7286e-02, -5.5809e-02,  5.9041e-02,  7.0192e-02,  5.7404e-02,\n",
      "        -1.8910e-01,  4.2402e-02, -2.7697e-05, -7.9399e-02,  1.4022e-02,\n",
      "        -8.3768e-02,  9.4662e-02,  3.6268e-03,  9.1148e-02,  3.4261e-02,\n",
      "        -8.4564e-02,  7.7369e-02,  3.9926e-02, -5.3629e-02,  2.9550e-02,\n",
      "        -1.8390e-02, -3.1450e-02, -4.0624e-02, -1.2019e-01,  2.6662e-02,\n",
      "        -4.4662e-02,  5.8109e-02,  3.1617e-02, -7.2515e-02,  6.2905e-02,\n",
      "        -1.3624e-02, -5.6858e-02, -5.2198e-03,  3.2219e-02,  3.8624e-02,\n",
      "        -4.1880e-02,  4.6210e-02,  4.0830e-02,  8.7160e-03, -4.6309e-02,\n",
      "        -1.6020e-02,  2.9218e-02,  5.9578e-02,  2.3748e-02, -4.3036e-02,\n",
      "        -4.7950e-02,  1.1244e-02, -1.0443e-01, -7.8451e-02, -7.1506e-02,\n",
      "        -7.2116e-02, -2.3675e-02,  1.1621e-01,  6.8649e-03,  4.1851e-02,\n",
      "        -5.0313e-02,  3.5496e-02,  1.2057e-01, -8.1934e-02,  8.8387e-02,\n",
      "         6.6635e-02,  8.3435e-02,  1.4149e-02, -1.0519e-01, -1.2564e-01,\n",
      "         5.7659e-02,  5.5782e-03,  3.3722e-02, -6.4534e-02, -3.5661e-02,\n",
      "        -2.4239e-02,  7.0963e-02,  5.8680e-02, -2.4814e-03,  1.5235e-03,\n",
      "        -2.8754e-02,  1.6501e-01,  1.2348e-01, -1.2195e-01, -8.9567e-02,\n",
      "        -1.8193e-01, -1.1281e-02,  3.7100e-02,  2.8865e-02, -8.1071e-03,\n",
      "         4.9602e-02, -8.1422e-02, -7.9961e-02, -4.3574e-02,  8.2809e-02,\n",
      "        -1.1259e-02, -2.7526e-03, -5.1072e-02,  4.1860e-03, -4.2625e-04,\n",
      "        -9.5067e-02, -1.5487e-01,  3.0396e-02,  6.8715e-02, -7.5029e-02,\n",
      "         9.2942e-03, -1.2595e-01,  7.0684e-02,  2.4516e-02, -3.0511e-02,\n",
      "         3.4226e-02,  4.1941e-02,  1.0474e-01, -2.6879e-02,  6.9127e-02,\n",
      "        -1.0180e-02, -1.0232e-02,  2.3756e-02, -5.5037e-02, -1.2139e-01,\n",
      "        -1.1308e-01,  3.7190e-02, -2.0187e-02,  2.7901e-02, -5.1158e-02,\n",
      "         4.2777e-02, -4.9613e-03,  2.2356e-02,  4.5275e-02,  2.5698e-02,\n",
      "         4.5245e-02, -1.1356e-01,  7.0757e-02, -6.9607e-02, -4.1697e-03,\n",
      "         6.6910e-02, -2.5528e-02,  6.4253e-02,  1.0409e-02, -7.2579e-04,\n",
      "        -7.3089e-02, -2.0248e-02,  1.7462e-02, -3.3883e-02, -1.1205e-03,\n",
      "        -3.5429e-02, -7.6884e-02,  4.0896e-02,  2.2355e-03,  2.2846e-02,\n",
      "         2.2795e-02, -9.4740e-04,  5.5668e-05, -8.1515e-02,  1.3105e-03,\n",
      "        -1.3832e-02,  1.0462e-01, -9.7608e-02, -2.6543e-02, -1.2445e-01,\n",
      "        -5.8794e-02, -9.6623e-02, -1.4255e-01,  3.4016e-02, -3.4813e-02,\n",
      "         5.1790e-02,  6.0032e-02,  1.0280e-01, -2.1046e-02, -5.4628e-03,\n",
      "        -7.0915e-02, -9.5495e-03, -8.0815e-03,  6.3632e-02, -7.6534e-02,\n",
      "        -6.9711e-02,  8.3796e-02,  1.6767e-01, -4.6572e-02, -1.4859e-01,\n",
      "        -7.1365e-02,  9.0123e-02,  1.9527e-03,  7.4546e-02,  3.7403e-03,\n",
      "        -7.8155e-02,  8.5910e-03,  3.4561e-02,  1.7155e-02, -1.9577e-01,\n",
      "        -1.1732e-01,  1.6553e-01, -3.3543e-02, -9.9009e-02, -4.6197e-03,\n",
      "        -1.0752e-01,  1.0633e-02, -7.2534e-02, -1.0665e-01,  4.1134e-02,\n",
      "         3.5642e-02,  5.1734e-02, -1.4523e-01,  2.9584e-02, -4.4375e-02,\n",
      "         2.5179e-02, -1.1683e-01, -8.2675e-02,  8.0172e-03, -8.6575e-02,\n",
      "         1.5035e-02, -6.6025e-02,  5.3310e-02, -3.8863e-02, -7.8378e-02,\n",
      "         4.7066e-02, -3.8889e-03, -1.0377e-01,  6.2891e-02,  1.3100e-01,\n",
      "        -3.4964e-02,  1.5612e-02,  3.7274e-03,  6.6199e-02,  1.2689e-02,\n",
      "         1.3173e-01, -3.2367e-02, -1.9400e-02, -5.9931e-02, -5.4847e-02,\n",
      "         5.1655e-02, -1.1833e-02, -1.9608e-02, -2.0693e-02,  1.0746e-03,\n",
      "         3.3654e-02,  3.5769e-02,  1.3690e-02,  3.1541e-02, -5.3719e-02,\n",
      "        -2.1673e-02,  1.3684e-01, -1.0368e-01, -5.6823e-03,  8.7633e-03,\n",
      "        -5.0604e-02, -5.1086e-03])\n",
      "trainable parameters: bert.encoder.layer.1.attention.output.LayerNorm.weight tensor([0.9177, 0.8452, 0.8651, 0.8475, 0.8492, 0.8613, 0.8520, 0.8441, 0.8243,\n",
      "        0.8691, 0.8609, 0.9058, 0.9078, 0.8630, 0.8969, 0.8440, 0.8977, 0.8761,\n",
      "        0.8526, 0.8386, 0.8706, 0.8868, 0.8059, 0.6869, 0.9145, 0.8687, 0.9309,\n",
      "        0.8325, 0.8769, 0.8581, 0.8501, 0.7984, 0.8609, 0.8643, 0.8893, 0.9153,\n",
      "        0.8464, 0.8411, 0.8642, 0.8672, 0.8765, 0.8428, 0.8730, 0.8437, 0.8725,\n",
      "        0.8790, 0.8511, 0.8799, 0.8652, 0.9222, 0.8984, 0.8504, 0.8690, 0.8774,\n",
      "        0.8422, 0.8706, 0.8821, 0.8636, 0.9036, 0.8540, 0.8768, 0.8682, 0.8925,\n",
      "        0.8946, 0.8969, 0.8367, 0.8590, 0.8590, 0.8875, 0.8434, 0.8645, 0.8688,\n",
      "        0.8405, 0.9149, 0.8826, 0.8806, 0.8527, 0.8819, 0.8753, 0.8261, 0.8466,\n",
      "        0.8508, 0.8238, 0.8479, 0.9215, 0.8677, 0.8312, 0.8826, 0.8752, 0.8591,\n",
      "        0.8987, 0.8717, 0.8566, 0.8788, 0.8803, 0.8782, 0.8238, 0.9096, 0.8954,\n",
      "        0.8408, 0.8693, 0.8357, 0.8689, 0.8608, 0.8986, 0.8220, 0.8516, 0.8536,\n",
      "        0.8424, 0.8872, 0.8435, 0.8393, 0.8470, 0.9008, 0.8763, 0.9279, 0.8485,\n",
      "        0.9406, 0.8481, 0.9125, 0.8699, 0.7821, 0.8887, 0.8232, 0.9158, 0.8630,\n",
      "        0.8890, 0.8722, 0.8605, 0.8768, 0.9526, 0.9047, 0.8823, 0.8675, 0.6642,\n",
      "        0.8706, 1.2259, 0.9127, 0.8349, 0.8796, 0.8512, 0.8814, 0.8961, 0.8661,\n",
      "        0.8798, 0.8658, 0.8653, 0.8389, 0.8424, 0.8647, 0.8815, 0.8554, 0.8427,\n",
      "        0.8927, 0.8550, 0.9000, 0.8671, 0.8597, 0.8981, 0.8820, 0.8780, 0.8844,\n",
      "        0.8483, 0.8934, 0.8872, 0.8732, 0.9669, 0.8859, 0.8714, 0.8573, 0.8585,\n",
      "        1.0173, 0.8536, 0.9218, 0.9091, 0.8283, 0.8758, 0.8859, 0.8782, 0.8610,\n",
      "        0.8413, 0.8353, 0.8802, 0.8443, 0.8806, 0.8803, 0.8819, 0.8971, 0.8956,\n",
      "        0.8366, 0.8249, 0.8437, 0.8308, 0.7310, 0.8118, 0.9133, 0.8669, 0.8665,\n",
      "        0.8565, 0.8729, 0.8602, 0.8493, 0.9067, 0.8594, 0.8928, 0.9196, 0.8328,\n",
      "        0.8699, 0.8702, 0.8569, 0.8572, 0.9269, 0.8664, 0.8962, 0.9077, 0.8989,\n",
      "        0.8705, 0.8844, 0.8684, 0.8685, 0.8581, 0.8504, 0.8539, 0.8932, 0.9210,\n",
      "        0.8730, 0.8606, 0.9122, 0.9230, 0.8875, 0.8390, 0.8593, 0.8987, 0.9281,\n",
      "        0.8401, 0.8558, 0.8644, 0.8868, 0.8768, 0.8507, 0.8782, 0.8772, 0.8615,\n",
      "        0.7246, 0.8519, 0.8368, 0.8659, 0.8827, 0.8362, 0.8766, 0.8916, 0.8826,\n",
      "        0.8596, 0.8564, 0.8858, 0.8458, 0.9337, 0.8528, 0.8519, 0.9078, 0.8290,\n",
      "        0.8821, 0.8661, 0.8971, 0.8790, 0.8959, 0.8722, 0.8512, 0.8568, 0.9088,\n",
      "        0.8864, 0.8396, 0.8486, 0.8770, 0.8964, 1.3598, 1.5283, 0.8649, 0.8705,\n",
      "        0.8945, 0.8532, 0.8714, 0.8702, 0.8969, 0.8851, 0.8612, 0.8600, 0.8356,\n",
      "        0.9053, 0.8723, 0.8497, 0.8536, 0.8606, 0.8955, 0.8489, 0.8479, 0.8878,\n",
      "        0.8928, 0.8442, 0.8805, 0.8737, 0.8813, 0.8625, 0.8497, 0.8623, 0.8670,\n",
      "        0.8414, 0.8220, 0.8648, 0.8821, 0.8762, 0.8738, 0.8097, 0.8516, 0.8727,\n",
      "        0.8564, 0.8885, 0.8679, 0.8662, 0.8823, 0.8737, 0.8532, 0.8589, 0.8746,\n",
      "        0.8769, 0.8946, 0.8778, 0.8781, 0.7481, 0.9386, 0.9385, 0.8831, 0.8989,\n",
      "        0.8603, 0.7138, 0.8776, 0.8504, 0.8415, 0.9208, 0.8606, 0.8645, 0.8986,\n",
      "        0.8701, 0.8810, 0.8778, 0.8646, 0.9000, 0.8750, 0.8751, 0.8975, 0.9066,\n",
      "        0.8723, 0.8805, 0.8179, 0.9001, 0.8640, 1.0982, 0.8503, 0.8612, 0.8737,\n",
      "        0.8957, 0.8855, 0.9103, 0.8463, 0.9062, 0.8728, 0.8751, 0.8586, 0.8445,\n",
      "        0.8789, 0.8490, 0.8884, 0.8806, 0.8776, 0.8610, 0.9425, 0.8892, 0.8973,\n",
      "        0.8773, 0.8887, 0.8426, 0.8623, 0.8523, 0.8455, 0.8327, 0.8378, 0.7446,\n",
      "        0.8551, 0.8790, 0.8930, 0.8900, 0.8468, 0.8701, 0.8671, 0.8934, 0.8437,\n",
      "        0.8858, 0.8580, 0.9239, 0.8274, 0.8573, 0.8590, 0.8314, 0.8657, 0.8910,\n",
      "        0.8800, 0.8635, 0.8693, 0.8692, 0.8919, 0.7982, 0.8832, 0.8423, 0.8685,\n",
      "        0.8952, 0.8405, 0.8970, 0.8709, 0.8600, 0.9177, 0.8711, 0.7522, 0.8664,\n",
      "        0.8342, 0.7935, 0.8955, 0.8621, 0.8782, 0.9110, 0.8588, 0.8439, 0.8927,\n",
      "        0.8488, 0.8727, 0.9228, 0.8798, 1.0248, 0.9114, 0.7955, 0.9237, 0.8781,\n",
      "        0.8142, 0.8372, 0.8763, 1.9978, 0.8860, 1.0627, 0.8596, 0.8373, 0.8732,\n",
      "        0.8800, 0.8644, 0.8508, 0.8594, 0.7418, 0.8768, 0.8298, 0.8578, 0.8702,\n",
      "        0.8048, 0.8958, 0.8784, 0.9196, 0.9727, 0.8513, 0.8826, 0.8925, 0.9217,\n",
      "        0.8350, 0.7405, 0.9071, 0.8638, 0.8414, 0.8652, 0.8997, 0.8871, 0.8506,\n",
      "        0.8246, 0.8507, 0.8093, 0.9166, 0.8689, 0.8830, 0.8738, 0.8697, 0.8328,\n",
      "        0.9005, 0.8562, 0.8735, 0.8809, 0.8684, 0.8704, 0.8689, 0.8694, 0.8884,\n",
      "        0.8184, 0.8714, 0.9097, 0.8881, 0.8576, 0.9188, 0.8371, 0.8582, 0.8856,\n",
      "        0.8472, 0.8838, 0.9094, 0.8534, 0.8462, 0.8465, 0.8858, 0.8063])\n",
      "trainable parameters: bert.encoder.layer.1.attention.output.LayerNorm.bias tensor([ 4.8912e-02,  2.2729e-01, -6.6423e-02,  4.9133e-02,  5.0105e-02,\n",
      "         7.7786e-02,  3.4000e-02,  1.3145e-02, -1.2773e-01,  3.7042e-02,\n",
      "        -7.4462e-03, -1.9046e-02, -1.2707e-01, -5.2459e-02, -1.4294e-01,\n",
      "         8.8865e-02,  9.0171e-02,  3.2942e-02,  1.0029e-01, -9.4729e-03,\n",
      "         4.7532e-02, -6.7394e-02,  1.9451e-02,  2.4265e-02, -8.4421e-02,\n",
      "        -1.8743e-01, -1.6406e-01,  9.2293e-02, -2.1617e-02,  1.1167e-01,\n",
      "        -6.4441e-03, -1.2380e-01,  4.3706e-05, -8.5609e-02,  9.4254e-02,\n",
      "         2.4753e-01,  9.3759e-02, -1.5754e-01, -6.0209e-02,  2.3408e-03,\n",
      "        -4.5280e-02,  8.0305e-02,  8.9475e-02,  4.4866e-02, -5.2331e-03,\n",
      "         2.1009e-02,  9.4241e-02, -3.2491e-02, -1.8577e-01, -3.4671e-02,\n",
      "        -2.1812e-02,  5.3857e-02, -4.8094e-02,  4.0123e-02,  3.3323e-02,\n",
      "         5.0659e-02, -6.4606e-02, -1.1859e-01,  7.9769e-02,  2.3182e-01,\n",
      "         1.8029e-01, -5.8561e-02,  7.0102e-02,  7.6954e-02,  1.6312e-01,\n",
      "        -9.6390e-02, -1.0279e-01, -1.5545e-03, -5.5915e-02, -7.0689e-02,\n",
      "         1.0105e-01,  3.5945e-02, -4.4657e-02, -1.1933e-01, -2.9802e-02,\n",
      "         2.0310e-02, -1.4621e-01, -1.1693e-01,  9.5905e-02, -2.4069e-04,\n",
      "         7.4608e-02,  5.6689e-02,  9.4900e-03, -2.8254e-02, -1.1595e-01,\n",
      "         2.8672e-01,  4.1095e-02, -1.2261e-01,  4.3775e-02, -4.5130e-02,\n",
      "         1.2778e-01, -1.2507e-03,  4.5087e-02,  9.6503e-02,  2.8265e-02,\n",
      "        -1.2210e-01, -2.1124e-02,  9.4765e-02, -3.8672e-01,  8.1408e-02,\n",
      "        -1.2999e-01,  8.0155e-03,  4.7269e-02, -3.2140e-02,  2.9879e-02,\n",
      "        -8.3425e-03,  2.1594e-02, -7.9395e-02,  1.1468e-02, -7.4220e-04,\n",
      "        -2.4597e-02, -3.4945e-02, -1.3083e-01, -1.1835e-01, -1.3400e-01,\n",
      "        -1.9432e-01,  1.0204e-01, -2.5379e-01, -2.1745e-04,  2.5068e-01,\n",
      "         1.2397e-01, -1.6079e-03, -5.5718e-02,  1.1462e-01, -7.9616e-02,\n",
      "        -6.8346e-02, -2.5630e-02,  4.9496e-02, -5.4042e-02,  2.2712e-02,\n",
      "         1.5976e-01,  1.4977e-02, -4.9801e-02, -4.7463e-02,  3.4769e-01,\n",
      "         1.6734e-02, -1.2100e+00,  1.4872e-02,  5.3962e-02,  4.0776e-02,\n",
      "         4.1271e-03, -6.9500e-02, -4.3432e-02, -1.2331e-01,  2.2123e-01,\n",
      "         9.2567e-02, -1.1774e-02,  1.0500e-02,  1.0962e-01,  8.2620e-03,\n",
      "         2.2872e-01,  5.5575e-02,  4.1746e-02, -2.2057e-02,  2.3711e-02,\n",
      "        -3.3136e-02,  4.7520e-01, -1.0462e-01,  1.7356e-01,  7.5161e-02,\n",
      "        -1.1751e-01, -1.1930e-01, -8.7180e-02,  9.5858e-02,  4.2916e-02,\n",
      "        -7.5948e-02,  2.2450e-01,  4.2380e-02, -5.4961e-02,  5.0555e-02,\n",
      "        -1.1667e-01, -1.8229e-02,  4.8746e-02,  8.7643e-03, -1.7062e-01,\n",
      "         1.3813e-02,  1.1072e-01, -1.4759e-01,  9.9449e-02, -2.1519e-02,\n",
      "         1.1451e-02,  9.6751e-02,  1.4543e-01, -2.4445e-03,  2.3105e-01,\n",
      "         1.2509e-01,  2.5787e-02,  3.4221e-02, -1.2165e-01,  7.2647e-02,\n",
      "        -4.7455e-02, -8.5609e-03,  1.7977e-01, -2.0692e-01, -4.0297e-02,\n",
      "         4.8283e-02, -1.2142e-01, -1.6533e-02, -9.2920e-03,  1.0182e-01,\n",
      "         4.1818e-02,  1.3689e-01, -1.1611e-01, -8.7693e-02, -2.1066e-01,\n",
      "         2.4460e-01, -5.3238e-02, -4.3799e-02, -7.9863e-02,  6.4211e-02,\n",
      "        -6.5781e-02,  1.9229e-01, -2.1210e-02,  2.1510e-02, -2.1290e-02,\n",
      "         5.7274e-02,  8.8503e-02, -3.9927e-02, -1.6538e-01, -1.7318e-02,\n",
      "         2.6375e-01, -1.5841e-02,  4.3956e-03, -1.8638e-01,  3.6335e-02,\n",
      "        -1.2338e-02, -4.5470e-02,  1.1953e-01,  1.5949e-01,  3.4331e-02,\n",
      "         4.4719e-02, -5.1176e-02,  1.0256e-01,  6.2774e-02, -6.3887e-02,\n",
      "        -9.3725e-02, -4.5713e-02, -4.4425e-02, -4.7226e-02,  1.0297e-01,\n",
      "        -8.2400e-02, -3.8215e-02, -3.7057e-02, -2.7446e-01,  1.2526e-03,\n",
      "        -6.8293e-02,  1.2147e-01,  8.6048e-03,  1.1182e-01, -2.3060e-02,\n",
      "         2.2083e-01,  6.9688e-02,  1.3512e-02,  5.9934e-02,  2.5639e-02,\n",
      "         1.6104e-02, -1.0787e-01,  1.2071e-01,  7.3453e-02, -9.4001e-03,\n",
      "        -2.5475e-02, -1.7469e-01,  3.9582e-01, -1.5705e-02,  4.5101e-03,\n",
      "        -1.9583e-01,  7.7222e-02, -6.9571e-02,  2.1336e-02, -2.8376e-01,\n",
      "        -9.5870e-02, -5.0708e-02,  4.0030e-02, -1.0211e-01, -4.1742e-02,\n",
      "         2.8923e-01, -1.2889e+00, -1.5287e-02,  1.6496e-02, -6.1226e-02,\n",
      "         1.1347e-02, -2.0020e-02, -3.3909e-02,  2.1020e-01,  2.0655e-03,\n",
      "         1.1625e-02,  1.0401e-03,  1.4850e-02,  1.2352e-01, -1.9643e-02,\n",
      "        -9.5615e-02,  2.2258e-02, -2.2299e-03,  1.5561e-01, -8.3981e-02,\n",
      "         1.5216e-01, -1.3720e-03, -1.9314e-01,  3.8585e-02, -2.2101e-01,\n",
      "        -7.4708e-02, -7.5754e-03,  6.3631e-03,  1.6848e-02,  1.2268e-01,\n",
      "         7.7184e-02, -4.5126e-03,  1.1971e-01,  2.0338e-04,  1.5772e-01,\n",
      "        -1.8717e-01,  4.9442e-02, -3.8198e-02, -1.6778e-02, -8.5620e-02,\n",
      "        -2.2100e-02,  1.3135e-02,  1.6424e-02, -7.6211e-02,  1.4941e-01,\n",
      "         4.2331e-02, -2.6805e-02, -7.6758e-02, -3.0292e-02, -1.0960e-01,\n",
      "         9.2286e-02,  9.7324e-02, -1.8557e-01, -1.2594e-01,  4.6829e-01,\n",
      "        -3.3282e-01, -1.3696e-01,  5.2751e-02,  8.2703e-02,  4.6186e-03,\n",
      "         4.6206e-02,  5.9549e-02, -5.6046e-02, -1.2288e-01,  1.1032e-01,\n",
      "         9.7258e-03,  1.9733e-02,  9.6468e-02,  1.7441e-01,  1.6917e-02,\n",
      "         1.6881e-01,  3.1914e-02, -2.1450e-02,  1.2640e-02,  1.4281e-01,\n",
      "        -1.8324e-01,  5.0521e-03,  9.0120e-03, -2.0128e-01,  1.5659e-01,\n",
      "        -1.0638e-01,  7.3889e-01, -5.5127e-02, -2.8161e-02,  9.0136e-02,\n",
      "         2.4611e-01, -9.9247e-02, -6.5384e-02, -1.6545e-02,  1.6636e-01,\n",
      "        -2.1975e-03,  7.0662e-02,  1.2802e-02, -1.6568e-02,  1.4486e-01,\n",
      "         9.4272e-02,  5.8898e-02, -2.9321e-02,  6.1079e-02,  8.3225e-02,\n",
      "        -2.5181e-01,  1.0524e-01,  1.5503e-01,  1.4605e-01, -1.5258e-01,\n",
      "         2.6950e-02, -1.9431e-02,  4.2255e-02, -3.3971e-03, -1.9709e-02,\n",
      "         5.5611e-02, -1.6014e-02, -3.7219e-02,  9.8279e-02, -2.5193e-03,\n",
      "        -1.0660e-02,  1.9309e-01, -1.0330e-02,  1.1527e-01, -4.4155e-02,\n",
      "        -3.9206e-02,  7.5243e-02, -7.3680e-04, -2.1087e-01,  8.4505e-05,\n",
      "         2.0145e-01, -1.0264e-01, -6.1082e-03, -1.1104e-01,  1.1700e-01,\n",
      "         1.4817e-01,  9.0363e-02,  1.3991e-02,  7.9270e-02,  4.3475e-02,\n",
      "         1.5561e-01, -1.1561e-01, -6.3414e-03, -4.6586e-02, -3.7314e-03,\n",
      "         1.7167e-02,  5.3718e-02,  2.6405e-02,  1.4993e-01,  4.1969e-02,\n",
      "         8.3391e-02, -1.4991e-01,  2.4636e-02,  1.7508e-01,  1.0972e-01,\n",
      "         1.7896e-03,  2.2370e-02,  3.7297e-03,  2.1804e-01,  9.5464e-02,\n",
      "         7.5071e-02, -5.1429e-02,  9.0954e-02,  4.7435e-02, -1.6725e-01,\n",
      "         7.1051e-02, -4.4058e-01,  1.6099e-01, -1.0296e-01, -8.9332e-02,\n",
      "        -1.4727e-02, -6.5326e-02,  5.0438e-02, -1.3634e-02,  2.8418e+00,\n",
      "         6.6568e-02, -4.2556e-02,  9.6784e-02,  2.2782e-02, -1.0154e-01,\n",
      "         1.5436e-01, -4.3759e-02,  1.5489e-01,  7.1666e-02,  3.6993e-01,\n",
      "         1.1927e-01, -5.5070e-02,  4.8381e-03,  1.1693e-01, -2.3865e-04,\n",
      "        -6.7966e-02, -4.2939e-02, -1.2716e-01,  4.4026e-02, -4.6863e-02,\n",
      "        -6.4843e-02,  1.4103e-01,  3.6409e-02,  7.9961e-02,  1.2515e-02,\n",
      "        -1.3869e-01,  7.6653e-02,  1.0311e-01, -3.5354e-02, -2.0178e-02,\n",
      "         6.4147e-02, -1.5781e-01, -4.7969e-02, -1.2537e-03, -5.7403e-02,\n",
      "         2.2070e-01,  1.5096e-01, -2.7895e-03,  1.4068e-02,  1.0552e-01,\n",
      "        -7.2471e-02,  5.6092e-02, -4.8952e-02, -1.1332e-02,  1.2517e-01,\n",
      "        -6.9796e-02,  4.4525e-02,  1.7038e-01,  5.4440e-02,  2.1597e-01,\n",
      "         3.8001e-02, -4.8069e-02, -1.7368e-01, -1.4408e-01, -7.5215e-02,\n",
      "         3.0510e-01,  1.3171e-01,  7.5996e-02, -8.9338e-03,  1.1263e-01,\n",
      "         1.3951e-01,  3.0472e-01,  1.4713e-01,  1.6349e-01, -1.2266e-01,\n",
      "        -2.5170e-02,  1.3439e-01])\n",
      "trainable parameters: bert.encoder.layer.1.intermediate.dense.weight tensor([[-0.0202, -0.0112, -0.0382,  ...,  0.0033, -0.0395,  0.0197],\n",
      "        [ 0.0002,  0.0357,  0.0963,  ..., -0.0370, -0.0365,  0.0316],\n",
      "        [ 0.0396, -0.0588,  0.0505,  ...,  0.0639,  0.0438, -0.0019],\n",
      "        ...,\n",
      "        [-0.0100, -0.0379, -0.0154,  ...,  0.0655,  0.0286, -0.0175],\n",
      "        [-0.0469, -0.0690, -0.0579,  ...,  0.1359,  0.0125, -0.0284],\n",
      "        [-0.0296, -0.0498,  0.0146,  ...,  0.0650, -0.0075, -0.0387]])\n",
      "trainable parameters: bert.encoder.layer.1.intermediate.dense.bias tensor([ 0.0281, -0.0567, -0.0409,  ..., -0.0481, -0.1157, -0.0456])\n",
      "trainable parameters: bert.encoder.layer.1.output.dense.weight tensor([[-0.0630, -0.0994, -0.0325,  ..., -0.0140, -0.0490, -0.0501],\n",
      "        [ 0.0651, -0.0148,  0.0423,  ..., -0.0589, -0.0802, -0.0596],\n",
      "        [ 0.0078, -0.0630, -0.0277,  ..., -0.0607, -0.0022,  0.0046],\n",
      "        ...,\n",
      "        [ 0.0201, -0.0655, -0.0271,  ...,  0.0816,  0.0935, -0.0178],\n",
      "        [-0.0236, -0.0268,  0.0435,  ...,  0.0224,  0.0224, -0.0222],\n",
      "        [-0.0127, -0.0377,  0.0455,  ...,  0.0143, -0.0412,  0.0770]])\n",
      "trainable parameters: bert.encoder.layer.1.output.dense.bias tensor([ 2.7251e-02, -2.0687e-03, -6.4154e-02, -6.8366e-03,  2.2341e-02,\n",
      "        -2.0360e-02, -2.8756e-02, -5.9441e-03,  4.2228e-02,  3.1133e-02,\n",
      "         2.1960e-02,  2.3401e-02, -3.6825e-02,  2.2233e-02,  7.0615e-03,\n",
      "         2.5793e-02,  5.4523e-03,  7.1704e-03,  3.8797e-02, -5.3482e-02,\n",
      "         5.6951e-02, -7.6121e-02, -1.4785e-02, -1.6694e-02, -1.2370e-02,\n",
      "        -6.6128e-04,  1.5026e-02, -1.9373e-03, -3.2725e-02, -1.1372e-02,\n",
      "         1.3496e-02,  1.2223e-02, -3.5807e-02, -2.1916e-03, -1.8296e-02,\n",
      "        -3.6592e-02, -8.4665e-03,  4.1323e-03,  1.4504e-02, -1.5979e-02,\n",
      "        -3.2149e-03, -1.0316e-02, -5.2759e-03,  2.3782e-02,  4.2113e-02,\n",
      "        -4.5519e-03,  1.9660e-02, -1.1611e-02, -1.0584e-01,  6.9062e-02,\n",
      "         2.7799e-02, -2.6449e-02, -3.9913e-02, -5.5477e-02, -2.0979e-02,\n",
      "         2.3061e-02, -4.5293e-02, -2.3175e-02,  3.2268e-02, -2.7009e-02,\n",
      "        -7.9574e-02, -5.2889e-02, -1.5172e-02, -6.2700e-05,  3.5098e-02,\n",
      "        -8.4687e-02,  2.4703e-02, -1.2649e-02,  1.5818e-02,  9.0994e-03,\n",
      "        -4.9719e-02, -3.2306e-02, -7.6429e-03, -4.6367e-02, -3.8870e-02,\n",
      "        -1.9469e-02, -3.1966e-02, -8.4507e-03, -2.5631e-02, -9.9906e-03,\n",
      "         2.7473e-02, -3.0855e-03,  2.9487e-03, -1.7389e-02, -9.3095e-02,\n",
      "         3.2712e-02,  3.8253e-03,  2.0768e-02, -1.0751e-02, -1.3103e-02,\n",
      "        -9.4145e-02,  4.0769e-02, -6.9810e-03,  9.0642e-03, -8.6439e-03,\n",
      "         2.3222e-02, -5.3910e-02, -4.7758e-02, -6.4556e-02, -1.7526e-02,\n",
      "        -2.1477e-02,  2.9121e-02,  8.3771e-03,  7.9878e-03,  8.3821e-03,\n",
      "        -2.4343e-02, -1.5585e-02,  1.9086e-02, -3.5428e-02, -1.5950e-02,\n",
      "        -3.4417e-02, -2.4210e-02, -4.2654e-02, -2.2653e-02, -2.0003e-02,\n",
      "         2.4337e-02,  1.5643e-02, -1.9446e-02, -2.6104e-02, -3.0984e-03,\n",
      "         5.7592e-02, -2.9901e-02, -1.7646e-02,  1.7510e-02, -9.9582e-03,\n",
      "        -6.5897e-02,  6.1430e-02,  1.9916e-02, -4.1014e-02, -8.1953e-03,\n",
      "        -1.9457e-02, -1.5809e-03,  3.5808e-02,  8.1852e-03,  3.3750e-03,\n",
      "        -2.7253e-03,  3.2212e-02,  3.4243e-02, -4.7848e-02, -2.2253e-03,\n",
      "        -2.7170e-03, -3.8513e-02, -3.5783e-02, -2.2275e-03,  2.3129e-02,\n",
      "         2.5638e-02, -9.7826e-03, -5.7608e-02,  2.9306e-02, -2.9372e-02,\n",
      "         2.3408e-02, -4.0628e-02, -2.1568e-02,  2.9681e-02,  2.2181e-02,\n",
      "         8.3927e-03, -5.3971e-02, -5.9017e-02,  8.2027e-02, -3.4498e-02,\n",
      "         4.0604e-02,  3.8195e-02, -2.9835e-03,  1.9970e-02,  1.0221e-03,\n",
      "         2.2086e-02,  1.1774e-02,  1.0565e-02,  8.0134e-03, -3.0346e-02,\n",
      "         2.1088e-03,  3.2171e-02, -3.5604e-02,  2.6115e-02, -3.2692e-02,\n",
      "         2.7125e-02, -1.3015e-02, -8.5100e-03,  8.7204e-03,  1.4728e-02,\n",
      "         2.6532e-02,  2.5782e-02, -3.6392e-03, -4.9467e-02,  2.5553e-02,\n",
      "         3.4230e-02,  4.8547e-02,  4.6626e-02, -9.2680e-03, -4.0559e-02,\n",
      "        -4.7363e-02,  4.2373e-02,  1.3909e-02, -5.0769e-02,  1.5387e-02,\n",
      "        -1.7314e-02, -6.4929e-02,  7.9001e-02, -2.5183e-02,  6.2429e-03,\n",
      "        -8.8816e-03, -1.0965e-02, -4.6174e-03,  1.9819e-02,  8.4449e-03,\n",
      "         6.1100e-02,  3.0616e-02, -3.3012e-02, -2.1687e-02,  7.3095e-03,\n",
      "         1.1479e-02,  9.6998e-03, -3.2364e-02, -4.7515e-02,  1.6748e-02,\n",
      "        -6.9006e-02, -3.5791e-02, -2.6021e-02, -6.7153e-02, -1.0814e-02,\n",
      "         8.2697e-02, -1.4795e-02,  1.5710e-02, -8.8191e-03,  8.3857e-03,\n",
      "        -2.0461e-02, -2.8768e-02,  1.8620e-02,  2.1949e-02, -1.6546e-02,\n",
      "         2.7223e-02, -3.5805e-02,  1.2045e-02,  1.0799e-02,  7.1149e-02,\n",
      "         3.9711e-02,  4.0124e-03, -3.5615e-02, -3.4082e-02,  5.3633e-02,\n",
      "         4.3960e-03, -4.5103e-02,  4.7432e-02,  2.4125e-02, -2.4884e-02,\n",
      "        -1.9567e-02,  4.2659e-02,  3.6870e-02,  2.3516e-02,  5.5057e-02,\n",
      "         6.2114e-02,  1.8234e-02,  1.1968e-02,  2.5486e-02, -2.5350e-02,\n",
      "         1.2617e-02,  6.6752e-03,  2.6562e-02, -7.3987e-03,  5.4660e-02,\n",
      "        -1.3942e-02,  1.1501e-04,  3.1521e-02,  8.4525e-03, -1.5912e-02,\n",
      "        -2.8957e-02,  1.0220e-02, -2.2103e-02,  2.4891e-02, -4.6523e-02,\n",
      "         1.7336e-02,  1.7294e-02,  1.6843e-03, -7.8414e-03, -5.6610e-02,\n",
      "        -2.1506e-02,  1.0766e-01, -4.4169e-03,  5.2433e-02,  1.3618e-02,\n",
      "        -2.2400e-02,  1.4743e-03, -9.1542e-03,  1.8226e-02, -2.0650e-02,\n",
      "         1.7982e-02, -8.0602e-02, -1.9724e-02, -2.5722e-02,  2.5669e-03,\n",
      "         7.2008e-02, -3.8464e-02,  2.7552e-02,  5.0439e-03, -6.5305e-03,\n",
      "         2.2233e-02,  3.4213e-02,  4.0373e-03,  4.4236e-02,  5.9543e-02,\n",
      "         2.3926e-02,  2.1346e-02, -5.5515e-02,  3.6973e-02,  2.3304e-02,\n",
      "         6.7483e-02,  5.1050e-02, -1.0786e-02, -3.2226e-02, -2.6487e-02,\n",
      "        -1.0839e-02, -1.0403e-02, -3.0653e-02, -5.5479e-02,  1.7627e-03,\n",
      "        -1.7649e-02,  6.9802e-03, -3.1985e-02, -2.8289e-02, -5.8944e-02,\n",
      "        -1.0165e-03,  1.6446e-02, -3.2780e-02,  7.2760e-03,  2.0040e-02,\n",
      "         2.8180e-02,  4.1306e-02, -8.3101e-02,  2.5115e-02, -6.6373e-03,\n",
      "         2.8173e-02, -3.5165e-02,  5.9689e-02,  5.1379e-02,  1.0441e-01,\n",
      "        -1.9390e-02,  4.9962e-03, -6.4871e-03, -7.1855e-03,  3.3671e-02,\n",
      "        -3.8084e-02,  2.9416e-02,  3.4059e-02, -7.1803e-03,  1.9484e-02,\n",
      "        -3.7775e-03, -8.0231e-02, -3.7608e-02,  1.1919e-02,  1.4077e-02,\n",
      "         5.8401e-02,  2.1450e-02,  1.1550e-02, -2.8221e-02,  2.7493e-02,\n",
      "         1.0036e-02, -4.5443e-03,  3.8313e-02, -4.4031e-02,  4.4680e-02,\n",
      "         5.4650e-02,  1.2299e-02,  2.8171e-02,  1.5230e-02, -3.2480e-02,\n",
      "        -2.1245e-02,  8.0021e-02, -2.2693e-03, -2.3059e-02,  3.6573e-03,\n",
      "         4.2928e-02,  7.7347e-02, -2.7066e-02, -4.7239e-03,  4.3552e-02,\n",
      "        -9.6941e-03, -3.4387e-04, -9.9599e-03,  1.0796e-02, -2.1914e-02,\n",
      "        -1.4385e-02,  4.1022e-02, -8.0287e-03,  3.3413e-03,  7.4119e-02,\n",
      "         1.7915e-02, -4.7825e-02,  5.6011e-02,  4.5090e-02,  2.7503e-03,\n",
      "         1.2032e-02, -3.8002e-02, -3.5884e-02,  4.8718e-03,  2.1754e-02,\n",
      "        -2.0489e-02,  6.9769e-03,  5.7064e-02,  2.0034e-02,  3.7025e-02,\n",
      "         3.7004e-02,  7.3576e-03, -7.7090e-02, -2.9532e-02,  1.0925e-02,\n",
      "         2.3959e-02, -1.9434e-02, -3.7149e-02,  2.6593e-02, -8.1477e-03,\n",
      "        -1.8671e-02,  4.8266e-02, -3.7585e-02,  2.1283e-02, -3.0099e-02,\n",
      "        -1.3857e-02, -2.8908e-02,  8.8067e-03,  6.7466e-03, -1.0897e-02,\n",
      "         3.7764e-02, -6.3132e-02, -2.2144e-02,  8.2246e-03, -3.2565e-02,\n",
      "         6.7110e-02,  4.0967e-02,  3.5495e-02,  5.6575e-02,  2.8416e-02,\n",
      "        -1.3111e-02, -2.5680e-02, -3.1326e-02,  1.1528e-02, -2.6952e-02,\n",
      "         1.0622e-02,  2.3485e-02, -4.4681e-02,  1.5495e-02,  1.8395e-03,\n",
      "         5.2601e-03,  1.1611e-02, -7.1311e-02,  3.5650e-02,  1.5183e-02,\n",
      "        -3.0030e-03, -2.0448e-02, -3.4656e-02,  2.2814e-02, -2.0060e-02,\n",
      "         2.9170e-02,  5.4269e-03,  1.7109e-02,  3.0034e-02,  1.5518e-02,\n",
      "         1.8891e-02,  1.3528e-02,  4.1891e-03,  9.4377e-03,  2.2215e-02,\n",
      "         5.3523e-02,  2.0360e-02,  3.0340e-02,  4.1955e-02,  2.5170e-02,\n",
      "        -4.0320e-03, -3.0614e-02,  5.8384e-02,  7.5949e-03,  8.9283e-02,\n",
      "        -6.8193e-02,  2.3943e-02, -2.2557e-03, -4.6133e-02, -1.0990e-02,\n",
      "         2.5897e-02, -1.5135e-03,  5.8006e-03, -5.1083e-02,  7.5327e-03,\n",
      "         2.5720e-02, -2.1322e-02,  1.6614e-02, -1.7068e-02, -3.3315e-02,\n",
      "         3.6207e-02, -4.0984e-02,  3.4264e-02, -2.1199e-03, -5.5107e-02,\n",
      "        -9.6003e-02, -2.1848e-03,  3.2649e-02, -5.4472e-02,  1.9996e-02,\n",
      "        -3.8331e-02, -2.6366e-02, -5.4249e-02, -1.5687e-02,  4.9774e-02,\n",
      "        -1.2320e-02,  1.5869e-03,  3.1585e-02,  8.2743e-03, -4.4862e-03,\n",
      "        -1.1108e-03,  3.7253e-02, -1.1185e-02,  5.4610e-02, -3.9797e-02,\n",
      "         1.3890e-02,  1.8870e-02])\n",
      "trainable parameters: bert.encoder.layer.1.output.LayerNorm.weight tensor([1.1013, 1.0879, 1.0902, 1.1193, 1.1476, 1.0969, 1.1686, 1.0500, 0.8529,\n",
      "        1.1535, 1.1481, 1.1023, 1.0822, 1.1162, 1.0968, 1.1291, 1.1503, 1.1455,\n",
      "        1.1177, 1.1245, 1.1057, 1.1022, 1.1181, 0.8680, 1.1337, 1.0461, 1.1184,\n",
      "        1.0815, 1.1462, 1.1172, 1.1432, 0.9201, 1.0315, 1.1167, 1.0640, 1.0622,\n",
      "        1.0632, 0.9991, 1.0968, 1.1398, 1.1259, 1.0927, 1.0809, 1.0874, 1.1222,\n",
      "        1.1115, 1.1622, 1.0657, 1.1047, 0.9882, 1.1167, 1.1050, 1.0828, 1.1447,\n",
      "        1.1330, 1.0973, 1.0556, 1.1344, 1.0736, 1.1253, 1.1367, 1.1416, 1.1308,\n",
      "        1.1042, 1.0838, 1.0935, 1.1169, 1.1077, 1.1072, 1.1381, 1.1511, 1.1223,\n",
      "        1.0652, 1.1245, 1.1203, 1.0992, 1.1249, 1.1230, 1.1677, 1.1136, 1.1083,\n",
      "        1.1158, 1.1105, 1.1269, 1.0969, 1.1090, 1.1407, 1.0849, 1.0993, 1.0965,\n",
      "        1.1242, 1.0818, 1.1201, 1.1572, 1.1103, 1.1267, 1.1189, 1.1117, 1.1194,\n",
      "        1.1042, 1.1466, 1.1184, 1.0859, 1.1338, 1.1218, 1.1016, 1.1333, 1.1498,\n",
      "        1.1040, 1.1471, 1.1327, 1.0868, 1.1086, 1.0910, 1.0318, 1.1099, 1.1203,\n",
      "        1.1228, 1.0868, 1.0883, 1.0669, 0.8243, 1.1247, 1.1024, 1.1011, 1.1327,\n",
      "        1.1278, 1.1144, 1.1004, 1.1128, 1.0347, 1.0872, 1.1348, 1.1625, 0.8061,\n",
      "        1.1563, 1.0975, 1.1436, 1.1587, 1.1663, 1.1237, 1.0813, 1.1381, 1.0798,\n",
      "        1.1297, 1.1309, 1.0711, 1.1543, 1.0775, 1.1162, 1.1352, 1.0855, 1.1199,\n",
      "        1.1068, 1.1138, 1.0609, 1.0205, 1.0523, 1.0638, 1.1569, 1.1265, 1.0938,\n",
      "        1.1158, 1.1040, 1.1363, 1.0994, 0.9876, 1.1548, 1.0479, 1.1024, 1.1573,\n",
      "        0.9467, 1.0914, 1.1166, 1.1076, 1.0183, 1.0816, 1.0679, 1.1389, 1.0416,\n",
      "        1.1079, 1.0952, 1.1593, 1.0704, 1.0523, 1.1519, 1.1378, 1.0897, 1.0565,\n",
      "        1.1464, 1.1209, 1.1473, 1.0819, 0.6299, 1.1030, 1.1095, 1.0473, 1.1044,\n",
      "        1.1073, 1.1399, 1.1710, 1.1019, 1.1294, 0.9943, 1.1430, 1.0621, 1.1268,\n",
      "        1.0779, 1.1422, 1.1114, 1.1162, 1.1165, 1.1296, 1.1353, 1.0720, 1.1473,\n",
      "        1.1020, 1.0998, 1.0667, 1.1216, 1.0234, 1.1344, 1.1112, 1.0628, 1.1192,\n",
      "        1.1093, 1.1145, 1.0861, 1.0932, 1.0847, 1.1214, 1.0890, 1.1057, 1.1096,\n",
      "        1.0968, 1.1709, 1.0790, 1.0147, 1.0977, 1.1338, 1.1177, 1.1097, 1.1092,\n",
      "        0.8928, 1.1177, 1.1120, 1.0913, 1.1438, 1.1264, 1.1057, 1.1328, 1.1425,\n",
      "        1.1579, 1.1364, 1.1121, 1.1258, 1.0902, 1.0559, 1.0531, 1.0924, 1.1003,\n",
      "        1.0658, 0.2230, 1.1323, 1.0910, 1.0669, 1.1192, 1.1136, 1.1615, 1.1117,\n",
      "        1.0984, 1.1307, 1.1185, 1.1240, 1.0943, 0.5927, 0.6514, 1.0995, 1.1164,\n",
      "        1.1069, 1.1172, 1.1113, 1.1245, 1.1468, 1.1330, 1.1241, 1.0978, 1.0913,\n",
      "        1.1142, 1.1155, 1.0657, 1.0976, 1.0945, 1.0975, 1.1225, 1.0818, 1.1284,\n",
      "        0.9181, 1.1033, 1.1284, 1.1654, 1.1513, 1.1189, 1.1420, 1.1075, 1.1058,\n",
      "        1.1489, 1.1456, 1.0726, 1.1396, 1.0801, 1.1025, 1.1237, 1.1232, 1.1265,\n",
      "        1.1076, 1.1323, 1.0900, 1.1364, 1.0892, 1.0814, 1.0954, 1.1041, 1.1426,\n",
      "        1.1171, 1.1746, 1.0959, 1.0842, 0.9260, 1.1294, 1.0284, 1.1250, 1.1140,\n",
      "        1.1312, 0.9123, 1.1127, 1.0758, 1.1027, 1.0990, 1.1181, 1.1110, 1.0902,\n",
      "        1.0968, 1.1722, 1.0941, 1.0987, 1.0947, 1.1266, 1.0885, 1.1141, 0.8507,\n",
      "        1.0979, 1.0919, 1.0959, 1.1115, 1.0976, 1.1991, 1.1405, 1.0842, 1.1250,\n",
      "        1.1232, 1.0556, 1.1123, 1.1461, 1.0884, 1.1582, 1.1389, 1.1232, 1.1090,\n",
      "        1.1073, 1.0578, 1.1367, 1.1310, 1.1024, 1.0999, 1.0873, 1.1418, 1.1154,\n",
      "        1.0877, 1.1198, 1.1401, 1.1890, 1.0973, 1.1460, 1.0682, 1.1304, 0.8971,\n",
      "        1.1415, 1.1073, 1.0751, 1.1206, 1.1215, 1.1143, 1.0639, 1.0946, 1.0975,\n",
      "        1.0927, 1.1582, 1.1159, 1.1071, 1.0998, 1.1291, 1.0866, 1.1060, 1.1105,\n",
      "        1.1415, 1.1642, 1.1134, 1.1225, 1.1122, 1.1035, 1.1303, 1.1762, 1.1372,\n",
      "        1.1603, 1.1453, 1.1260, 1.1503, 1.0812, 1.0779, 1.1117, 0.8591, 1.1197,\n",
      "        1.0882, 0.9858, 1.1353, 1.1203, 1.1133, 1.1423, 1.0609, 1.1008, 1.1568,\n",
      "        1.1261, 1.1373, 1.0877, 1.0332, 1.1193, 1.1349, 1.1087, 1.1200, 1.1363,\n",
      "        1.0617, 1.1022, 1.1066, 0.5354, 1.1434, 0.9491, 1.1620, 1.1024, 1.1304,\n",
      "        1.1531, 1.1338, 1.0731, 1.0346, 0.8793, 1.0852, 1.1944, 1.1403, 1.1029,\n",
      "        1.1267, 1.1191, 1.1341, 1.1039, 0.9805, 1.1178, 1.0914, 1.1107, 1.1172,\n",
      "        1.1239, 0.9332, 1.0951, 1.0921, 1.0947, 1.0762, 1.0318, 1.1233, 1.0895,\n",
      "        1.1148, 1.1477, 1.0402, 1.1163, 1.1581, 1.0555, 1.1321, 1.0957, 1.0945,\n",
      "        1.1403, 1.0597, 1.1161, 1.1712, 1.0580, 1.0847, 1.1215, 1.1167, 1.0926,\n",
      "        1.0717, 1.1285, 1.0153, 1.1448, 1.1377, 1.0879, 1.1222, 1.0901, 1.0548,\n",
      "        1.1457, 1.1547, 1.1205, 1.0578, 1.1477, 1.0970, 1.1224, 1.1711])\n",
      "trainable parameters: bert.encoder.layer.1.output.LayerNorm.bias tensor([-3.5077e-02, -6.4737e-02,  5.8104e-02,  2.6181e-02,  2.1366e-02,\n",
      "        -2.2352e-02,  2.1571e-02, -5.5632e-02,  6.8296e-02, -2.9125e-02,\n",
      "         1.7154e-02,  3.8894e-02,  4.2271e-02,  7.8787e-02,  6.5134e-02,\n",
      "         3.8704e-03, -1.9579e-02,  3.6111e-02, -6.8721e-03,  3.6762e-02,\n",
      "         4.2436e-02, -4.2762e-03,  1.4487e-02, -4.5529e-02,  3.9749e-02,\n",
      "         1.3297e-01,  1.2101e-01, -2.6848e-02,  3.7116e-02, -8.5073e-03,\n",
      "        -4.1249e-03,  1.1257e-01,  4.8137e-02,  7.6018e-02, -3.7081e-02,\n",
      "        -7.2005e-02, -4.4490e-02,  9.2339e-02,  6.0235e-02, -1.3617e-02,\n",
      "         2.8331e-02,  1.0161e-02, -5.2264e-02, -1.5924e-02, -1.7434e-02,\n",
      "         2.9465e-02, -2.7083e-02,  2.3493e-02,  1.4736e-02,  1.5698e-02,\n",
      "         2.9726e-02, -1.2688e-02,  9.4204e-03, -4.7479e-02,  8.8404e-03,\n",
      "        -2.5645e-02,  7.2170e-02,  6.7027e-02, -2.8641e-02, -8.4423e-02,\n",
      "         1.0907e-02,  5.6353e-02, -6.3429e-02,  2.1404e-02, -3.6948e-02,\n",
      "         2.4786e-02,  6.9326e-02, -3.2716e-02,  4.8440e-02,  5.9686e-02,\n",
      "        -3.6840e-02,  2.5621e-02,  2.9670e-02,  4.5838e-02,  1.8409e-02,\n",
      "        -2.2663e-02,  6.6913e-02,  9.4506e-02, -2.8737e-02, -1.5356e-03,\n",
      "        -2.1020e-02, -2.0189e-02, -2.4407e-02,  2.5312e-02,  7.3033e-03,\n",
      "        -5.2176e-02, -1.9888e-02,  3.3652e-02,  1.0630e-02,  1.3262e-02,\n",
      "        -2.7998e-02,  8.5167e-02, -1.8870e-03,  1.7577e-02,  1.0016e-02,\n",
      "         1.0556e-01,  1.3734e-02, -4.5216e-02,  5.6670e-02,  1.2064e-02,\n",
      "         5.8283e-02,  1.1816e-02,  2.9897e-02,  1.9359e-02, -2.6736e-02,\n",
      "         5.2202e-02, -6.0620e-02,  8.6128e-02,  1.7834e-02,  6.5441e-02,\n",
      "        -1.8352e-02,  5.7672e-02,  6.1299e-02,  1.6497e-02,  1.2098e-01,\n",
      "         5.6574e-02,  1.9702e-02,  6.1625e-02,  2.2656e-02, -1.0372e-01,\n",
      "         2.7470e-03,  7.8990e-02,  3.5673e-02,  3.1981e-02,  9.3194e-02,\n",
      "         6.2648e-02,  7.3545e-02, -1.3842e-02,  2.6250e-02, -2.9546e-02,\n",
      "        -5.0423e-02,  3.4669e-03,  5.6700e-02,  4.1580e-02, -1.8165e-01,\n",
      "        -8.0943e-03,  1.3772e-02, -1.5574e-02, -4.0243e-02, -1.1736e-02,\n",
      "         1.3132e-02,  9.7410e-02,  3.0191e-02,  6.9638e-02, -7.9056e-02,\n",
      "        -2.8958e-02,  1.9007e-02,  1.2278e-02, -6.7052e-03,  2.5899e-02,\n",
      "        -6.0693e-02,  9.1393e-03, -2.9262e-02,  7.0664e-02,  1.1924e-02,\n",
      "         2.7542e-02, -7.0739e-02,  9.2399e-02, -1.9269e-02, -9.3587e-03,\n",
      "         1.4553e-01,  1.1505e-01,  6.6931e-02, -4.6979e-02,  2.7059e-02,\n",
      "         3.0354e-02, -1.0464e-01,  1.5559e-02,  9.5069e-02,  2.1288e-02,\n",
      "         4.8532e-02, -7.1997e-02, -2.4489e-02,  3.8602e-02,  3.4636e-02,\n",
      "         3.2380e-03, -3.7320e-02,  8.2826e-02, -4.5095e-02,  1.0175e-01,\n",
      "         2.4372e-02,  2.2805e-02, -6.5750e-02,  4.0916e-02, -4.7992e-02,\n",
      "        -3.2382e-02,  8.1505e-03, -1.6350e-02,  6.7710e-02, -1.1604e-02,\n",
      "         4.5613e-02,  3.7820e-02, -4.4094e-02,  2.9913e-01,  7.8389e-02,\n",
      "         3.0153e-03,  8.3398e-03,  5.0311e-02,  5.8715e-03, -3.1038e-02,\n",
      "         2.9891e-02, -4.4854e-02,  1.0813e-01,  8.5926e-02,  5.7929e-02,\n",
      "         1.0822e-02,  3.1386e-02,  2.5869e-02,  6.8837e-02, -1.2349e-02,\n",
      "         5.6601e-02, -2.4737e-02,  2.6232e-02,  1.2767e-02,  6.5232e-02,\n",
      "        -2.5968e-02,  1.0610e-03,  4.4749e-02,  8.9160e-03,  4.7177e-02,\n",
      "        -1.2329e-01,  2.2510e-02,  2.6101e-02,  8.3956e-02,  6.7357e-03,\n",
      "        -2.8603e-02,  4.8388e-02, -1.3803e-02, -3.8261e-02,  1.2047e-03,\n",
      "         2.7149e-02,  2.4051e-02, -2.7044e-02,  4.0137e-03,  6.6642e-02,\n",
      "         5.2854e-02,  8.1026e-02,  4.9455e-02,  1.0870e-04,  1.8484e-02,\n",
      "         1.6360e-02,  7.5299e-03,  1.0630e-01,  1.3804e-01, -2.5055e-02,\n",
      "         5.4768e-02, -6.7208e-02,  2.6681e-02, -1.2815e-02,  4.7074e-02,\n",
      "        -8.7586e-03, -2.8532e-02,  2.2151e-02,  5.1063e-02,  3.9951e-02,\n",
      "        -7.7666e-03,  1.6855e-02, -7.7480e-02, -2.4531e-02,  1.0668e-02,\n",
      "         1.9544e-02,  9.6306e-02, -1.7624e-01, -1.8329e-02,  1.2158e-02,\n",
      "         7.5833e-02,  1.0394e-02,  8.5977e-02, -6.6107e-03,  7.8812e-02,\n",
      "         6.1612e-02,  5.0336e-02, -3.4155e-02,  2.1599e-02,  8.5924e-03,\n",
      "        -3.1433e-01, -2.0387e-01,  5.2427e-02,  5.2269e-02,  1.8283e-02,\n",
      "        -1.2968e-02,  6.2359e-02,  3.9930e-02, -4.4945e-02,  2.9078e-02,\n",
      "         1.5280e-02,  3.4063e-02,  2.8171e-02, -5.1460e-02,  5.1370e-02,\n",
      "         7.3197e-02,  3.7487e-02, -1.7374e-02, -1.7477e-02,  7.3903e-02,\n",
      "        -2.0416e-02, -2.0372e-02,  1.0878e-01, -4.8289e-02,  1.0428e-01,\n",
      "         1.9901e-02,  6.0297e-02,  3.2028e-02,  7.7166e-03, -5.4898e-02,\n",
      "         1.0903e-02,  4.7737e-02, -4.4176e-03,  4.9017e-03, -6.7373e-02,\n",
      "         1.1910e-01,  5.9153e-02,  5.7745e-02,  3.8574e-02,  9.0905e-02,\n",
      "         3.1553e-02, -7.0834e-02,  3.7910e-02,  1.0909e-02, -2.5331e-02,\n",
      "         3.6300e-02,  3.2511e-03,  5.7353e-02, -7.9910e-03,  4.1006e-02,\n",
      "        -1.3736e-02,  1.8096e-02,  5.5325e-02,  8.9465e-02, -6.9879e-02,\n",
      "         1.2402e-01,  6.7817e-02,  4.0982e-02,  2.6021e-02, -1.6453e-02,\n",
      "        -6.8125e-02,  3.1087e-02,  9.0453e-02,  8.8053e-02, -6.9634e-03,\n",
      "        -1.4039e-02, -5.2799e-03, -1.1069e-02, -7.0458e-02,  3.8755e-02,\n",
      "        -4.6820e-02, -2.5467e-02, -9.6347e-03, -2.6545e-02, -6.5956e-02,\n",
      "         1.2223e-01, -5.8793e-03,  2.3392e-02,  6.7409e-02, -9.6739e-02,\n",
      "         9.3930e-02, -4.3040e-02,  6.3969e-02, -3.2269e-02,  3.7707e-02,\n",
      "        -1.9264e-02,  6.4903e-02,  9.1197e-02,  1.0937e-02, -2.4886e-02,\n",
      "        -1.8212e-03,  5.4301e-02,  1.1308e-02,  2.8132e-02, -8.5859e-03,\n",
      "        -1.1909e-02,  4.5513e-02,  4.0122e-02,  7.9658e-03, -1.7512e-02,\n",
      "         7.6191e-02, -7.3921e-02,  7.9553e-03,  8.8353e-03,  1.2273e-01,\n",
      "        -3.6473e-02,  6.4712e-02,  2.1206e-02,  1.3367e-02, -2.1606e-02,\n",
      "         3.8587e-02,  6.0535e-02,  2.2149e-02, -8.0268e-03, -1.8272e-02,\n",
      "        -2.0177e-02, -9.2115e-02,  2.2504e-02, -8.0801e-02, -8.8398e-03,\n",
      "        -3.0982e-03, -1.1339e-02,  3.7496e-02,  9.6884e-02,  9.1909e-02,\n",
      "        -3.3298e-02,  9.6182e-02,  4.8828e-02,  5.9225e-02, -8.4383e-02,\n",
      "        -3.7911e-02,  4.0340e-03,  4.1941e-02,  3.0735e-03, -1.2623e-02,\n",
      "        -3.9332e-02,  8.7168e-02,  2.0175e-02,  3.8407e-02,  6.4175e-03,\n",
      "         8.7442e-03, -9.8462e-04,  2.9558e-02, -7.5747e-03, -5.8141e-02,\n",
      "         3.1095e-03,  4.2330e-02,  3.8850e-02, -1.0359e-01,  1.0182e-02,\n",
      "         4.5591e-02,  1.9849e-02,  5.7454e-02, -5.1142e-02, -9.5847e-02,\n",
      "        -2.0648e-02,  1.5032e-02, -3.6367e-02, -1.9899e-04,  1.0784e-01,\n",
      "        -3.8366e-02,  2.4798e-02, -8.0005e-02,  4.8002e-02,  4.8010e-02,\n",
      "         1.5321e-02,  7.0191e-02, -2.0304e-02,  7.8240e-02,  1.0850e+00,\n",
      "         1.8152e-02,  1.5423e-01,  7.8494e-04,  9.1180e-03,  7.8570e-02,\n",
      "        -2.3952e-02, -2.2183e-03, -7.0070e-02, -6.7495e-03, -1.4322e-01,\n",
      "        -1.5688e-02,  5.5656e-02,  7.2237e-03, -2.1191e-02,  3.7018e-02,\n",
      "         8.0230e-02,  7.8918e-03,  7.0299e-02, -4.9076e-02,  1.9641e-02,\n",
      "         1.0405e-01, -2.1194e-02,  1.6678e-02,  2.5694e-03,  4.5583e-02,\n",
      "        -2.3094e-02,  2.9485e-02, -5.9763e-02,  2.4710e-03,  5.8212e-02,\n",
      "        -4.7689e-03,  4.9301e-02,  3.2101e-02, -9.8645e-03,  5.0930e-02,\n",
      "        -7.7473e-02, -2.2376e-02,  3.4462e-02,  2.5031e-03, -2.1852e-02,\n",
      "         1.0813e-01, -3.6551e-02,  4.4064e-02,  8.2503e-03, -5.6844e-02,\n",
      "         3.6123e-02, -4.3392e-02, -3.0910e-02,  4.2493e-02, -5.2120e-02,\n",
      "        -7.3521e-03,  2.1681e-02,  1.5544e-01,  3.7457e-02,  8.4171e-02,\n",
      "        -5.1822e-02, -3.2128e-02, -5.6910e-03,  3.7415e-04, -1.6312e-02,\n",
      "         4.4049e-04, -4.9526e-02, -7.9066e-02, -3.7170e-02,  1.0720e-01,\n",
      "         3.2378e-02,  3.1729e-03])\n",
      "trainable parameters: bert.encoder.layer.2.attention.self.query.weight tensor([[-0.0808,  0.0789, -0.0147,  ...,  0.0547,  0.0272, -0.0006],\n",
      "        [ 0.0391, -0.0254,  0.0007,  ...,  0.0135,  0.0247, -0.0961],\n",
      "        [ 0.0661, -0.0542, -0.0509,  ...,  0.0268,  0.0432,  0.0444],\n",
      "        ...,\n",
      "        [ 0.0272,  0.1627, -0.0470,  ...,  0.0783, -0.0413, -0.0012],\n",
      "        [-0.0737, -0.0278, -0.0225,  ..., -0.0435,  0.0072, -0.0527],\n",
      "        [-0.1041,  0.0557,  0.0020,  ..., -0.0507,  0.0208, -0.0124]])\n",
      "trainable parameters: bert.encoder.layer.2.attention.self.query.bias tensor([-1.4767e-01, -8.0864e-02,  1.3298e-02, -6.2550e-02,  4.1988e-02,\n",
      "        -8.9328e-02, -7.0942e-02,  1.5251e-01,  1.8327e-01, -2.5814e-03,\n",
      "        -1.9908e-01,  1.0673e-01, -9.4709e-02,  4.4424e-03, -1.7771e-01,\n",
      "         1.5713e-01, -3.1063e-02, -1.3712e-01, -4.2738e-02,  1.3490e-01,\n",
      "        -4.9119e-02,  5.7713e-04,  3.4931e-02, -1.5154e-02,  9.2815e-02,\n",
      "         7.9742e-02, -8.2873e-04, -2.6416e-02, -7.1123e-02, -1.4218e-02,\n",
      "        -1.1880e-01, -2.2268e-01, -4.1205e-03,  2.9907e-02, -1.4169e-03,\n",
      "         5.5561e-04,  9.2829e-02,  1.2188e-01,  1.2022e-01,  5.2220e-02,\n",
      "         4.1825e-02, -1.1765e-01, -3.0241e-02, -1.1189e-01,  2.8292e-02,\n",
      "         1.4153e-01, -4.4032e-03, -1.5900e-01, -1.1945e-01,  2.8316e-02,\n",
      "        -6.0116e-02,  4.5695e-02, -4.7552e-02, -1.2719e-01, -6.6011e-02,\n",
      "         2.7517e-02, -1.4802e-01,  5.6164e-02, -1.6730e-01,  5.5330e-02,\n",
      "        -1.0298e-01,  5.4531e-02,  3.1866e-02,  2.0090e-01, -5.2770e-02,\n",
      "        -7.0873e-02, -8.9970e-02,  2.8759e-02, -2.8070e-02,  6.2553e-02,\n",
      "         5.2293e-02,  4.1315e-02, -2.0442e-01, -3.2545e-03,  4.3366e-02,\n",
      "        -5.6223e-02,  6.8639e-02, -5.1677e-02,  1.6799e-01, -1.1975e-01,\n",
      "         1.9023e-01,  1.9304e-01, -4.7093e-02,  5.0876e-02,  3.1886e-02,\n",
      "        -1.3234e-01, -8.4545e-02, -7.7549e-02,  5.2405e-02,  1.3407e-01,\n",
      "         1.0160e-02,  6.4039e-02,  5.5938e-02,  1.5846e-02, -3.6789e-02,\n",
      "        -1.2711e-04, -4.9455e-03, -1.0713e-01, -1.6591e-01, -7.1996e-02,\n",
      "        -4.4547e-03,  4.4103e-02, -1.7805e-01, -8.4836e-02, -5.7673e-02,\n",
      "         2.0943e-02,  9.5605e-02,  4.4853e-02, -1.5021e-01,  9.1768e-02,\n",
      "         1.2485e-01, -8.1754e-02, -8.6445e-02, -1.3244e-01, -8.3653e-02,\n",
      "         5.0851e-02, -1.9892e-01,  9.6506e-03, -1.1474e-01,  1.8845e-01,\n",
      "        -1.0233e-01,  4.0119e-02, -1.4828e-01,  2.9806e-02,  2.0824e-02,\n",
      "         1.3518e-02, -1.1728e-01,  1.4932e-01,  7.8680e-02, -8.1784e-02,\n",
      "         2.0048e-02,  1.2941e-01, -1.0498e-02, -3.3821e-03, -2.1581e-02,\n",
      "         2.7263e-02,  7.4363e-02, -6.8504e-02,  9.0455e-02,  1.2827e-01,\n",
      "        -2.1005e-02,  6.9668e-02, -1.0378e-01,  6.4298e-02, -7.2032e-02,\n",
      "        -4.9526e-02,  1.1744e-01,  1.2137e-01, -1.4122e-01, -1.9793e-01,\n",
      "        -1.0910e-01,  7.1177e-02,  6.0506e-02,  2.0822e-02, -2.5893e-02,\n",
      "         1.6214e-02,  8.3883e-02,  4.7146e-02, -1.7603e-01,  1.4555e-02,\n",
      "         9.3174e-02,  2.9356e-02, -9.7019e-02, -6.2008e-02, -1.5841e-02,\n",
      "         1.6052e-02, -4.2805e-02,  5.9534e-02,  6.2706e-02, -9.7218e-02,\n",
      "         5.6715e-02, -4.2875e-03,  1.3861e-02, -1.7794e-01, -3.8418e-02,\n",
      "         6.3198e-02,  1.1891e-02, -1.1679e-01,  2.1755e-02, -3.7905e-02,\n",
      "         1.3926e-02,  2.0291e-01, -4.1209e-02,  6.0195e-02,  1.5459e-01,\n",
      "        -8.2846e-02, -6.9630e-02,  8.3277e-02,  2.8074e-02,  2.1909e-02,\n",
      "         1.9820e-01,  1.6108e-01,  1.0852e-01,  5.7068e-02,  6.7025e-02,\n",
      "         2.2377e-02, -1.2083e-01, -1.8789e-02,  1.0163e-01, -1.1959e-02,\n",
      "         8.2232e-02,  6.6585e-02, -1.2501e-01, -3.9690e-02, -2.6169e-02,\n",
      "         2.4928e-02, -3.7096e-02, -4.7677e-02,  5.0923e-03,  5.0425e-02,\n",
      "        -4.7509e-02,  1.0036e-02,  6.7289e-03, -6.8821e-02,  1.3919e-01,\n",
      "         3.4672e-02, -8.7188e-02, -2.9609e-03,  6.3541e-02,  4.0466e-03,\n",
      "         1.0187e-01,  3.2494e-02,  4.2239e-02,  1.1753e-02,  6.6970e-02,\n",
      "        -1.5035e-01, -7.7566e-02,  7.6156e-02,  5.6911e-02,  2.3128e-02,\n",
      "        -3.1612e-02, -4.5866e-02,  2.2681e-02, -1.2026e-01,  8.1594e-02,\n",
      "        -1.7196e-02, -1.1697e-02, -7.0361e-02,  2.0122e-02, -1.0105e-01,\n",
      "        -6.8447e-02, -3.4855e-02, -1.4925e-03, -9.2185e-03,  1.2220e-01,\n",
      "        -1.0594e-01, -2.4627e-02,  9.8617e-02,  2.4886e-02, -7.2504e-02,\n",
      "        -6.5293e-02,  3.5322e-02,  4.3451e-02,  8.4660e-02, -1.6164e-02,\n",
      "        -1.1595e-01,  3.7427e-04,  1.5419e-01, -1.0511e-01, -6.2902e-02,\n",
      "        -2.8623e-02,  2.0377e-02, -2.3998e-03,  1.1736e-01, -1.5692e-01,\n",
      "         1.3517e-01,  1.1257e-01, -1.1431e-01, -1.5875e-02, -1.0862e-01,\n",
      "         4.3900e-02, -1.4806e-02,  5.3595e-02, -1.4075e-01,  1.6502e-01,\n",
      "         6.9151e-02,  2.5797e-02,  7.9610e-03, -1.9768e-01,  1.4185e-01,\n",
      "        -9.3919e-02,  9.6839e-02, -1.0213e-01, -1.1809e-01,  3.5338e-02,\n",
      "         1.7267e-01, -1.4098e-02,  1.6724e-01, -3.0427e-02, -1.4681e-01,\n",
      "         4.8573e-02, -4.1165e-04,  4.2793e-02,  1.3605e-01,  1.1763e-01,\n",
      "         6.8113e-02, -3.5136e-02, -5.5731e-02, -1.2410e-01,  6.7360e-04,\n",
      "         2.2375e-01, -1.3126e-02,  1.3941e-01, -1.3465e-01,  1.5283e-01,\n",
      "         5.8738e-03, -9.8221e-02,  7.0253e-02, -3.5165e-02,  1.7008e-01,\n",
      "         6.1593e-02,  3.8659e-02,  1.2088e-01, -1.6725e-01,  1.2687e-01,\n",
      "        -1.7805e-01, -4.1406e-03, -7.8673e-02,  1.0375e-01, -2.2168e-02,\n",
      "         6.7581e-02,  2.0944e-01,  6.7535e-02, -9.0924e-02,  2.3871e-01,\n",
      "        -6.2932e-02, -5.4278e-02,  2.5277e-02, -1.6756e-01, -7.1372e-02,\n",
      "        -1.2589e-01,  2.0392e-01,  3.6861e-01, -2.2449e-01, -1.6246e-01,\n",
      "        -1.6974e-01,  1.2175e-01, -8.2869e-02, -3.5834e-02, -5.1303e-02,\n",
      "         7.0267e-02, -1.4366e-01,  1.9503e-01, -1.7657e-01, -5.0906e-02,\n",
      "         1.3447e-01,  1.6376e-01,  7.9220e-03,  2.1317e-02, -1.8557e-01,\n",
      "         5.1361e-02, -2.8727e-01,  7.6670e-02,  1.7230e-01, -8.5728e-02,\n",
      "        -1.7502e-01,  1.2559e-01,  2.1169e-01, -2.2263e-01,  1.7237e-01,\n",
      "         8.7113e-03,  3.1724e-01,  1.4654e-01, -1.1340e-01, -3.5475e-02,\n",
      "         2.6005e-01,  1.4873e-01, -2.1269e-01, -8.0783e-02,  9.6220e-02,\n",
      "         1.7097e-01, -2.2833e-01,  8.7970e-02,  1.3160e-01,  1.7423e-01,\n",
      "        -9.6411e-02,  2.3125e-01,  6.4082e-02, -2.8252e-01, -1.7301e-01,\n",
      "         5.2848e-02, -6.5343e-02,  4.7724e-02, -1.3174e-01, -3.9144e-02,\n",
      "         1.5152e-01,  2.1277e-01,  5.0403e-02, -1.3033e-01,  1.4087e-01,\n",
      "        -2.2695e-01,  1.0654e-01, -6.7771e-02,  1.2443e-02, -5.3189e-02,\n",
      "        -2.1293e-02, -2.3977e-02,  2.9481e-02, -2.7950e-01,  4.1401e-02,\n",
      "        -8.0855e-02, -1.1834e-01,  5.6535e-02, -1.5328e-01, -1.0108e-01,\n",
      "         2.1443e-01,  1.4636e-01, -9.5544e-02, -1.8908e-01,  2.3229e-01,\n",
      "        -2.2695e-01, -2.0125e-01,  9.2240e-02,  1.4527e-01,  2.6713e-01,\n",
      "        -1.3975e-01,  6.4033e-03, -2.5264e-01,  8.2896e-02,  1.6382e-01,\n",
      "        -1.1071e-01, -5.8629e-02, -3.7186e-02,  1.7244e-01, -1.8096e-01,\n",
      "         1.4331e-01, -1.4011e-01,  1.6928e-01,  2.0841e-01,  7.6073e-02,\n",
      "        -9.5821e-02, -7.8628e-02,  1.5205e-02, -7.9696e-03, -3.2740e-02,\n",
      "         1.7387e-01, -2.3063e-01,  1.7895e-01, -2.1362e-01, -1.8681e-01,\n",
      "        -1.6981e-01, -5.5261e-02,  2.2846e-01, -4.5228e-02,  2.2034e-01,\n",
      "        -3.9774e-02,  3.3860e-01,  8.5419e-02, -3.5910e-02,  2.4630e-02,\n",
      "         9.9764e-02,  3.9252e-02, -7.1518e-03, -9.1646e-02, -1.1973e-01,\n",
      "        -1.6565e-03,  1.4820e-02,  9.1011e-02, -1.6955e-01, -1.5895e-01,\n",
      "        -1.0884e-02,  9.7850e-02, -3.5928e-02, -6.7029e-02, -8.4394e-02,\n",
      "         1.2855e-01,  6.8960e-02, -3.2721e-02,  2.4894e-02, -9.0627e-02,\n",
      "         7.5479e-03,  7.1138e-02,  1.1235e-01,  1.0261e-01,  1.2855e-01,\n",
      "        -4.9258e-02, -2.2115e-02,  2.4048e-04, -3.7961e-02,  3.6293e-02,\n",
      "         1.7304e-02,  1.5757e-02, -2.9064e-02, -4.0533e-02, -3.8555e-02,\n",
      "        -1.8389e-01,  3.8638e-02, -6.4055e-02, -7.7849e-02,  2.7176e-02,\n",
      "         1.1787e-01, -8.6906e-02, -5.0255e-02,  2.6346e-02,  9.4984e-02,\n",
      "        -1.0824e-03, -1.0523e-01,  1.1814e-01, -2.8148e-02,  3.8075e-02,\n",
      "         1.0993e-01,  1.2103e-01,  2.0071e-01, -4.9563e-02, -1.1158e-01,\n",
      "         8.1284e-02,  4.7860e-02, -6.9677e-02, -1.3837e-01,  5.6546e-02,\n",
      "         6.6781e-02,  3.1087e-02])\n",
      "trainable parameters: bert.encoder.layer.2.attention.self.key.weight tensor([[-0.0544,  0.0472,  0.0605,  ...,  0.0144,  0.0194, -0.0847],\n",
      "        [-0.0346,  0.0290, -0.0237,  ...,  0.0531, -0.0222,  0.0159],\n",
      "        [ 0.0126, -0.0320, -0.0395,  ..., -0.0473,  0.0336,  0.0766],\n",
      "        ...,\n",
      "        [-0.0830,  0.0321,  0.0107,  ...,  0.0546, -0.1895,  0.0438],\n",
      "        [ 0.0027, -0.0102, -0.1216,  ..., -0.0082,  0.0749, -0.0332],\n",
      "        [-0.0831, -0.0043, -0.0506,  ..., -0.0320, -0.0337,  0.1149]])\n",
      "trainable parameters: bert.encoder.layer.2.attention.self.key.bias tensor([-1.3582e-02,  1.8243e-02, -3.8712e-02, -2.5999e-02, -2.5417e-02,\n",
      "         2.1583e-02, -3.7696e-02,  5.6652e-02, -1.9050e-02, -4.7283e-02,\n",
      "         1.4785e-02,  1.2509e-03,  5.4618e-02,  3.6293e-02, -1.9574e-02,\n",
      "         2.2972e-03, -2.8737e-02, -2.1625e-02, -2.9827e-02, -9.4371e-04,\n",
      "        -2.2100e-02,  2.1434e-02,  8.3136e-02, -5.1403e-02, -1.5464e-02,\n",
      "         5.8276e-03, -1.3701e-02,  5.1362e-02, -1.6689e-02, -1.2939e-02,\n",
      "         3.0448e-02,  1.3547e-02,  1.6996e-03,  2.7274e-02, -1.0818e-02,\n",
      "        -5.8455e-02, -1.1506e-01, -5.5500e-03,  5.5142e-02, -5.3491e-02,\n",
      "        -3.5968e-02, -3.3258e-02, -2.2700e-02, -8.3444e-03,  8.5451e-03,\n",
      "         7.0905e-02, -5.2778e-02,  4.3290e-02, -2.4796e-02,  2.9703e-02,\n",
      "        -2.3138e-02,  2.5274e-02,  3.0928e-02, -9.2243e-02, -4.3797e-02,\n",
      "         3.7184e-02, -2.8854e-02, -6.2237e-02,  2.4999e-02, -4.1763e-02,\n",
      "        -2.6210e-02,  3.9323e-02, -1.6528e-02, -2.1515e-02, -4.0465e-02,\n",
      "        -4.2082e-03,  2.9626e-02,  4.7697e-02,  2.4076e-02, -1.0506e-03,\n",
      "        -3.3854e-02, -2.2277e-02,  4.1284e-02,  6.0155e-03,  2.9682e-02,\n",
      "        -4.1403e-02,  2.9640e-02, -4.8711e-02,  3.8655e-02, -2.4935e-02,\n",
      "         1.5572e-02,  1.1203e-02,  5.1292e-02,  7.0370e-02, -1.8457e-02,\n",
      "         4.0530e-02, -6.4722e-03, -1.5133e-02,  2.0010e-02,  3.8292e-02,\n",
      "         2.5729e-02, -4.6038e-02,  5.8333e-02, -2.1343e-02, -1.3122e-03,\n",
      "         4.4823e-02, -4.0343e-03,  1.5005e-02, -4.0442e-02, -3.6778e-03,\n",
      "         6.3052e-03, -1.2999e-02, -7.9816e-02, -2.8209e-02,  1.6729e-02,\n",
      "         1.3847e-03,  9.2568e-02,  6.3534e-04, -7.3590e-02, -2.9722e-02,\n",
      "         5.5278e-03, -7.5641e-02,  4.3795e-02,  2.2619e-03,  2.6359e-02,\n",
      "        -1.4499e-02, -2.6444e-02,  4.5598e-02,  2.8369e-02,  3.8815e-02,\n",
      "         6.4515e-02,  7.2055e-02, -2.2800e-02, -2.4574e-02,  4.4533e-02,\n",
      "        -2.1924e-02, -4.0762e-02,  8.5393e-03, -1.6594e-02,  2.6132e-02,\n",
      "         1.7154e-02, -1.4301e-02,  1.2281e-02, -1.2464e-02,  4.1675e-03,\n",
      "        -9.3707e-03, -1.9301e-02,  2.5081e-02, -5.5286e-03, -1.0472e-02,\n",
      "         1.8697e-03, -2.5542e-02,  7.0983e-03, -5.9769e-03,  8.3788e-03,\n",
      "         8.6335e-03,  7.1418e-03, -2.6672e-02,  1.2981e-02,  1.4247e-02,\n",
      "        -5.1476e-03, -4.7961e-03,  1.7657e-03, -1.9305e-02,  4.4912e-03,\n",
      "         7.6904e-03, -2.0523e-02, -9.2348e-03,  2.3837e-02,  1.3168e-02,\n",
      "         1.1604e-02, -8.1599e-03,  1.9379e-02,  2.1974e-02, -1.4678e-02,\n",
      "        -3.3535e-03,  1.6850e-02,  2.4164e-03, -1.1001e-02,  1.6970e-03,\n",
      "         1.3157e-03, -6.2269e-04,  4.0765e-03,  3.6507e-03, -9.7250e-03,\n",
      "        -1.8540e-02,  3.5222e-03,  2.2962e-02,  1.6757e-02,  4.8395e-03,\n",
      "        -5.7825e-03, -1.4635e-02,  9.5213e-03,  1.0197e-02, -9.9996e-03,\n",
      "         1.4100e-02,  5.1869e-03, -1.1231e-02, -2.1657e-02, -1.4883e-02,\n",
      "        -3.2422e-02, -3.3500e-03,  1.2799e-02, -6.1600e-03, -2.2012e-03,\n",
      "         2.0386e-02,  2.0739e-02, -1.4127e-02, -2.6015e-03,  2.0937e-02,\n",
      "        -1.5506e-02, -4.6604e-04,  2.3807e-02,  2.1264e-02, -1.5358e-02,\n",
      "        -5.3508e-02, -4.9251e-02, -1.3806e-02,  3.0974e-02,  2.1761e-02,\n",
      "         5.2081e-03, -1.5135e-02, -3.2539e-02,  3.5148e-03,  1.7390e-02,\n",
      "         2.2579e-02,  8.8138e-03, -3.8971e-03,  6.3291e-03, -5.4211e-02,\n",
      "        -4.9411e-03,  3.5442e-03, -2.0397e-02, -9.2383e-03, -2.6843e-02,\n",
      "        -6.4804e-02,  7.4308e-02,  2.5958e-02,  1.6907e-02,  2.3276e-02,\n",
      "        -3.8808e-02, -2.5313e-03,  1.0689e-04,  1.3302e-02,  7.0014e-02,\n",
      "        -3.5100e-03, -1.1992e-02, -1.9951e-02, -2.2592e-02,  1.6325e-02,\n",
      "        -4.2907e-02,  1.6727e-02,  4.0397e-02,  4.8234e-02, -1.4337e-02,\n",
      "         2.0634e-02,  1.7327e-02, -2.2443e-02,  3.2232e-02,  4.4966e-02,\n",
      "        -2.0636e-02,  3.1975e-02,  5.1035e-03,  5.9576e-03, -6.0157e-03,\n",
      "         5.2068e-02, -5.2664e-02, -1.1247e-03, -9.7392e-03, -4.3738e-02,\n",
      "        -4.7449e-02,  3.8855e-03, -3.1364e-02, -1.5739e-02,  2.8074e-02,\n",
      "         1.6295e-02, -2.4767e-02,  2.1059e-02,  2.5705e-02,  1.7330e-02,\n",
      "        -1.3446e-02,  2.8195e-02, -3.0895e-02,  2.1856e-02,  7.0046e-03,\n",
      "        -4.2857e-03,  1.6284e-02,  2.1931e-02, -1.0627e-02,  1.9551e-02,\n",
      "         4.9621e-02, -2.5257e-02, -2.6819e-02, -4.7115e-02, -3.0351e-02,\n",
      "        -3.9718e-03,  4.3117e-02,  3.8307e-02,  4.8379e-02, -4.3949e-02,\n",
      "        -2.3383e-02, -3.0190e-02, -1.6505e-02, -4.5911e-02,  6.8188e-02,\n",
      "        -1.3130e-02,  3.3447e-03, -6.9930e-03,  4.5183e-02, -1.2244e-02,\n",
      "         4.1333e-03,  8.1368e-03, -7.2848e-03, -5.1528e-02, -7.3327e-02,\n",
      "        -4.5525e-02,  6.0707e-02,  3.8010e-02,  5.5759e-03, -1.1702e-02,\n",
      "        -5.1420e-02, -4.0236e-02, -1.6350e-02,  1.2182e-02, -6.3929e-02,\n",
      "         9.9347e-03, -2.3118e-02,  8.8942e-03,  1.7372e-02,  3.1220e-02,\n",
      "         3.3982e-02, -2.1900e-02, -8.5031e-03,  1.1802e-02,  5.0447e-02,\n",
      "        -3.2444e-02,  2.5601e-02,  9.4912e-03, -5.4820e-02,  2.5581e-02,\n",
      "        -1.2653e-02,  3.2095e-02,  3.4697e-02, -3.4023e-02,  1.0277e-02,\n",
      "        -4.2074e-02, -3.9996e-02, -3.0014e-02, -9.3429e-03, -1.7809e-02,\n",
      "         9.7129e-05, -1.8995e-02,  3.5854e-02, -4.3500e-03, -4.8703e-02,\n",
      "        -8.1941e-03, -2.8612e-02, -9.8410e-03,  7.7366e-02,  7.8236e-03,\n",
      "         3.3526e-02, -4.7488e-02,  1.4890e-02, -5.5401e-02,  1.5489e-02,\n",
      "        -1.9355e-02, -1.4872e-02, -7.1783e-03, -5.0507e-02,  1.7865e-02,\n",
      "        -3.2212e-02,  3.2929e-03, -1.9696e-02, -1.0913e-02, -3.0559e-02,\n",
      "         1.9339e-02, -2.9521e-03, -1.9163e-02, -2.6003e-02, -1.8652e-03,\n",
      "        -2.1637e-03, -2.9853e-02,  2.2950e-02, -6.7310e-03, -4.0709e-02,\n",
      "        -2.8850e-02,  4.4289e-02,  5.1122e-02, -4.7280e-02,  2.9190e-02,\n",
      "         3.8721e-02, -4.1738e-02, -2.9012e-02,  3.3128e-04,  3.7143e-02,\n",
      "        -6.9830e-03,  1.7951e-02, -5.4363e-02, -5.6041e-02, -1.1704e-02,\n",
      "        -3.5383e-02,  1.1312e-02, -2.7713e-02, -1.7896e-02, -1.1341e-02,\n",
      "         2.0762e-02, -1.1726e-02, -1.8332e-02,  1.0813e-02,  9.5706e-03,\n",
      "        -6.3946e-03,  1.0122e-02,  7.2556e-03,  6.4389e-03, -5.2725e-03,\n",
      "        -1.6298e-02,  2.2650e-02, -1.2146e-02, -2.0629e-02, -2.6045e-03,\n",
      "        -2.7109e-02, -1.0569e-03,  1.2155e-02,  2.3060e-02,  2.2411e-02,\n",
      "        -1.5220e-02, -1.7372e-02,  6.8078e-03,  2.3989e-02,  2.2753e-02,\n",
      "        -2.5973e-02, -9.7467e-03,  2.9451e-02,  3.4926e-02, -4.6484e-02,\n",
      "         2.0204e-02,  1.4008e-03,  6.2949e-04,  3.4792e-02,  3.2294e-02,\n",
      "         2.7246e-02, -3.2817e-02, -2.7637e-02, -1.5569e-02,  8.2462e-03,\n",
      "        -2.8235e-02,  5.3217e-03,  2.6336e-02, -1.3387e-02,  6.9415e-03,\n",
      "         3.9890e-03, -1.1198e-02,  6.5917e-02,  9.5319e-03, -1.7664e-04,\n",
      "        -2.3990e-02,  2.4891e-03,  7.7810e-03,  1.3511e-02,  1.4917e-02,\n",
      "         1.1392e-03,  1.8714e-02,  7.9727e-03,  8.8504e-03, -2.4924e-02,\n",
      "        -1.8593e-03, -4.4160e-03,  1.3869e-02,  3.4947e-03,  6.3217e-03,\n",
      "         2.1330e-02,  9.0850e-03,  1.1517e-02,  8.3578e-03, -1.0909e-02,\n",
      "        -5.1753e-04,  1.0164e-02, -7.2878e-03,  5.1644e-03, -1.0067e-02,\n",
      "         6.6587e-03,  2.8452e-02,  2.4350e-02, -2.1468e-03,  4.7927e-03,\n",
      "         7.7926e-03, -6.9684e-03,  4.6627e-04,  1.3619e-02,  9.9315e-03,\n",
      "        -1.6957e-02,  2.7607e-03, -1.7911e-02, -1.5246e-02, -1.2891e-02,\n",
      "        -2.2716e-03,  4.8926e-03, -2.5313e-03,  1.5548e-02, -7.5253e-03,\n",
      "         6.7146e-03,  4.2851e-03,  9.2304e-03,  9.0864e-03, -1.0380e-02,\n",
      "        -2.3282e-02, -1.0051e-02,  2.8470e-03, -7.5220e-03, -1.7387e-03,\n",
      "         2.1099e-02,  6.7190e-03, -2.9544e-03, -1.3889e-03, -7.1899e-03,\n",
      "         5.6537e-03,  3.4386e-02,  1.4210e-02, -3.4804e-03, -1.4429e-03,\n",
      "        -3.5724e-03, -1.8011e-03])\n",
      "trainable parameters: bert.encoder.layer.2.attention.self.value.weight tensor([[ 0.0175, -0.0021,  0.0202,  ...,  0.0964, -0.0843, -0.0310],\n",
      "        [-0.0257, -0.0389, -0.0593,  ..., -0.0076, -0.0751, -0.0256],\n",
      "        [ 0.0260,  0.0504, -0.0044,  ..., -0.0825, -0.0159, -0.0137],\n",
      "        ...,\n",
      "        [-0.0036,  0.0017, -0.0178,  ...,  0.0450, -0.0208,  0.0189],\n",
      "        [ 0.0307,  0.0308, -0.0034,  ..., -0.0163,  0.0043,  0.0146],\n",
      "        [-0.0519,  0.0066, -0.0209,  ..., -0.0425, -0.0011,  0.0258]])\n",
      "trainable parameters: bert.encoder.layer.2.attention.self.value.bias tensor([ 1.3177e-01, -1.1330e-01,  1.6342e-02, -5.2674e-02, -1.9566e-03,\n",
      "        -7.0632e-04, -7.6717e-02,  1.9040e-02,  9.8856e-03, -4.2072e-02,\n",
      "         4.9174e-03, -1.0462e-02, -8.6719e-03, -1.7385e-02,  1.4777e-01,\n",
      "         2.7575e-02,  5.5254e-02,  2.1371e-02,  3.5757e-02, -5.0506e-02,\n",
      "        -4.4861e-02, -1.1341e-01,  1.0212e-01, -5.7793e-02, -2.8159e-02,\n",
      "        -7.9446e-02, -7.1407e-02,  6.2574e-02,  1.1016e-02,  6.0677e-02,\n",
      "        -8.1849e-03, -1.7424e-02,  5.3960e-02,  1.1807e-01,  1.8498e-02,\n",
      "         7.7456e-02, -3.5034e-02, -2.4709e-02,  2.2052e-02, -1.3022e-02,\n",
      "         1.6400e-03, -3.8422e-03, -2.9302e-02, -3.8680e-02,  1.2049e-01,\n",
      "        -6.7852e-02, -5.2742e-03,  1.5810e-02,  5.8982e-02,  7.3538e-02,\n",
      "         1.0961e-01, -3.8801e-02, -4.9491e-02, -4.0972e-02,  3.3841e-02,\n",
      "         1.0087e-02,  5.1202e-02, -1.1929e-01,  5.5090e-03,  1.1575e-02,\n",
      "         2.8920e-02,  3.1566e-04, -7.2192e-02, -3.1324e-02, -6.9285e-03,\n",
      "         4.8661e-03,  1.0538e-02, -1.7829e-02, -3.6525e-02,  4.4670e-02,\n",
      "        -2.8658e-02,  5.9672e-03, -2.4586e-02, -2.8344e-02, -1.7736e-02,\n",
      "         2.2710e-03, -1.1037e-02, -5.2613e-02,  2.9435e-02, -1.0597e-01,\n",
      "         4.2763e-02, -3.0310e-02,  1.6948e-02,  1.6315e-02,  3.7821e-02,\n",
      "        -2.7038e-03, -1.9029e-02, -2.0858e-02,  5.3563e-02,  1.0352e-02,\n",
      "        -2.0388e-02, -1.4861e-02,  8.9836e-04, -3.6694e-02,  9.0969e-03,\n",
      "        -1.4179e-03, -8.5728e-03, -7.2624e-03, -1.4363e-02,  3.8167e-02,\n",
      "         2.1271e-02, -3.0154e-02,  3.6854e-02, -4.2548e-02,  1.1766e-03,\n",
      "        -1.2189e-02,  2.5088e-03,  2.0020e-02, -3.8939e-02, -2.0960e-02,\n",
      "        -9.0891e-02,  6.5990e-03,  1.5247e-02, -9.1910e-02, -1.8665e-02,\n",
      "        -5.9841e-03, -3.1727e-02,  4.0547e-02, -5.2186e-03,  9.0900e-03,\n",
      "        -6.8720e-02, -7.6750e-03, -2.2524e-02, -7.6272e-02, -1.0731e-02,\n",
      "        -1.6224e-02,  1.0608e-02,  1.1228e-02,  5.2179e-02,  1.7612e-01,\n",
      "        -4.5914e-02, -7.4990e-02, -1.8764e-02,  6.3621e-02,  6.2422e-02,\n",
      "        -1.5762e-01,  1.4495e-01, -9.0562e-02, -1.6716e-03, -2.0071e-02,\n",
      "         1.1261e-01,  2.0691e-02, -8.0444e-02,  1.2111e-01,  1.9214e-01,\n",
      "         1.1285e-01, -9.4287e-02, -1.2566e-01, -9.4545e-02,  7.2284e-02,\n",
      "         1.1493e-01, -2.3985e-02, -2.4257e-01,  9.5004e-02, -3.7741e-05,\n",
      "        -1.5546e-01, -1.3536e-01,  7.2159e-02,  4.6357e-02,  5.7344e-02,\n",
      "         6.8538e-02, -1.0912e-01,  1.0217e-01,  9.9423e-02,  1.8021e-02,\n",
      "        -2.8217e-03, -3.1526e-02, -3.8188e-02,  1.5617e-02,  4.7142e-02,\n",
      "        -1.5558e-01,  3.9981e-02,  7.0274e-02,  5.5847e-02, -7.9459e-02,\n",
      "        -7.0747e-02,  2.4835e-02, -3.2413e-01,  4.7863e-02,  2.7844e-02,\n",
      "        -1.3540e-02, -2.0662e-02,  1.0883e-01, -1.4195e-02,  7.9628e-02,\n",
      "        -9.7166e-02,  6.3899e-02, -1.2027e-01,  3.8431e-01, -4.9069e-02,\n",
      "        -1.6914e-01, -5.9617e-02,  7.3008e-03,  2.2269e-02,  1.6560e-02,\n",
      "        -1.9373e-02, -4.2822e-02,  2.3052e-02, -1.1784e-02,  2.1143e-02,\n",
      "         5.3803e-02,  1.9396e-02,  1.0038e-02,  1.0489e-02,  1.0819e-02,\n",
      "        -2.5612e-04,  5.5188e-03, -4.4236e-03, -1.5100e-02,  7.5900e-03,\n",
      "         3.5343e-02, -1.2501e-02, -2.1667e-02, -1.5365e-02, -7.4376e-03,\n",
      "         1.5402e-02,  2.7187e-03, -1.7200e-02, -1.5976e-03,  3.9297e-03,\n",
      "        -1.0877e-02, -8.5833e-03, -1.6222e-02,  2.7047e-02,  1.6120e-02,\n",
      "        -1.5561e-02,  7.2650e-03,  1.0094e-02,  8.9594e-03,  9.1009e-03,\n",
      "        -1.0783e-02,  2.6357e-03,  2.1115e-02, -3.3373e-02, -2.4166e-03,\n",
      "        -1.7846e-03, -2.1317e-03,  1.2471e-02,  9.4895e-04,  2.6678e-02,\n",
      "         2.6738e-02,  6.2576e-03, -9.2743e-03, -2.6695e-02,  2.4296e-02,\n",
      "         2.2058e-03, -8.2118e-04, -3.0145e-03,  1.2641e-02, -2.0539e-02,\n",
      "        -1.2749e-02, -1.4455e-02,  1.2053e-02,  1.1422e-02, -2.9665e-02,\n",
      "        -7.8360e-03,  3.8316e-03, -7.1809e-02,  5.3367e-03,  2.4490e-02,\n",
      "        -2.6494e-02, -3.2943e-02,  4.1312e-05, -4.0622e-02, -2.8445e-02,\n",
      "         1.1129e-02,  2.0317e-02, -1.5353e-02, -2.0028e-02,  1.4570e-02,\n",
      "         7.8987e-02,  2.1907e-02, -2.0383e-02, -2.8253e-02, -2.8591e-02,\n",
      "         3.9050e-02, -5.4162e-02,  2.6378e-02,  4.0269e-02,  2.9584e-02,\n",
      "        -2.7171e-02, -3.5278e-02, -2.2964e-03, -1.7049e-02, -2.2044e-02,\n",
      "        -2.9002e-02,  2.0211e-02, -5.5772e-02, -2.4041e-02, -2.1869e-02,\n",
      "         4.8443e-02,  2.3176e-02, -3.8391e-03,  4.3963e-03, -5.0724e-02,\n",
      "        -4.0319e-02,  3.8550e-02,  2.2765e-02, -1.1518e-02,  8.5229e-03,\n",
      "         1.8038e-02,  3.0800e-02,  1.3663e-02,  3.5263e-03,  1.1169e-02,\n",
      "         2.9324e-03,  4.4755e-02,  5.3604e-03,  5.0212e-02,  2.0621e-02,\n",
      "        -4.7100e-02, -2.4746e-03, -8.4908e-03,  5.6873e-03,  5.9803e-02,\n",
      "        -4.3030e-02, -5.5463e-02,  5.2792e-02,  4.2475e-03, -4.7188e-02,\n",
      "        -7.5674e-02, -9.0800e-02, -1.3374e-01, -3.4908e-02,  9.1950e-02,\n",
      "        -8.7210e-02,  2.2639e-02, -4.6850e-02, -2.8346e-02, -8.2629e-03,\n",
      "        -3.5518e-02, -1.2676e-01, -3.7950e-02,  4.8816e-02, -4.2876e-02,\n",
      "        -2.4322e-03,  2.3942e-02, -1.0919e-01,  2.2376e-02, -1.2896e-02,\n",
      "         7.6107e-02, -2.4571e-02, -9.3516e-03,  2.2564e-02,  2.2836e-03,\n",
      "         4.0647e-02, -6.8949e-02,  3.5962e-02,  6.3728e-02, -7.2451e-02,\n",
      "         1.6304e-02,  3.7351e-02,  7.4663e-03,  5.4673e-02,  1.0747e-01,\n",
      "         1.9072e-02, -4.8591e-02,  3.1537e-02, -1.8712e-01, -3.4367e-01,\n",
      "        -7.1840e-02, -5.1720e-02, -6.5882e-02,  1.1110e-01,  1.4132e-01,\n",
      "        -2.1416e-03,  1.3044e-02,  6.1644e-02, -3.0450e-02, -2.7923e-02,\n",
      "        -1.3127e-01,  1.2338e-02,  1.4828e-01,  4.3015e-02,  3.2610e-02,\n",
      "         9.4043e-02,  9.0909e-02, -7.1795e-02,  8.2242e-02, -2.0711e-02,\n",
      "        -4.2585e-02,  7.3658e-02, -1.7443e-01, -3.3501e-02, -2.5350e-02,\n",
      "         1.2982e-01,  6.5485e-02,  4.0988e-01,  7.8660e-02,  9.6770e-02,\n",
      "        -1.9021e-02,  9.4611e-02,  7.7823e-02, -4.5767e-02, -6.6142e-03,\n",
      "         3.3142e-02, -1.2396e-02,  2.7362e-02, -8.1490e-02,  1.1191e-01,\n",
      "        -3.8931e-02, -4.4957e-02, -3.3852e-02, -7.6310e-02,  3.4438e-02,\n",
      "        -6.3157e-02,  2.2575e-02, -5.3861e-02,  2.5373e-02,  4.0702e-02,\n",
      "         7.0833e-02,  2.1661e-02,  1.2196e-01,  2.3474e-02,  1.6660e-01,\n",
      "        -4.6984e-02,  7.8973e-02,  1.3632e-01,  9.8115e-02, -1.7137e-01,\n",
      "        -1.8019e-02,  4.5603e-02, -9.7409e-02,  4.6198e-02, -2.0333e-02,\n",
      "        -1.3877e-01,  2.2900e-02, -8.2334e-02,  2.5460e-02,  2.2058e-03,\n",
      "         7.3921e-02,  1.1712e-01, -9.3721e-02,  1.7367e-02,  1.2044e-02,\n",
      "        -8.8404e-02,  1.3382e-01, -1.0211e-01, -5.6774e-02, -3.7698e-02,\n",
      "         6.6932e-03,  1.6374e-02,  3.1999e-02,  9.8221e-02,  2.2323e-02,\n",
      "         1.2928e-01, -4.2344e-02, -1.1896e-02, -1.2663e-01,  1.3927e-02,\n",
      "         2.9545e-02,  3.4953e-02,  5.4628e-02,  2.8023e-01,  1.5492e-01,\n",
      "         1.9039e-01, -2.3421e-01, -1.4154e-02, -6.3387e-02,  4.0119e-02,\n",
      "         2.5034e-02,  1.9409e-01,  8.9000e-02, -2.6058e-01, -1.6312e-01,\n",
      "         9.7639e-02,  2.2550e-02, -1.1270e-01,  4.3735e-02,  4.4457e-02,\n",
      "         1.8823e-01, -1.0046e-01,  1.3022e-01,  1.6090e-01, -1.5250e-03,\n",
      "        -1.2690e-01, -1.6435e-02,  9.7584e-02,  1.2120e-01,  6.7715e-02,\n",
      "        -1.0626e-01, -6.9249e-02,  1.1493e-01,  1.6347e-02, -5.0627e-02,\n",
      "         4.5912e-02, -1.7365e-01,  5.1340e-02, -7.1359e-02,  4.6390e-02,\n",
      "        -1.8080e-01, -2.6226e-01,  7.7482e-02,  8.2737e-02,  3.8058e-02,\n",
      "        -6.1040e-03,  1.2849e-01,  4.3215e-02,  3.7409e-01, -1.0705e-01,\n",
      "        -2.4313e-01, -1.3835e-02, -4.6850e-02,  7.2390e-02, -6.0550e-02,\n",
      "         1.3984e-02, -4.0549e-02, -7.8598e-03,  1.2699e-02, -2.1375e-03,\n",
      "         7.5277e-02,  4.5466e-02])\n",
      "trainable parameters: bert.encoder.layer.2.attention.output.dense.weight tensor([[ 0.0353,  0.0182,  0.0023,  ...,  0.0448, -0.0175, -0.0024],\n",
      "        [-0.0068,  0.0340,  0.0231,  ..., -0.0186, -0.0256, -0.0092],\n",
      "        [-0.0363,  0.0265,  0.0274,  ...,  0.0390, -0.0421,  0.0456],\n",
      "        ...,\n",
      "        [ 0.0410,  0.0369, -0.0035,  ...,  0.0295, -0.0100,  0.0022],\n",
      "        [ 0.0530, -0.0493,  0.0407,  ..., -0.0107, -0.0037, -0.0099],\n",
      "        [ 0.0029,  0.0532, -0.0506,  ...,  0.0188,  0.0363, -0.0285]])\n",
      "trainable parameters: bert.encoder.layer.2.attention.output.dense.bias tensor([-8.6492e-02,  5.4309e-02,  1.9556e-01, -5.2534e-02,  5.2886e-02,\n",
      "        -9.9790e-02,  9.3717e-02, -1.8711e-01,  2.6272e-02, -1.2686e-01,\n",
      "        -8.4951e-02,  7.2412e-03, -2.3538e-02,  9.6631e-02, -8.4519e-02,\n",
      "        -3.5072e-02, -4.8237e-03,  2.8229e-02,  1.1830e-02, -6.3208e-02,\n",
      "         1.3195e-01,  1.4087e-01,  1.6655e-01, -1.8450e-01, -2.0535e-02,\n",
      "         3.2296e-01,  7.6455e-02, -1.2177e-03,  5.3407e-02,  7.2538e-02,\n",
      "        -6.6931e-02, -3.1193e-01,  1.1300e-01,  8.2446e-02, -1.9978e-02,\n",
      "        -1.1196e-02, -1.8263e-01,  1.5337e-01, -1.1995e-01,  1.6777e-02,\n",
      "        -5.0994e-02, -8.8120e-02, -5.9758e-02, -5.7054e-02, -3.0944e-02,\n",
      "        -1.4159e-01, -2.1452e-01, -3.4424e-02,  2.4596e-01, -1.0010e-01,\n",
      "        -1.8051e-01,  1.0357e-01,  1.4321e-02,  1.2673e-01,  7.8798e-02,\n",
      "        -1.8233e-01,  1.5913e-01,  7.4409e-03, -2.6362e-01, -5.1748e-02,\n",
      "        -1.9676e-02,  2.5100e-02, -8.4340e-02, -1.2485e-01, -2.0757e-01,\n",
      "         2.2372e-01,  6.2113e-02, -1.5626e-01,  2.6087e-02, -1.6037e-02,\n",
      "         6.7447e-02,  5.9007e-02,  3.2888e-02,  1.4333e-01,  6.7905e-02,\n",
      "         1.4884e-01,  2.3093e-01,  8.7814e-02,  2.7177e-02, -3.6181e-02,\n",
      "        -2.5682e-01, -1.6966e-02,  7.0798e-02,  6.6754e-02,  5.2922e-02,\n",
      "        -1.5321e-02, -2.9152e-02, -3.9520e-04,  6.7542e-02, -7.3191e-02,\n",
      "         1.8501e-01,  1.7830e-01,  1.2125e-02,  5.7926e-02, -1.1549e-01,\n",
      "         3.0726e-01, -9.3134e-02, -1.9121e-01,  2.2235e-01, -6.4711e-02,\n",
      "         1.2076e-01, -1.0800e-01,  1.1571e-01, -1.4783e-01, -8.3401e-02,\n",
      "         2.3620e-01, -6.6573e-02,  4.2500e-03,  1.2967e-01,  7.1308e-02,\n",
      "         9.7115e-03,  7.4435e-02,  8.6734e-03,  5.0480e-02, -3.6004e-02,\n",
      "         4.1592e-02, -9.3205e-02,  1.1082e-01, -5.8513e-02, -1.0507e-01,\n",
      "        -6.7716e-02,  1.9691e-01,  1.4930e-01,  1.6466e-01,  5.4580e-02,\n",
      "        -4.7805e-02,  1.0157e-01, -7.7116e-02, -5.0356e-02, -1.3613e-01,\n",
      "         6.4498e-02, -2.0764e-02,  7.3832e-02,  4.1160e-02, -5.7007e-01,\n",
      "        -8.9587e-02,  4.4953e-02, -2.6968e-02,  2.7563e-02, -1.7281e-01,\n",
      "        -5.1599e-02, -7.6069e-03,  1.7561e-01,  2.6001e-02, -1.6635e-01,\n",
      "        -3.9994e-02,  1.1771e-01, -2.3738e-02, -1.1979e-01,  2.3874e-02,\n",
      "        -8.4356e-02, -1.4683e-01,  8.3951e-02, -1.6727e-01,  1.8757e-02,\n",
      "        -7.8824e-02, -4.0895e-01,  1.8579e-01, -1.7551e-01, -3.1615e-02,\n",
      "        -7.8765e-02,  1.9671e-01,  9.2827e-02, -1.1180e-01,  1.9902e-01,\n",
      "         1.7910e-01, -1.6652e-01, -4.5398e-02,  4.0038e-01, -1.0721e-01,\n",
      "        -5.3676e-02, -1.8469e-01,  4.4043e-02, -1.5499e-01, -9.1972e-02,\n",
      "        -3.4111e-01,  2.5630e-02,  1.2482e-01, -1.0120e-01,  2.2668e-01,\n",
      "         6.3034e-02, -1.6570e-01, -5.7695e-02,  2.1351e-01, -1.1757e-01,\n",
      "        -3.4161e-02, -1.3160e-01, -2.0458e-01,  3.5617e-01, -2.7169e-02,\n",
      "         6.0642e-02, -4.8285e-02,  1.4997e-01,  4.3617e-01,  8.1516e-02,\n",
      "         1.0386e-01,  1.5787e-02,  1.0142e-01,  6.0050e-02,  1.0254e-01,\n",
      "        -8.9212e-02, -8.9792e-02,  7.7639e-02, -1.7994e-01,  1.0993e-02,\n",
      "        -2.6391e-01, -1.2641e-01,  5.1746e-02, -5.3989e-02,  7.3661e-02,\n",
      "         2.0010e-01, -4.6054e-02, -1.7415e-02,  1.9112e-01,  1.3923e-01,\n",
      "         4.6390e-02,  3.6312e-03,  1.7931e-01,  6.6572e-02,  7.8363e-02,\n",
      "        -1.6305e-01, -7.6120e-02,  7.7184e-02, -6.2072e-02, -5.7913e-02,\n",
      "        -1.1287e-01,  1.1522e-01,  1.1924e-01,  3.1827e-03,  1.1418e-01,\n",
      "        -5.8686e-02,  2.5494e-01, -7.8183e-04, -1.1554e-01,  1.8567e-01,\n",
      "         8.3264e-02,  2.9253e-01,  1.7338e-02,  1.1537e-02,  3.8192e-03,\n",
      "         5.3983e-02,  4.9404e-02, -3.7390e-02,  1.7003e-01, -1.9893e-01,\n",
      "        -1.9559e-02, -2.8586e-02,  2.0142e-02, -7.0604e-02, -9.1153e-02,\n",
      "         5.3102e-02, -7.5939e-02,  1.6535e-01, -2.2043e-02,  1.6848e-01,\n",
      "         1.9785e-02, -9.2900e-02, -8.9298e-02,  1.9451e-02, -5.5433e-02,\n",
      "         4.3930e-02,  5.8940e-02, -4.9241e-01, -1.6116e-01,  1.2414e-01,\n",
      "        -1.5947e-01,  1.7838e-01,  1.1819e-01, -1.0211e-02,  6.5257e-03,\n",
      "        -5.0888e-02,  6.3822e-02,  5.2793e-02, -1.7855e-02,  4.8890e-02,\n",
      "        -4.1962e-01,  7.9777e-01,  8.0480e-02,  7.5483e-02,  2.5602e-03,\n",
      "        -5.5050e-02,  1.9781e-01,  1.0759e-01, -4.8773e-02, -1.1620e-01,\n",
      "        -1.0713e-01,  1.2286e-01,  2.3201e-01, -1.8421e-01,  1.4410e-01,\n",
      "        -1.0624e-01,  5.1961e-02, -1.5350e-01, -1.4777e-01,  2.4446e-02,\n",
      "        -7.5138e-02,  9.2587e-02,  1.3802e-01, -1.6711e-01,  1.6551e-01,\n",
      "         8.7329e-03,  1.1790e-01, -6.8474e-02, -2.8770e-02, -8.3017e-03,\n",
      "        -1.6251e-01, -5.2449e-02,  1.3705e-01,  7.4732e-02, -2.0919e-02,\n",
      "        -4.0606e-03,  1.4338e-01,  1.4045e-02,  1.7087e-01, -2.6518e-02,\n",
      "         8.7728e-04, -1.3705e-01,  4.6062e-03, -1.8532e-01, -1.5886e-02,\n",
      "         2.2987e-02,  3.8062e-02,  1.4250e-01,  1.8284e-02, -3.9081e-02,\n",
      "        -7.8403e-02,  1.8485e-01,  1.9305e-01, -6.5406e-02, -7.4368e-02,\n",
      "        -5.5790e-02, -1.1475e-01, -1.1908e-01, -3.2907e-02, -1.4594e-01,\n",
      "         8.0883e-03,  1.5513e-02,  7.5814e-02,  2.0729e-02, -1.0970e-01,\n",
      "         6.9243e-02,  1.8822e-02, -4.5927e-02,  8.5758e-02,  6.0351e-02,\n",
      "        -9.1477e-02,  1.1924e-01,  4.5063e-02, -7.6894e-02, -7.0972e-02,\n",
      "        -1.0283e-01, -1.6417e-01, -2.7620e-02,  8.3121e-02, -2.7871e-01,\n",
      "         1.4412e-01, -2.3762e-01, -6.5708e-02, -9.0776e-02,  3.4312e-02,\n",
      "         8.1229e-03, -1.4891e-01, -8.4368e-02, -4.4358e-02, -1.4449e-02,\n",
      "        -1.9949e-01,  1.8486e-02,  3.4022e-02, -1.1803e-02, -1.9610e-01,\n",
      "         8.4171e-03,  2.3502e-02,  1.3272e-01,  1.5384e-01, -1.4325e-01,\n",
      "         5.0053e-03, -7.3326e-02,  7.2921e-02, -1.1671e-01,  1.9375e-01,\n",
      "         8.5767e-02, -1.5389e-01,  8.7207e-03, -1.9867e-02, -3.5011e-01,\n",
      "        -1.6280e-01, -2.5451e-02,  1.1792e-03, -4.1284e-02,  1.2913e-01,\n",
      "        -1.0135e-01, -7.5461e-02, -9.4012e-02,  1.9449e-01,  1.0381e-01,\n",
      "         1.3058e-01, -2.8678e-02, -7.4729e-03,  1.1390e-01,  1.3033e-01,\n",
      "         8.0023e-02, -7.1906e-02,  2.2552e-01,  1.1696e-01, -2.7563e-02,\n",
      "        -7.1381e-02,  5.2150e-02,  6.6685e-02, -3.5627e-02,  5.6116e-02,\n",
      "        -5.3560e-02, -8.1469e-02,  9.7503e-03, -4.9344e-02, -1.4867e-02,\n",
      "         5.5670e-02, -1.9556e-02, -2.3628e-02, -2.1073e-01,  9.2350e-02,\n",
      "        -1.5630e-01,  1.9244e-01, -7.7076e-02, -7.6356e-02, -1.9473e-01,\n",
      "        -1.2839e-01, -2.4145e-01, -1.4640e-01,  4.4421e-02, -7.3241e-02,\n",
      "         1.5093e-01,  3.3194e-02,  3.7523e-02, -1.3658e-02,  6.6217e-02,\n",
      "        -9.6472e-04,  1.4638e-02,  9.2476e-02, -7.4461e-02,  1.0899e-01,\n",
      "        -9.7035e-02,  1.5101e-01,  2.1145e-01,  1.2187e-01, -7.7473e-01,\n",
      "         1.0282e-01,  2.4538e-01, -5.6205e-02, -1.5757e-01, -6.9465e-02,\n",
      "        -6.6123e-02, -2.2741e-01, -5.7125e-02,  6.7341e-02, -2.9014e-01,\n",
      "         4.1172e-02,  1.2672e-01, -2.2585e-01, -5.7076e-02,  9.5766e-02,\n",
      "        -4.5440e-03, -2.3654e-02, -1.5336e-01, -1.9981e-01,  2.9312e-02,\n",
      "         4.9908e-02,  1.5538e-01, -1.2473e-01, -4.8416e-03, -1.1084e-02,\n",
      "         1.3768e-02, -2.6271e-02, -2.5040e-01,  2.0195e-02,  2.9937e-02,\n",
      "        -5.5309e-02,  2.3775e-01, -6.9311e-02,  3.6679e-02,  1.5656e-01,\n",
      "        -9.5113e-03, -9.9355e-02,  2.0905e-01, -1.0188e-02,  1.0685e-01,\n",
      "         3.5620e-02, -5.7456e-02,  1.4312e-02,  2.3712e-02, -2.0324e-01,\n",
      "         2.8173e-01, -1.2215e-01, -7.9313e-02,  5.0049e-03, -1.1639e-01,\n",
      "         1.1002e-01,  1.6314e-02,  2.0834e-01, -6.7942e-02, -5.6372e-02,\n",
      "        -2.4969e-01,  7.0810e-02,  8.8311e-02,  6.6575e-02,  1.2620e-01,\n",
      "         1.4856e-01, -1.3006e-01, -1.8583e-01, -3.2715e-02, -5.1556e-02,\n",
      "        -1.5783e-02, -1.4308e-01])\n",
      "trainable parameters: bert.encoder.layer.2.attention.output.LayerNorm.weight tensor([0.8500, 0.7743, 0.8150, 0.7790, 0.8366, 0.7824, 0.8221, 0.7687, 0.7947,\n",
      "        0.8321, 0.8501, 0.8218, 0.8172, 0.8408, 0.8536, 0.8118, 0.8406, 0.8278,\n",
      "        0.8107, 0.8326, 0.8000, 0.8256, 0.8048, 0.7374, 0.8588, 0.8818, 0.8514,\n",
      "        0.8284, 0.8370, 0.8461, 0.8175, 0.6995, 0.8625, 0.8768, 0.8671, 0.8406,\n",
      "        0.7766, 0.7372, 0.8380, 0.8062, 0.8272, 0.8306, 0.8143, 0.8147, 0.8438,\n",
      "        0.8273, 0.7994, 0.8436, 0.8233, 0.8912, 0.8305, 0.8329, 0.7984, 0.8470,\n",
      "        0.8035, 0.8156, 0.8119, 0.8287, 0.8329, 0.7789, 0.8465, 0.8499, 0.8072,\n",
      "        0.8451, 0.8433, 0.7925, 0.8166, 0.8172, 0.8335, 0.8186, 0.8149, 0.8301,\n",
      "        0.7752, 0.8213, 0.7917, 0.8391, 0.8394, 0.8362, 0.8422, 0.7921, 0.8142,\n",
      "        0.7958, 0.8201, 0.8190, 0.8469, 0.8122, 0.7800, 0.7866, 0.8308, 0.8042,\n",
      "        0.8338, 0.7829, 0.7928, 0.8065, 0.8491, 0.8468, 0.7867, 0.8399, 0.8829,\n",
      "        0.7951, 0.8508, 0.8254, 0.7929, 0.8057, 0.8715, 0.7816, 0.8361, 0.8174,\n",
      "        0.8107, 0.8514, 0.8026, 0.7383, 0.8065, 0.8563, 0.8364, 0.8286, 0.8321,\n",
      "        0.9104, 0.7860, 0.8589, 0.7534, 0.8690, 0.8365, 0.8066, 0.7844, 0.8475,\n",
      "        0.8218, 0.8286, 0.8258, 0.8342, 0.8527, 0.8355, 0.8164, 0.8582, 0.7834,\n",
      "        0.7870, 0.8212, 0.8286, 0.8187, 0.8695, 0.8208, 0.8256, 0.8512, 0.7618,\n",
      "        0.8337, 0.7969, 0.8476, 0.7874, 0.7817, 0.8480, 0.7790, 0.7802, 0.8232,\n",
      "        0.8156, 0.8008, 0.8174, 0.8446, 0.7837, 0.8289, 0.8391, 0.8219, 0.8361,\n",
      "        0.7858, 0.8278, 0.7865, 0.7856, 0.8624, 0.8005, 0.8272, 0.8105, 0.8398,\n",
      "        0.9631, 0.8210, 0.8502, 0.7991, 0.8457, 0.8286, 0.8395, 0.8164, 0.8228,\n",
      "        0.8289, 0.7562, 0.8506, 0.8107, 0.8101, 0.8079, 0.8117, 0.7525, 0.8897,\n",
      "        0.7929, 0.7821, 0.8550, 0.7707, 0.7911, 0.7938, 0.8457, 0.8300, 0.7943,\n",
      "        0.8219, 0.8563, 0.8072, 0.8423, 0.8361, 0.7249, 0.8136, 0.7704, 0.8446,\n",
      "        0.8239, 0.8059, 0.7826, 0.8597, 0.8300, 0.8005, 0.8423, 0.8012, 0.8012,\n",
      "        0.8119, 0.8448, 0.8035, 0.7729, 0.8005, 0.7863, 0.8118, 0.8096, 0.8412,\n",
      "        0.8337, 0.8136, 0.8660, 0.8065, 0.8466, 0.7794, 0.8288, 0.8347, 0.8382,\n",
      "        0.7950, 0.8657, 0.8215, 0.8294, 0.8171, 0.8090, 0.8432, 0.8363, 0.8293,\n",
      "        0.9228, 0.8161, 0.7431, 0.8225, 0.7992, 0.8117, 0.8235, 0.8502, 0.8224,\n",
      "        0.7887, 0.8088, 0.8507, 0.8532, 0.8267, 0.7739, 0.8046, 0.8483, 0.7309,\n",
      "        0.8363, 0.8019, 0.8798, 0.7983, 0.8102, 0.8562, 0.7911, 0.8801, 0.8350,\n",
      "        0.8571, 0.8190, 0.8500, 0.8612, 0.8264, 1.4114, 1.3416, 0.8282, 0.8036,\n",
      "        0.8641, 0.8089, 0.8316, 0.8752, 0.8174, 0.8429, 0.8102, 0.8090, 0.8424,\n",
      "        0.8813, 0.8305, 0.7774, 0.8399, 0.8223, 0.8322, 0.8238, 0.8129, 0.8224,\n",
      "        0.8618, 0.8305, 0.8412, 0.8606, 0.8730, 0.7958, 0.8130, 0.8038, 0.8038,\n",
      "        0.8121, 0.7742, 0.8207, 0.7865, 0.8343, 0.8334, 0.7985, 0.8510, 0.7968,\n",
      "        0.8387, 0.8725, 0.8632, 0.8513, 0.8010, 0.7896, 0.8067, 0.8332, 0.8143,\n",
      "        0.8095, 0.8151, 0.8826, 0.8143, 0.7340, 0.8490, 0.8279, 0.8295, 0.8783,\n",
      "        0.8265, 0.7262, 0.7847, 0.8154, 0.8227, 0.8862, 0.8494, 0.8597, 0.8304,\n",
      "        0.8409, 0.7930, 0.8338, 0.8396, 0.8083, 0.8734, 0.8291, 0.8098, 0.8031,\n",
      "        0.8822, 0.8605, 0.8113, 0.8836, 0.7989, 0.9395, 0.8187, 0.7982, 0.8233,\n",
      "        0.8306, 0.7782, 0.8029, 0.8100, 0.8509, 0.8358, 0.8367, 0.7497, 0.8246,\n",
      "        0.8093, 0.8286, 0.8032, 0.8889, 0.8529, 0.8205, 0.8942, 0.8235, 0.8506,\n",
      "        0.8159, 0.8195, 0.8437, 0.8237, 0.8301, 0.8106, 0.8425, 0.7785, 0.7275,\n",
      "        0.8255, 0.8052, 0.8662, 0.8346, 0.8326, 0.8384, 0.8449, 0.8182, 0.8091,\n",
      "        0.8463, 0.8486, 0.8431, 0.7702, 0.8513, 0.7944, 0.7897, 0.8187, 0.8839,\n",
      "        0.8576, 0.8324, 0.8363, 0.8060, 0.8557, 0.7813, 0.8308, 0.8292, 0.8528,\n",
      "        0.8281, 0.8262, 0.8138, 0.8187, 0.8121, 0.8473, 0.8586, 0.7918, 0.7994,\n",
      "        0.7883, 0.7182, 0.8465, 0.8143, 0.8000, 0.7999, 0.8013, 0.8181, 0.8500,\n",
      "        0.7997, 0.8015, 0.8728, 0.8177, 0.7948, 0.8392, 0.7510, 0.8418, 0.8227,\n",
      "        0.8096, 0.8359, 0.7973, 1.6639, 0.8174, 1.0186, 0.7740, 0.8299, 0.8187,\n",
      "        0.8362, 0.8454, 0.8579, 0.8115, 0.7521, 0.8061, 0.8153, 0.8188, 0.8129,\n",
      "        0.7855, 0.8589, 0.8539, 0.7946, 0.9279, 0.8005, 0.8110, 0.8489, 0.8490,\n",
      "        0.8250, 0.7774, 0.8636, 0.8600, 0.8087, 0.7881, 0.8310, 0.8164, 0.8391,\n",
      "        0.8184, 0.8067, 0.7810, 0.8164, 0.7915, 0.7900, 0.8199, 0.8195, 0.8318,\n",
      "        0.7746, 0.7712, 0.8317, 0.8931, 0.7630, 0.8528, 0.8167, 0.7846, 0.8321,\n",
      "        0.8086, 0.8174, 0.8665, 0.8454, 0.7957, 0.9422, 0.7924, 0.8080, 0.8075,\n",
      "        0.8664, 0.8317, 0.8519, 0.8287, 0.8109, 0.8200, 0.8315, 0.8350])\n",
      "trainable parameters: bert.encoder.layer.2.attention.output.LayerNorm.bias tensor([ 5.6125e-02,  8.5118e-04, -2.1561e-01, -2.9194e-02,  5.2329e-02,\n",
      "         2.6058e-02, -3.9158e-02,  6.1473e-02, -5.4976e-02, -1.9932e-02,\n",
      "         1.0947e-01,  1.2223e-01,  1.4437e-02, -8.5455e-02, -9.0989e-02,\n",
      "         1.2210e-03,  2.2894e-02, -2.5176e-02,  2.7454e-02, -5.5591e-02,\n",
      "         8.4066e-02, -1.4662e-01, -8.0208e-02,  1.7370e-01,  7.3798e-03,\n",
      "        -1.6465e-01, -1.2288e-01, -1.1816e-02, -8.0408e-02, -4.8663e-02,\n",
      "         7.6424e-02,  6.9111e-02, -1.5622e-01, -8.7916e-02,  1.6228e-02,\n",
      "         8.3307e-02,  2.4966e-01, -1.8476e-01,  5.8810e-02, -6.6353e-02,\n",
      "        -2.4103e-02,  7.5484e-02, -1.4397e-02,  5.4403e-02,  8.1339e-02,\n",
      "         8.4548e-02,  1.8989e-01,  5.8428e-03, -4.4662e-01,  1.2625e-01,\n",
      "         1.7748e-01,  1.0957e-02, -1.5032e-01, -1.1957e-01,  2.2830e-02,\n",
      "         1.4147e-01, -1.3301e-01, -8.7892e-02,  1.8336e-01,  7.6893e-02,\n",
      "         1.5930e-01, -1.2413e-01,  3.9987e-02,  1.4016e-02,  2.3658e-01,\n",
      "        -2.0858e-01,  3.3614e-02,  1.5059e-02, -7.1363e-03,  1.5417e-02,\n",
      "        -7.6866e-02, -5.7198e-02, -2.5110e-02, -1.1058e-01,  6.0643e-02,\n",
      "        -1.1805e-01, -1.9361e-01, -8.0255e-02, -2.3599e-03,  2.0540e-04,\n",
      "         3.2333e-01, -2.1214e-03, -1.8807e-02,  4.5725e-02, -2.3615e-01,\n",
      "         9.6397e-02, -2.3735e-02, -2.6882e-02, -1.6018e-02,  2.3652e-02,\n",
      "        -6.7880e-02, -6.4135e-02,  6.3653e-02, -1.9648e-02,  6.5380e-03,\n",
      "        -4.7439e-02, -6.6580e-02,  1.3914e-01, -3.5754e-01, -6.6024e-03,\n",
      "        -9.3171e-02,  1.3925e-01, -7.8455e-02,  9.7174e-03, -4.5567e-03,\n",
      "        -1.7146e-01, -3.4742e-02,  2.2833e-02, -7.7437e-02,  1.7522e-02,\n",
      "        -1.0747e-01, -1.1576e-01, -3.1301e-02, -2.3325e-02, -4.6510e-02,\n",
      "        -2.8504e-01,  8.9579e-02, -2.3718e-01, -1.1340e-01,  1.8472e-02,\n",
      "         2.5120e-01, -8.4106e-02, -5.1190e-02,  2.6169e-03,  2.4876e-02,\n",
      "        -5.1252e-02, -4.2773e-02,  2.8258e-02, -1.1268e-01,  8.3984e-02,\n",
      "         5.5852e-02, -5.6701e-03, -3.3152e-02, -5.3037e-02,  3.2813e-01,\n",
      "         6.3995e-02, -3.3533e-01,  1.4098e-02,  7.2521e-02,  1.1425e-01,\n",
      "         9.8381e-02, -6.4594e-02, -9.8052e-02,  1.6190e-02,  9.3577e-02,\n",
      "         6.8966e-02, -8.9829e-02, -1.7299e-02,  2.0501e-01, -7.0031e-02,\n",
      "         1.2054e-01,  7.8284e-02, -1.7198e-02,  4.5541e-02, -4.3225e-02,\n",
      "         1.7833e-01,  3.9141e-01, -1.5972e-01,  3.2224e-01,  3.8986e-02,\n",
      "         2.4999e-03, -1.3550e-01, -1.8556e-01,  1.0688e-01,  4.9129e-03,\n",
      "         2.4866e-02,  7.9360e-02, -5.7413e-03, -1.6081e-01,  1.0556e-01,\n",
      "        -4.4712e-03,  2.2157e-01,  3.0636e-03,  9.1748e-02, -7.7342e-02,\n",
      "         2.4469e-01,  2.8848e-02, -2.0696e-01,  1.6103e-02, -8.7654e-02,\n",
      "         1.6524e-02,  2.2620e-01,  1.8903e-02, -1.5034e-01,  2.7318e-01,\n",
      "         7.4720e-02,  8.5264e-02,  1.0732e-01, -3.3831e-01, -4.1514e-02,\n",
      "        -1.7675e-01,  3.2087e-02,  5.6120e-02, -2.7605e-01, -6.2257e-02,\n",
      "        -3.4335e-02, -2.0814e-01,  9.8871e-02, -9.7930e-02, -2.9510e-02,\n",
      "         1.1434e-01,  3.2045e-02, -1.5742e-01,  5.4406e-02, -9.3646e-03,\n",
      "         3.8177e-01,  1.0985e-01, -5.9744e-02, -5.4785e-02,  5.8719e-02,\n",
      "        -7.3136e-02,  2.2551e-01, -1.9827e-02, -1.2545e-01, -5.5180e-04,\n",
      "        -4.0534e-02, -8.6483e-02, -7.2635e-02, -2.0123e-01, -6.4589e-02,\n",
      "         2.4379e-01, -6.3642e-02, -3.2459e-02, -1.6720e-01,  1.7095e-01,\n",
      "         1.0391e-01,  1.9892e-02,  3.9853e-02,  1.8048e-01,  1.7320e-02,\n",
      "         1.2176e-01, -8.1146e-02,  1.6617e-01,  1.1500e-02, -3.9018e-02,\n",
      "        -7.8396e-06, -5.5433e-02,  1.0223e-02, -8.5261e-03, -7.2442e-03,\n",
      "        -2.6596e-02, -5.3487e-02,  6.8989e-02, -3.0730e-01,  8.3936e-03,\n",
      "        -8.0240e-03,  1.0774e-01,  9.2839e-02,  1.5148e-01,  5.6306e-02,\n",
      "         1.6268e-01,  4.9870e-02,  5.3765e-02,  1.8811e-02,  3.5021e-03,\n",
      "         4.3308e-02, -1.1187e-01,  7.2042e-02, -2.1795e-02,  1.3677e-01,\n",
      "        -7.0234e-02,  9.9189e-02,  2.0734e-01,  4.1208e-02, -6.0222e-02,\n",
      "        -5.1443e-03, -2.5272e-02, -1.0645e-01,  2.5140e-02, -8.8144e-02,\n",
      "         1.9669e-02, -4.7822e-02, -4.1664e-03, -9.5013e-02, -5.2821e-02,\n",
      "         1.5069e-01, -8.8863e-01, -1.6474e-02,  4.2153e-02, -8.7327e-03,\n",
      "        -5.8395e-02, -8.1259e-02, -3.1250e-02,  1.5873e-01,  6.1810e-02,\n",
      "         6.9881e-02, -1.2524e-02, -1.6866e-01,  1.5476e-01,  6.0043e-03,\n",
      "         2.2561e-01, -5.8385e-02,  1.3687e-01,  1.6985e-01, -7.8681e-02,\n",
      "         1.7404e-01,  6.3079e-02, -7.5368e-02,  6.8565e-02, -9.9189e-02,\n",
      "        -9.0288e-04, -6.8944e-03,  5.9603e-02,  1.2128e-02,  9.1072e-02,\n",
      "         1.8606e-01,  1.1243e-01, -1.8830e-02, -5.6583e-02,  1.2840e-02,\n",
      "        -1.6478e-01, -1.0064e-01, -8.3973e-02, -9.0964e-02,  4.8123e-03,\n",
      "        -1.5613e-02,  2.9129e-03, -1.7469e-02,  3.1093e-02,  1.2312e-02,\n",
      "         3.7762e-02, -5.5147e-02, -1.3524e-01,  2.1150e-02, -2.9132e-02,\n",
      "         2.0519e-01, -5.3048e-02, -1.6520e-01,  1.0538e-01,  2.8834e-01,\n",
      "         6.1483e-04, -1.4162e-02,  7.3139e-02,  1.3182e-01,  4.1734e-02,\n",
      "         8.1108e-02, -7.0286e-02, -5.8799e-02, -3.1748e-02,  1.1023e-01,\n",
      "         3.7879e-03, -3.4173e-02,  8.4840e-02,  3.9563e-02, -3.1219e-02,\n",
      "         6.6068e-02, -1.0135e-01, -1.1370e-01,  4.0196e-02,  1.6917e-01,\n",
      "         9.3098e-02,  2.0230e-01,  9.2343e-02, -8.1685e-02,  3.1249e-01,\n",
      "        -1.9581e-01,  4.1865e-01,  1.0474e-02, -7.2222e-02,  8.5898e-02,\n",
      "         2.3754e-02,  6.1525e-02,  3.0843e-02,  1.7725e-02,  2.0647e-02,\n",
      "         5.5784e-02,  5.0505e-02, -1.0924e-01, -1.0567e-01,  9.7945e-02,\n",
      "         4.3455e-02, -8.2031e-03, -9.8103e-02,  1.8061e-03,  1.9834e-01,\n",
      "        -2.4615e-01,  2.8592e-02, -5.2712e-03,  1.2165e-01, -1.4012e-01,\n",
      "        -2.2738e-02,  7.0231e-02,  6.4761e-02, -6.4916e-02,  1.5158e-01,\n",
      "         4.0294e-02, -6.0755e-02,  2.5555e-02,  9.3219e-03, -1.3034e-01,\n",
      "        -1.4146e-02, -1.0655e-02,  7.3134e-02,  1.6817e-02,  1.2334e-02,\n",
      "        -9.1537e-02,  1.0187e-01,  8.2996e-02, -1.4819e-01, -2.9165e-02,\n",
      "        -1.9396e-02,  3.6723e-02, -1.2444e-01,  4.1880e-02,  1.1164e-01,\n",
      "         1.0115e-01, -1.5768e-02,  4.1721e-02,  8.6894e-02, -3.8595e-03,\n",
      "         5.0485e-02, -1.2086e-01, -5.3753e-02,  1.6273e-02, -4.0344e-03,\n",
      "        -5.8022e-02,  1.0517e-03,  2.6731e-03,  2.3735e-01,  1.8080e-02,\n",
      "         2.1506e-01, -1.9691e-01,  9.8787e-02,  1.6609e-01, -5.8156e-02,\n",
      "         1.9685e-01,  2.0152e-01,  9.4458e-02,  1.6061e-01,  8.6362e-02,\n",
      "        -4.8798e-02, -1.2645e-01,  3.6574e-03,  7.6269e-02, -6.4111e-02,\n",
      "         1.4459e-01, -1.2675e-01, -6.4039e-02,  7.7808e-02, -2.9207e-02,\n",
      "         1.5425e-01, -5.3209e-02, -1.7895e-01,  5.1607e-02,  2.1635e+00,\n",
      "        -1.0337e-01, -1.0630e-01, -7.2405e-03,  1.4127e-01, -1.1621e-03,\n",
      "         1.6142e-01,  1.3438e-01,  2.0059e-01,  9.2691e-02,  2.2043e-01,\n",
      "        -4.1975e-02, -6.8819e-03,  5.9140e-02,  1.3965e-01,  9.1556e-04,\n",
      "        -2.1085e-02, -4.7654e-02, -2.6258e-02,  1.9830e-01, -1.4459e-01,\n",
      "        -1.1809e-02,  3.5614e-02,  1.4422e-01,  5.3709e-02,  3.0942e-02,\n",
      "        -9.4560e-02, -6.0420e-02,  2.1417e-01, -7.6052e-02, -1.1541e-02,\n",
      "         1.6527e-02, -1.5167e-01, -4.0331e-02, -1.0409e-01, -4.2211e-02,\n",
      "         1.1313e-01,  8.7196e-02, -9.2107e-02, -3.7028e-02, -5.9461e-02,\n",
      "         5.4872e-02, -3.0508e-02,  1.1548e-01, -3.9141e-02,  7.1079e-02,\n",
      "        -2.5662e-01,  1.4607e-01,  1.9078e-01, -1.0181e-01,  1.0272e-01,\n",
      "        -5.9564e-02, -2.8439e-02, -2.9577e-01, -2.0607e-01, -1.9739e-02,\n",
      "         3.2320e-01,  3.6450e-02,  8.6760e-02, -1.0644e-01,  8.4316e-02,\n",
      "        -7.8155e-02,  3.9971e-01,  1.2499e-01,  2.1541e-01, -6.0376e-02,\n",
      "         3.4380e-02,  4.8009e-02])\n",
      "trainable parameters: bert.encoder.layer.2.intermediate.dense.weight tensor([[-0.0381, -0.0683,  0.0205,  ...,  0.0510,  0.0205,  0.0353],\n",
      "        [-0.0646,  0.0752,  0.0833,  ...,  0.0618, -0.0269, -0.0602],\n",
      "        [ 0.0116, -0.0021,  0.0057,  ..., -0.0038,  0.0137,  0.0106],\n",
      "        ...,\n",
      "        [ 0.0069, -0.0167,  0.0671,  ..., -0.0242, -0.0132,  0.0804],\n",
      "        [ 0.0208, -0.0263,  0.0166,  ..., -0.0628,  0.0223,  0.0730],\n",
      "        [-0.0091, -0.0507, -0.0034,  ..., -0.0207,  0.0714,  0.0094]])\n",
      "trainable parameters: bert.encoder.layer.2.intermediate.dense.bias tensor([-0.0730, -0.1857,  0.0123,  ..., -0.0904,  0.0081, -0.1024])\n",
      "trainable parameters: bert.encoder.layer.2.output.dense.weight tensor([[-0.1066,  0.1072, -0.0480,  ...,  0.0607,  0.0227, -0.0161],\n",
      "        [-0.0335, -0.0293, -0.0166,  ..., -0.0254,  0.0620,  0.0072],\n",
      "        [ 0.0573, -0.0558, -0.0428,  ...,  0.0093, -0.0098,  0.0346],\n",
      "        ...,\n",
      "        [ 0.2074,  0.0717,  0.0149,  ..., -0.0405,  0.0472,  0.0130],\n",
      "        [-0.0403,  0.0198, -0.0206,  ...,  0.0169, -0.0137, -0.0507],\n",
      "        [-0.0774,  0.0442, -0.0228,  ...,  0.0806,  0.0164, -0.0588]])\n",
      "trainable parameters: bert.encoder.layer.2.output.dense.bias tensor([-1.2770e-02, -6.5386e-02, -3.9845e-02, -2.7028e-02, -4.3436e-02,\n",
      "        -1.3600e-02, -5.5419e-02, -3.1095e-02, -3.0992e-02, -7.8483e-03,\n",
      "         2.9500e-02,  7.4176e-03, -3.1639e-02,  2.1774e-02,  8.1083e-03,\n",
      "         4.5134e-02, -1.1275e-02,  2.8770e-02,  1.0303e-02,  3.3050e-02,\n",
      "         2.2958e-02, -2.6382e-02, -2.8191e-02,  8.2759e-02,  3.9112e-02,\n",
      "        -5.1343e-03, -3.0567e-02, -1.3075e-03, -4.7533e-02, -5.8518e-02,\n",
      "         3.8389e-02, -7.9076e-02, -2.1644e-02, -2.1278e-02, -2.7192e-02,\n",
      "         2.6313e-02,  5.6206e-03, -2.0089e-02, -1.2351e-02,  9.4101e-03,\n",
      "         9.4810e-03, -2.9282e-02,  3.6842e-02,  6.4120e-02,  4.0005e-02,\n",
      "        -1.6725e-02,  5.4049e-02, -4.8557e-02, -1.0635e-01,  2.9763e-02,\n",
      "         8.7527e-02, -3.9883e-02, -2.5937e-02,  4.0737e-02, -1.7963e-02,\n",
      "         2.5406e-02, -4.1285e-02, -1.9048e-02, -2.4950e-02, -1.6688e-02,\n",
      "        -1.8861e-02, -4.6035e-02, -3.3865e-02,  2.6755e-03,  9.0224e-02,\n",
      "        -6.5995e-02,  1.5388e-02,  4.1205e-02, -1.2085e-02, -2.4602e-02,\n",
      "        -2.1242e-02, -3.4747e-02,  4.0638e-03, -2.8268e-02,  1.9393e-02,\n",
      "        -2.6874e-02, -4.5399e-02, -4.9650e-04, -4.1230e-02, -2.2749e-02,\n",
      "         5.7260e-02, -3.6546e-02,  1.8086e-03,  6.6873e-02, -5.0831e-02,\n",
      "         5.9342e-02,  4.7235e-02, -2.0519e-04,  1.0917e-02,  1.3533e-02,\n",
      "        -5.9262e-02,  8.1890e-03,  1.4445e-01, -2.8509e-03, -3.1928e-02,\n",
      "         3.8186e-02, -7.4000e-03, -2.4872e-02, -3.0283e-02, -4.5792e-02,\n",
      "         3.4592e-02, -3.0978e-02, -1.5966e-02,  3.1341e-02,  3.1177e-02,\n",
      "        -3.3803e-02,  1.1734e-02, -1.0429e-02,  4.2235e-02,  7.4972e-03,\n",
      "        -3.5499e-02, -4.6577e-02,  1.6574e-02, -1.6168e-02, -2.2000e-02,\n",
      "         2.7162e-02,  4.9244e-03, -1.9098e-02, -5.0724e-02, -4.0306e-02,\n",
      "         2.7279e-02, -1.9613e-01, -7.9365e-03, -2.4739e-02,  3.0198e-02,\n",
      "        -3.6045e-02, -7.7507e-03, -1.1424e-02, -6.1016e-02,  2.2522e-02,\n",
      "        -1.6496e-02, -2.7211e-03, -2.5704e-02,  3.9221e-02,  1.2105e-01,\n",
      "         4.8457e-03, -3.0304e-02,  7.4754e-02,  2.1352e-02,  5.4025e-02,\n",
      "        -3.4553e-02, -6.4500e-02, -4.5638e-02, -6.6540e-02,  4.1011e-02,\n",
      "         5.6068e-02, -6.2579e-02, -7.2109e-03,  5.8994e-02, -2.1248e-02,\n",
      "         3.9532e-02, -3.9493e-02,  1.5638e-02,  2.8447e-02,  1.2565e-02,\n",
      "        -7.3331e-03, -3.2555e-02, -1.1049e-02,  5.6620e-04, -2.2580e-02,\n",
      "         1.4435e-02,  4.4741e-02, -4.4264e-02,  6.9468e-03, -1.8934e-02,\n",
      "         3.6634e-02, -9.1458e-03,  1.2789e-02, -3.9438e-02, -4.6656e-02,\n",
      "         5.4755e-02,  5.3106e-02,  1.6617e-02,  1.7044e-02,  3.3092e-02,\n",
      "        -2.3286e-02,  5.9677e-03, -1.2622e-01, -3.0255e-03, -2.5934e-03,\n",
      "        -2.7435e-02,  5.1178e-02, -1.9312e-02,  1.9457e-02,  5.8739e-02,\n",
      "        -1.9181e-03,  4.0638e-02,  3.2952e-03, -2.2762e-02,  1.0779e-02,\n",
      "        -4.3023e-02,  3.2240e-02, -1.6472e-02,  4.6194e-02, -4.6759e-02,\n",
      "        -1.2282e-02, -5.5495e-02, -8.1565e-03,  3.5801e-02,  2.3760e-02,\n",
      "        -7.9453e-03, -3.8487e-02, -3.8810e-02,  2.4581e-02, -2.2952e-02,\n",
      "        -2.6477e-02, -7.5524e-02, -1.3002e-02, -4.3062e-02,  4.2153e-02,\n",
      "         5.3515e-02,  7.9278e-02, -2.4284e-02, -6.9260e-02,  2.3623e-02,\n",
      "        -6.4197e-02, -4.0622e-02, -3.5734e-02, -9.9994e-02, -5.7705e-02,\n",
      "         2.0516e-02, -6.4247e-02, -2.6810e-03, -1.5850e-02,  7.8897e-03,\n",
      "         1.1834e-02, -3.3172e-02,  6.9727e-03,  3.1636e-02,  1.5082e-04,\n",
      "         4.8014e-03,  2.0053e-02,  2.1204e-02,  2.9458e-02,  2.5044e-02,\n",
      "        -7.1568e-03, -1.1675e-03, -4.0660e-02, -5.4554e-02, -2.4877e-02,\n",
      "        -1.3690e-02, -1.7944e-02, -1.5480e-02,  1.0408e-01, -4.9225e-03,\n",
      "        -1.5708e-02,  3.7947e-02,  1.1235e-02, -9.7781e-03,  1.8224e-02,\n",
      "        -1.2978e-03, -3.1727e-02,  5.5097e-02, -1.7221e-02,  2.5079e-02,\n",
      "         4.7386e-02, -6.5879e-02,  6.1201e-02, -1.0320e-01,  4.1233e-02,\n",
      "        -6.2756e-03, -4.0528e-02,  5.0056e-01,  4.1543e-02, -6.2085e-02,\n",
      "        -4.5857e-03, -6.7258e-03, -7.8901e-02,  3.0177e-02, -3.3009e-02,\n",
      "         5.9528e-02, -2.1241e-02,  1.2908e-02,  5.7942e-04,  1.7275e-04,\n",
      "         2.9638e-03,  5.8257e-02,  1.0319e-02,  4.3425e-02, -1.4159e-02,\n",
      "         1.4274e-03, -1.3155e-02, -1.8595e-02,  2.2175e-02,  4.8130e-02,\n",
      "        -6.7066e-03, -1.1827e-02,  1.4060e-02,  5.0360e-02, -2.5997e-03,\n",
      "         1.9147e-02, -7.7567e-02,  1.8725e-02,  9.0524e-03, -9.4662e-02,\n",
      "         1.1002e-02,  7.6809e-02,  5.2987e-02, -3.6139e-02,  7.2778e-02,\n",
      "         1.4772e-02,  6.6157e-03, -3.0351e-02,  3.5080e-02, -9.8821e-04,\n",
      "         2.2911e-02,  8.5121e-02,  7.1168e-03,  3.5198e-02, -4.7308e-02,\n",
      "        -4.4923e-02, -1.4264e-02,  1.4473e-02, -2.6775e-03, -2.3267e-02,\n",
      "        -9.0132e-02,  1.0134e-02, -2.8944e-02,  2.2821e-02,  6.8924e-02,\n",
      "         8.3853e-02, -1.0866e-02, -1.6628e-02,  3.6710e-02,  2.4703e-02,\n",
      "         5.9335e-03, -1.6707e-02, -4.1168e-02, -7.9344e-03,  2.0569e-02,\n",
      "         1.5246e-02,  6.7102e-03, -3.7650e-02,  3.2882e-02,  1.1484e-01,\n",
      "         1.2181e-01, -2.4920e-02, -7.1096e-03,  3.8118e-02,  1.0301e-02,\n",
      "         6.2233e-02,  1.0070e-01,  8.8315e-03,  2.2360e-02, -8.1555e-02,\n",
      "        -1.5045e-02, -4.0952e-02, -1.6025e-02, -1.4258e-02, -4.9865e-02,\n",
      "        -1.2689e-01,  1.1688e-02,  7.9019e-02, -4.4977e-03,  1.2713e-02,\n",
      "        -3.2286e-02,  1.1362e-02, -2.9410e-03, -2.3986e-02,  8.2612e-02,\n",
      "         1.4788e-02,  8.6182e-03, -4.5401e-02,  3.6739e-02, -2.9116e-02,\n",
      "        -4.9288e-02,  3.5539e-02,  2.3296e-03, -1.0348e-02,  5.8516e-02,\n",
      "         4.2542e-03,  2.0014e-02, -3.3341e-02,  1.8875e-02, -2.5918e-03,\n",
      "        -1.4353e-01, -2.9637e-02,  6.6104e-06,  1.7313e-02,  6.9250e-03,\n",
      "        -4.8887e-02, -6.5028e-02,  1.4707e-02, -2.5294e-02,  2.6076e-02,\n",
      "        -3.0800e-02, -4.1007e-02,  1.7833e-02, -1.7858e-02, -2.3843e-02,\n",
      "         3.2173e-02,  1.3913e-02,  4.6130e-02, -1.9413e-02,  2.4533e-02,\n",
      "        -1.4947e-03, -7.4752e-03,  4.2198e-02, -2.9430e-02,  3.1316e-02,\n",
      "         5.4678e-04, -7.4010e-03, -2.5017e-02,  3.7209e-02,  3.5483e-02,\n",
      "         3.7671e-02, -9.3434e-03, -1.7810e-02,  9.0204e-03, -1.1256e-02,\n",
      "        -4.9184e-02, -3.1311e-02, -2.7265e-02,  5.8586e-03, -2.0403e-03,\n",
      "         2.5330e-02, -1.9540e-02, -2.6538e-02, -8.0789e-03,  3.8297e-02,\n",
      "         6.9330e-02, -1.0427e-01, -9.6988e-03,  4.7111e-02, -6.8790e-02,\n",
      "         4.0212e-02,  4.0536e-02,  2.4173e-02,  1.7700e-03,  4.7888e-03,\n",
      "        -3.3997e-02, -6.6741e-02, -2.9831e-02, -1.3070e-02,  8.4702e-03,\n",
      "         4.9390e-02, -2.5299e-02, -7.3700e-02, -1.2700e-03,  4.2014e-02,\n",
      "         5.3181e-02,  3.1793e-02, -5.3777e-02,  1.0030e-01,  4.8019e-01,\n",
      "        -2.9566e-02, -8.4596e-03,  1.4797e-02,  1.3753e-01, -2.2685e-02,\n",
      "         3.6581e-02,  5.9534e-02,  2.3997e-02, -3.3822e-03,  6.9085e-02,\n",
      "        -1.2300e-02, -1.7058e-02,  3.7129e-02, -2.8863e-02,  4.9540e-02,\n",
      "         7.2616e-02,  3.6579e-02,  1.2546e-02, -1.0603e-03,  1.4903e-02,\n",
      "        -6.7601e-02,  5.6734e-02,  3.6186e-02, -3.2250e-02,  5.4831e-03,\n",
      "         6.8816e-03, -8.1365e-02, -2.2853e-02, -4.8436e-03, -6.4822e-02,\n",
      "        -1.2569e-02, -3.5518e-02, -3.4817e-02, -3.6250e-02, -2.0552e-02,\n",
      "         5.5184e-02,  4.2105e-02, -1.1698e-02, -2.4581e-02,  1.9505e-04,\n",
      "         2.7551e-02,  5.1759e-02,  8.0424e-02, -1.6396e-02, -1.9731e-02,\n",
      "        -8.3276e-02, -1.9721e-02,  1.0338e-01, -3.7227e-02, -4.2672e-02,\n",
      "         9.0591e-03,  1.4807e-02, -6.1732e-02, -6.9138e-02, -2.3793e-02,\n",
      "         7.3740e-02,  4.6499e-02,  6.1755e-02,  5.9222e-02,  2.8389e-03,\n",
      "        -7.9407e-02,  1.1014e-01, -5.1037e-02,  4.3302e-02,  1.3261e-02,\n",
      "         5.3968e-02,  3.1805e-03])\n",
      "trainable parameters: bert.encoder.layer.2.output.LayerNorm.weight tensor([1.0839, 1.1708, 1.1058, 1.1402, 1.1512, 1.1073, 1.1180, 1.1411, 0.9721,\n",
      "        1.1021, 1.1269, 1.1027, 1.1388, 1.0866, 1.1331, 1.1346, 1.1302, 1.1600,\n",
      "        1.1329, 1.1257, 1.1083, 1.1156, 1.0972, 1.0411, 1.1140, 1.1209, 1.1367,\n",
      "        1.1328, 1.1553, 1.1508, 1.1453, 1.0828, 1.0293, 1.1210, 1.1328, 1.1319,\n",
      "        1.1119, 1.0724, 1.1528, 1.1401, 1.1268, 1.1461, 1.0866, 1.0895, 1.1288,\n",
      "        1.1142, 1.1627, 1.1067, 1.1547, 0.9821, 1.1426, 1.1224, 1.1388, 1.1266,\n",
      "        1.1468, 1.0924, 1.1014, 1.1420, 1.1226, 1.1250, 1.0785, 1.1759, 1.1535,\n",
      "        1.1127, 1.1485, 1.1015, 1.1128, 1.1151, 1.0547, 1.1303, 1.1280, 1.1268,\n",
      "        1.1492, 1.1168, 1.1506, 1.1234, 1.1736, 1.1168, 1.1438, 1.1385, 1.0589,\n",
      "        1.1568, 1.1400, 1.0933, 1.1132, 1.1553, 1.1488, 1.1208, 1.1471, 1.1004,\n",
      "        1.1303, 1.0757, 1.1154, 1.1277, 1.1195, 1.1657, 1.1270, 1.1040, 1.1350,\n",
      "        1.1207, 1.1053, 1.0972, 1.1215, 1.1158, 1.1273, 1.1312, 1.1717, 1.1381,\n",
      "        1.1169, 1.1250, 1.1639, 1.0902, 1.0999, 1.1389, 1.0521, 1.0881, 1.1465,\n",
      "        1.1643, 1.0666, 1.1237, 1.1067, 0.5650, 1.1381, 1.1398, 1.1799, 1.1494,\n",
      "        1.1177, 1.1108, 1.1671, 1.1237, 1.1060, 1.1644, 1.1255, 1.0931, 0.9922,\n",
      "        1.1534, 1.1720, 1.1233, 1.1092, 1.1224, 1.1813, 1.1238, 1.1400, 1.1440,\n",
      "        1.1085, 1.1318, 1.1073, 1.1599, 1.1044, 1.1468, 1.1494, 1.1074, 1.1645,\n",
      "        1.1204, 1.1028, 1.1262, 1.0316, 1.0895, 1.1123, 1.1361, 1.1605, 1.1139,\n",
      "        1.2190, 1.1329, 1.1039, 1.1547, 1.0679, 1.1318, 1.1135, 1.0874, 1.1011,\n",
      "        0.9632, 1.1283, 1.1159, 1.1427, 1.0850, 1.1269, 1.1436, 1.1404, 1.1167,\n",
      "        1.1297, 1.1012, 1.1353, 1.0512, 1.1063, 1.1399, 1.1696, 1.1018, 1.0751,\n",
      "        1.1436, 1.0818, 1.1700, 1.0903, 0.9703, 1.1580, 1.1578, 1.0861, 1.1271,\n",
      "        1.1262, 1.1530, 1.1489, 1.1388, 1.1360, 1.0900, 1.1303, 1.1560, 1.1237,\n",
      "        1.1011, 1.1539, 1.1466, 1.1319, 1.1542, 1.1234, 1.0895, 1.0784, 1.1169,\n",
      "        1.0789, 1.1188, 1.0363, 1.1191, 1.0808, 1.1414, 1.1376, 1.1355, 1.1025,\n",
      "        1.1055, 1.1356, 1.1178, 1.1530, 1.0976, 1.1569, 1.0975, 1.1387, 1.1136,\n",
      "        1.1240, 1.1375, 1.1264, 1.0677, 1.1522, 1.1270, 1.1128, 1.1248, 1.1473,\n",
      "        0.4986, 1.1786, 1.1044, 1.1490, 1.1097, 1.1276, 1.1283, 1.1454, 1.1352,\n",
      "        1.1586, 1.1557, 1.1077, 1.1241, 1.1142, 1.1406, 1.1155, 1.1216, 1.0871,\n",
      "        1.1106, 0.4341, 1.1422, 1.0799, 1.1138, 1.1220, 1.1537, 1.1581, 1.1628,\n",
      "        1.1029, 1.1536, 1.1536, 1.1444, 1.1269, 1.0720, 1.4433, 1.1471, 1.1030,\n",
      "        1.1367, 1.0626, 1.1352, 1.1107, 1.1259, 1.1101, 1.1528, 1.1152, 1.0913,\n",
      "        1.1228, 1.1210, 1.1141, 1.1463, 1.1390, 1.1114, 1.1146, 1.1129, 1.1923,\n",
      "        0.9986, 1.1200, 1.1040, 1.1629, 1.0882, 1.0965, 1.1248, 1.1508, 1.1286,\n",
      "        1.1698, 1.1147, 1.1060, 1.1033, 1.1266, 1.0999, 1.1372, 1.0896, 1.1765,\n",
      "        1.1139, 1.1453, 1.1468, 1.1400, 1.1183, 1.1130, 1.1229, 1.1130, 1.1544,\n",
      "        1.1378, 1.1278, 1.1182, 1.1125, 1.1049, 1.2546, 1.0894, 1.1014, 1.1285,\n",
      "        1.1754, 1.0507, 1.1487, 1.1180, 1.0991, 1.0891, 1.1115, 1.1466, 1.0925,\n",
      "        1.1158, 1.1718, 1.1625, 1.1199, 1.1055, 1.1342, 1.0951, 1.1702, 1.0501,\n",
      "        1.1328, 1.1457, 1.1207, 1.1922, 1.0697, 1.1309, 1.1114, 1.1153, 1.1390,\n",
      "        1.2162, 1.1639, 1.1329, 1.1772, 1.1180, 1.1686, 1.1425, 1.1043, 1.1019,\n",
      "        1.1489, 1.1299, 1.1600, 1.1654, 1.1295, 1.0926, 1.1966, 1.1421, 1.1399,\n",
      "        1.1507, 1.1392, 1.1396, 1.1390, 1.1446, 1.1400, 1.0969, 1.0694, 1.0437,\n",
      "        1.1143, 1.1416, 1.1215, 1.1126, 1.1082, 1.1414, 1.1219, 1.1342, 1.1367,\n",
      "        1.1578, 1.1448, 1.1948, 1.1289, 1.1490, 1.1448, 1.1195, 1.1640, 1.1430,\n",
      "        1.1259, 1.1341, 1.1214, 1.0996, 1.1624, 1.1170, 1.1107, 1.1239, 1.1778,\n",
      "        1.1485, 1.1418, 1.1143, 1.1072, 1.0693, 1.1184, 1.1866, 1.0074, 1.1094,\n",
      "        1.1624, 1.0873, 1.1347, 1.1000, 1.1406, 1.1738, 1.1520, 1.1427, 1.1736,\n",
      "        1.1091, 1.1558, 1.1266, 1.1020, 1.1771, 1.1663, 1.1646, 1.0853, 1.1411,\n",
      "        1.0573, 1.1172, 1.1221, 0.7701, 1.1362, 0.9296, 1.1376, 1.1429, 1.1917,\n",
      "        1.1485, 1.1347, 1.1091, 1.0676, 1.0470, 1.0969, 1.1363, 1.1429, 1.1000,\n",
      "        1.1300, 1.1182, 1.1716, 1.1006, 0.9688, 1.1284, 1.0894, 1.1371, 1.0999,\n",
      "        1.1362, 1.0875, 1.0796, 1.0979, 1.1236, 1.1058, 1.1178, 1.1617, 1.1105,\n",
      "        1.1108, 1.1262, 1.1508, 1.1868, 1.1726, 1.1328, 1.1245, 1.1476, 1.1119,\n",
      "        1.1003, 1.1087, 1.1347, 1.1386, 1.0431, 1.1471, 1.1062, 1.1339, 1.1115,\n",
      "        1.1313, 1.1335, 1.0738, 1.1747, 1.1269, 1.1693, 1.1593, 1.1102, 1.1100,\n",
      "        1.1420, 1.1593, 1.1816, 1.0793, 1.1511, 1.1278, 1.1472, 1.1528])\n",
      "trainable parameters: bert.encoder.layer.2.output.LayerNorm.bias tensor([ 3.8338e-03, -2.4735e-02,  2.9395e-02,  7.1069e-02,  5.1908e-02,\n",
      "        -6.7870e-03,  6.2778e-02,  1.0684e-02,  6.8648e-02, -3.8898e-02,\n",
      "         4.5755e-02,  7.3198e-02, -1.1457e-02,  1.0633e-01,  8.2351e-02,\n",
      "         7.7965e-02,  9.3975e-02,  3.1699e-02,  8.0212e-03,  4.1857e-02,\n",
      "         1.1528e-02,  4.2350e-02,  3.5155e-02,  1.3017e-01,  3.3564e-02,\n",
      "         1.5047e-01,  1.2961e-01,  1.6698e-02,  2.7580e-02, -3.8662e-03,\n",
      "         6.2167e-02,  3.4886e-03,  7.0934e-02,  1.1374e-01,  4.5122e-02,\n",
      "         5.5993e-02, -5.9224e-02,  9.0675e-02,  1.8394e-02,  8.6001e-02,\n",
      "         4.7692e-02, -2.8887e-02, -5.7309e-02,  9.6262e-02,  6.7147e-02,\n",
      "        -2.3987e-02,  1.5353e-02,  7.2405e-02,  1.3208e-02, -2.9417e-02,\n",
      "         2.8385e-02,  5.4471e-02,  5.1179e-02,  8.5931e-02,  8.2170e-02,\n",
      "        -5.4341e-02,  1.2742e-01,  1.0673e-01, -5.9875e-02, -8.1584e-02,\n",
      "        -5.7856e-02,  5.7110e-02,  1.8257e-02,  3.4454e-02, -3.2800e-02,\n",
      "         1.2260e-01,  4.0760e-02,  2.8719e-02,  1.1324e-01,  7.0396e-02,\n",
      "         5.4167e-02,  2.5838e-02,  7.4356e-02,  1.5618e-02,  1.9715e-02,\n",
      "         3.7681e-02,  1.1234e-01,  7.3234e-02,  4.9932e-02, -6.8674e-03,\n",
      "         3.0706e-02, -9.8532e-03,  2.7792e-02,  6.2537e-02,  1.8094e-02,\n",
      "         1.5819e-02, -1.4455e-03,  6.9382e-02,  2.5283e-02,  3.1586e-02,\n",
      "         3.4657e-02,  5.6133e-02,  5.8138e-02,  2.6052e-02, -1.5854e-02,\n",
      "         7.5602e-02,  6.7815e-02, -5.4168e-02,  5.0441e-02, -3.0553e-02,\n",
      "         1.5562e-01,  3.9616e-02,  2.0032e-02,  1.1078e-01,  2.7329e-02,\n",
      "         9.6368e-02,  1.7184e-02,  6.9931e-02,  8.9157e-02,  5.0083e-02,\n",
      "         1.0208e-02,  1.2972e-01,  6.0973e-02,  1.8174e-03,  6.3125e-02,\n",
      "        -1.1278e-01, -2.9899e-02, -2.4286e-02,  1.3477e-02, -3.1834e-02,\n",
      "        -2.2467e-02,  3.9166e-01,  6.2079e-02,  3.6204e-02,  5.2644e-02,\n",
      "         2.6884e-02, -1.1291e-02,  5.5423e-02, -7.0797e-02, -5.7757e-02,\n",
      "        -1.1849e-02,  3.5500e-03,  3.0441e-02,  8.6746e-02, -9.2978e-02,\n",
      "         6.4774e-02, -1.8075e-01,  5.9690e-02,  6.4553e-02,  3.3772e-02,\n",
      "         3.4954e-02, -1.2629e-02,  1.0586e-01, -1.5427e-02, -4.4852e-02,\n",
      "         5.0055e-02,  1.0613e-01, -9.9985e-03, -2.1425e-02,  9.1865e-03,\n",
      "         7.4123e-02, -3.7780e-02,  1.3379e-02, -6.2761e-02,  4.9843e-02,\n",
      "        -2.1297e-02, -4.2467e-02,  3.8248e-02,  1.8643e-02, -1.4699e-02,\n",
      "         8.7668e-03,  1.5309e-01,  1.2539e-04,  6.4122e-02,  5.9517e-02,\n",
      "         5.6210e-02, -3.8854e-02, -3.6928e-02,  1.0223e-01, -2.7139e-02,\n",
      "         8.0112e-02,  1.3889e-02,  8.5271e-03,  5.3852e-02,  1.0524e-01,\n",
      "        -5.8419e-02,  4.1069e-03, -5.5536e-02,  2.0007e-02,  2.7808e-02,\n",
      "         4.8968e-02,  8.0004e-02, -4.6568e-02,  1.1128e-01,  4.9857e-02,\n",
      "         3.4479e-02,  3.8931e-02, -7.4904e-02,  9.1524e-02, -1.2450e-02,\n",
      "         2.6844e-02,  5.0856e-02,  2.5875e-03,  1.4293e-01,  6.5665e-02,\n",
      "         5.3976e-02,  6.4699e-02,  4.1096e-02,  1.3049e-01,  9.8704e-02,\n",
      "        -2.8533e-02,  1.6011e-02, -1.5949e-02, -1.4340e-02,  7.0547e-02,\n",
      "         9.7604e-02,  7.6255e-02,  1.3438e-01,  5.5680e-03,  1.4782e-02,\n",
      "         1.3776e-01,  1.4102e-01,  4.5714e-02, -2.1607e-02,  5.9535e-02,\n",
      "        -3.3724e-02,  1.4629e-03,  7.4412e-02,  9.8719e-02,  3.1977e-02,\n",
      "         8.2832e-02,  4.1714e-02, -1.6799e-02, -1.1702e-03,  6.4217e-02,\n",
      "         4.6932e-02,  1.9684e-02,  9.1079e-02,  2.5359e-02,  1.6578e-02,\n",
      "         7.2586e-02,  2.1118e-02, -3.6302e-02, -2.7595e-02,  7.4334e-02,\n",
      "         1.1493e-01,  6.1360e-02, -4.5797e-02, -2.8831e-02, -4.7125e-02,\n",
      "         8.0596e-02, -1.6037e-02,  2.9097e-02, -3.6897e-01,  4.2712e-02,\n",
      "         4.9212e-02, -1.1878e-02, -1.4241e-02, -2.2474e-03,  2.0213e-02,\n",
      "        -8.5040e-02, -4.0863e-02,  5.0740e-02,  1.6381e-03,  2.0030e-02,\n",
      "         4.2798e-02,  5.7652e-02,  3.4126e-02,  8.3741e-02, -5.6728e-03,\n",
      "         8.2642e-02,  9.6432e-02, -3.5613e-01,  8.1480e-02,  6.0811e-02,\n",
      "        -6.0178e-04,  7.1970e-02,  5.2330e-02,  8.5449e-02,  6.4185e-02,\n",
      "         1.0493e-01,  1.3457e-01,  1.4025e-01,  3.4308e-02,  4.6011e-02,\n",
      "         2.2429e-01, -7.7832e-01,  7.1573e-02,  3.5324e-02, -1.2402e-02,\n",
      "        -3.1117e-02,  8.4617e-02,  5.0715e-02,  3.1282e-02, -4.0272e-02,\n",
      "         4.0933e-02,  7.0266e-02,  1.0467e-01, -2.7242e-02,  5.5813e-02,\n",
      "         1.0024e-01,  3.0442e-02, -3.7470e-02, -6.1269e-02,  3.1192e-02,\n",
      "         2.4878e-02,  6.6323e-02,  3.3475e-02, -3.3851e-02,  1.2502e-01,\n",
      "         7.1867e-02,  3.9585e-02,  4.1277e-02,  6.4823e-02, -2.1146e-02,\n",
      "         1.5725e-02,  1.0012e-01,  3.8529e-02,  9.1593e-02, -3.1631e-02,\n",
      "         1.2761e-01,  9.7379e-02,  1.4869e-01,  1.0480e-01,  1.0376e-02,\n",
      "         4.6918e-02,  2.6571e-03, -4.8147e-02, -6.2363e-03, -4.4158e-02,\n",
      "         4.1664e-02,  1.0206e-01,  9.1515e-02,  4.2295e-02,  2.8252e-02,\n",
      "        -2.1918e-02,  3.7572e-02,  7.2907e-02,  4.4503e-02,  1.2371e-01,\n",
      "         1.9064e-01,  8.0171e-02,  6.2335e-02,  4.3841e-02,  1.3976e-02,\n",
      "         5.1061e-02,  3.3036e-02,  9.9967e-02,  1.3617e-01, -7.1083e-02,\n",
      "         6.1893e-02,  6.8066e-02,  6.3110e-02,  3.0021e-02,  5.2077e-03,\n",
      "        -2.3331e-02,  7.7729e-02,  1.1229e-01,  1.2389e-03, -4.8994e-02,\n",
      "         8.0899e-03, -2.4556e-02,  1.2762e-02,  4.9759e-02, -2.3594e-02,\n",
      "         1.5000e-01,  9.7574e-03,  4.9123e-02,  3.7844e-02,  3.6779e-02,\n",
      "         7.9819e-02,  1.0647e-02,  6.5003e-02,  6.2050e-02, -7.3557e-02,\n",
      "        -9.1994e-02, -1.0914e-03,  1.7958e-02,  5.6810e-02,  1.2824e-02,\n",
      "         2.5458e-02,  2.8154e-02,  8.7539e-02,  5.1351e-02,  1.0453e-02,\n",
      "         2.9825e-03, -3.8261e-02,  6.2282e-02,  3.3226e-03,  1.3307e-01,\n",
      "         8.4768e-02,  4.3263e-03,  7.9617e-02,  7.1875e-02,  2.7708e-02,\n",
      "        -4.8522e-02,  5.9619e-02, -2.0575e-03,  2.5300e-03,  8.6732e-02,\n",
      "         5.9217e-02, -5.8275e-02,  1.1070e-01,  5.1543e-02,  6.8558e-02,\n",
      "        -3.6108e-02, -2.5869e-02,  2.0458e-02, -2.4386e-02,  1.8028e-02,\n",
      "         3.9066e-02,  3.6465e-02,  7.6940e-02, -6.1633e-03,  1.5103e-02,\n",
      "        -8.1735e-03, -1.6324e-02,  1.2633e-02, -4.2707e-02,  3.2486e-02,\n",
      "        -1.2622e-02,  5.4775e-02,  3.3432e-02,  7.0478e-02, -2.4366e-02,\n",
      "         6.6846e-02,  1.0683e-01,  2.5917e-02, -1.3597e-01,  3.8154e-03,\n",
      "         9.7412e-03,  8.9514e-02, -3.3411e-02,  2.2763e-02,  7.1415e-02,\n",
      "         8.1421e-02, -1.8547e-02, -2.6336e-02, -2.4972e-02,  7.1684e-02,\n",
      "         1.5487e-02, -4.7713e-02,  2.8712e-02,  1.6060e-02,  5.0592e-02,\n",
      "        -8.8031e-03, -9.6084e-02,  2.1062e-02,  5.8587e-02,  1.2008e-01,\n",
      "        -2.3756e-02,  1.5717e-01,  2.4424e-02,  6.8010e-02,  5.6592e-01,\n",
      "         3.8664e-02,  1.0605e-01, -1.5089e-02,  1.0695e-01,  6.9932e-03,\n",
      "        -1.8725e-02,  9.4623e-03, -4.0762e-02,  3.0227e-02,  4.7947e-02,\n",
      "        -7.8837e-02,  1.4985e-01,  3.0342e-02, -1.1040e-01,  3.2742e-03,\n",
      "         9.9860e-02,  8.2475e-02,  1.1346e-01, -2.5858e-02,  3.3248e-02,\n",
      "         1.3246e-01,  2.4347e-02,  3.1736e-02,  3.9400e-02,  3.1550e-03,\n",
      "         5.0713e-02,  6.3662e-03, -3.8200e-02,  3.7664e-02,  9.0027e-03,\n",
      "         2.4785e-02,  3.6853e-02,  8.1245e-02,  2.3026e-02,  6.4926e-02,\n",
      "         7.8035e-02,  3.2035e-03, -2.1276e-02,  6.5669e-02,  5.6623e-02,\n",
      "         8.7050e-02, -5.2719e-02,  9.0366e-02,  1.6916e-02, -2.0822e-02,\n",
      "         1.0100e-01,  7.9927e-03,  1.0918e-01,  7.8971e-02, -1.4578e-03,\n",
      "         1.6368e-02,  4.6483e-02,  1.5199e-01, -2.9646e-02,  9.7457e-02,\n",
      "         5.4869e-02,  8.0722e-02,  1.1973e-02,  5.8927e-02, -3.0262e-02,\n",
      "         2.8616e-02,  2.0738e-01, -3.9288e-02,  1.6131e-02,  9.5995e-02,\n",
      "         1.1449e-02, -1.8373e-02])\n",
      "trainable parameters: bert.encoder.layer.3.attention.self.query.weight tensor([[-0.0236,  0.0053,  0.0739,  ..., -0.0094,  0.0161, -0.0471],\n",
      "        [ 0.0381, -0.0643, -0.0685,  ..., -0.0161,  0.0634, -0.0195],\n",
      "        [-0.0648,  0.0089,  0.0532,  ...,  0.0044,  0.1050,  0.0173],\n",
      "        ...,\n",
      "        [ 0.1003,  0.1853, -0.0116,  ...,  0.1114, -0.0084, -0.0257],\n",
      "        [-0.0569, -0.0763,  0.0599,  ...,  0.0224,  0.0712, -0.0296],\n",
      "        [ 0.0066, -0.0189,  0.0152,  ...,  0.0243,  0.0241, -0.0323]])\n",
      "trainable parameters: bert.encoder.layer.3.attention.self.query.bias tensor([-3.7309e-01,  1.1547e-01, -1.3164e-02, -1.0717e-01, -9.5470e-02,\n",
      "        -4.1465e-01,  3.5221e-02, -1.7869e-01, -4.9834e-02, -2.9743e-02,\n",
      "        -3.3980e-02, -5.8966e-02, -8.1917e-02,  2.9190e-01,  2.0406e-02,\n",
      "         1.4226e-01, -2.0722e-01,  3.5423e-02,  1.2197e-01,  3.1574e-02,\n",
      "        -1.8984e-01, -2.6068e-01,  4.1304e-02,  1.3226e-01,  2.1347e-01,\n",
      "         4.2548e-02,  1.1586e-01, -1.3803e-01, -7.4207e-04,  6.2602e-02,\n",
      "        -1.6061e-01,  4.7643e-02,  3.1801e-01, -1.6107e-01,  9.8944e-02,\n",
      "        -1.3317e-01,  7.9070e-03,  1.1720e-01,  4.0022e-02,  2.4895e-01,\n",
      "         7.0818e-02, -6.4097e-02,  7.7810e-02,  9.0938e-02, -1.7905e-01,\n",
      "        -1.6936e-01,  2.0534e-01,  3.2353e-01, -1.8386e-01, -1.0330e-01,\n",
      "        -1.3095e-01,  1.4454e-01,  7.0386e-02, -2.6079e-03,  3.7312e-01,\n",
      "        -1.0845e-01,  7.6693e-02, -1.9922e-01,  1.1324e-01,  2.0735e-01,\n",
      "        -2.7339e-02, -7.3170e-03,  1.2538e-01,  1.0342e-01,  1.1294e-01,\n",
      "         1.9587e-01, -3.3052e-01, -1.6881e-01, -5.8628e-02,  2.2319e-01,\n",
      "        -2.9243e-01,  2.9033e-01,  1.4172e-01, -2.4863e-01,  2.8943e-01,\n",
      "        -1.5389e-01,  4.2126e-01, -5.0582e-01, -2.4946e-01,  2.9448e-02,\n",
      "         2.7705e-01, -1.9593e-02,  7.3609e-02,  1.3654e-01, -1.6527e-01,\n",
      "         3.0381e-01,  2.2061e-02, -1.2510e-01,  2.1757e-01,  5.6266e-02,\n",
      "        -2.0540e-01, -4.0831e-01, -2.0236e-01,  8.0100e-02,  8.6943e-02,\n",
      "        -8.5544e-02, -6.6203e-02, -2.7798e-01, -7.1398e-02,  1.3682e-02,\n",
      "         3.4756e-01, -1.6451e-01,  3.1945e-03,  3.0471e-01, -2.9280e-01,\n",
      "        -3.3354e-01,  3.0757e-01,  1.2427e-02,  2.0838e-02, -1.2502e-01,\n",
      "         3.0988e-01,  4.0558e-01,  1.4400e-02, -5.0164e-01, -3.3626e-01,\n",
      "        -4.1942e-02, -2.7179e-01,  1.5659e-01,  4.7805e-01,  1.0884e-01,\n",
      "        -1.7300e-01,  2.9472e-01,  3.0916e-01, -1.5915e-01,  2.4439e-01,\n",
      "         2.3431e-01,  3.7146e-01,  2.2696e-01,  1.7113e-01,  1.2289e-01,\n",
      "        -1.6976e-01, -2.5500e-01,  1.9070e-01,  1.7155e-01, -7.5084e-02,\n",
      "         2.5819e-01,  1.4935e-01, -7.2278e-02,  7.4111e-03, -8.4606e-02,\n",
      "        -1.4725e-01,  2.2420e-01,  7.0692e-02,  1.5531e-01, -8.6420e-02,\n",
      "         2.6001e-01, -1.0655e-01,  2.2473e-01,  1.0922e-01, -2.0723e-01,\n",
      "        -2.8335e-01,  2.5920e-01,  2.2796e-01, -1.3525e-01,  2.9679e-02,\n",
      "        -1.2639e-02, -3.5424e-01,  1.2220e-01,  3.1600e-02, -2.2715e-01,\n",
      "        -1.6441e-01,  2.3947e-01, -2.0577e-01,  7.8654e-02, -4.0593e-02,\n",
      "         5.8406e-02,  7.2637e-02,  4.7170e-02, -3.2217e-01, -6.1302e-02,\n",
      "         1.5916e-01,  2.0143e-01, -2.0024e-01,  1.1601e-01, -2.1241e-01,\n",
      "         5.0343e-02,  5.8869e-02,  2.1084e-01, -3.5044e-02,  2.5563e-01,\n",
      "        -4.1105e-02,  4.0566e-03,  2.3713e-01, -1.5720e-01,  4.6000e-02,\n",
      "         3.8370e-02,  1.8159e-01, -1.4412e-02,  3.4131e-02,  5.0367e-02,\n",
      "        -1.9250e-01,  1.2253e-01,  2.3534e-01,  1.7120e-02, -2.5323e-01,\n",
      "         1.6303e-01, -4.5083e-02, -2.9629e-01,  2.6174e-01, -6.1628e-02,\n",
      "        -1.0652e-01,  1.0604e-01,  5.5759e-02, -1.3135e-01,  5.0748e-03,\n",
      "        -2.2110e-01,  2.0480e-02, -3.9569e-02, -6.4531e-02, -5.3499e-03,\n",
      "         1.2867e-01, -9.5083e-03, -2.4235e-01, -1.8094e-01, -2.5771e-01,\n",
      "        -1.3924e-01,  9.6810e-02, -2.1049e-01, -2.8419e-01, -1.1389e-01,\n",
      "         2.5883e-01, -1.0577e-01,  3.7263e-02,  2.0818e-01, -1.3957e-01,\n",
      "        -1.9317e-01, -1.5327e-01, -1.4242e-01,  9.8075e-04,  1.5944e-01,\n",
      "        -1.5211e-02, -1.5689e-01,  2.0364e-02,  2.5753e-03,  2.6308e-01,\n",
      "        -2.6403e-01, -2.1478e-02,  1.7370e-01, -7.2883e-02, -2.6651e-02,\n",
      "        -6.3516e-02,  2.3231e-01, -1.7631e-01,  1.0136e-01, -1.6425e-02,\n",
      "         2.1818e-01,  6.3482e-02, -1.6297e-01,  9.4809e-02, -1.1170e-01,\n",
      "         2.5756e-03,  3.6549e-02, -4.0205e-02,  1.8742e-02,  2.5192e-01,\n",
      "         2.0485e-01, -1.0094e-01,  2.1619e-01,  2.4248e-02, -3.3919e-01,\n",
      "        -1.7733e-01,  2.6233e-01, -2.1676e-01, -1.8892e-01,  4.1392e-01,\n",
      "        -4.6296e-03, -2.7784e-01, -3.0956e-02, -1.4135e-01,  2.9367e-01,\n",
      "        -2.6874e-01,  4.7554e-01,  5.7462e-01, -3.1615e-02, -2.5316e-01,\n",
      "        -6.4665e-02,  4.4288e-02,  3.2999e-01, -3.7405e-01,  2.1452e-01,\n",
      "         2.8991e-01, -1.1646e-01, -2.5442e-01, -3.7357e-01, -3.3098e-02,\n",
      "         6.2860e-02, -8.8487e-02,  6.8151e-02, -3.9303e-01, -2.8354e-01,\n",
      "        -7.6889e-02, -3.8036e-02,  2.6013e-01, -1.3430e-01,  2.4100e-01,\n",
      "        -2.7742e-01, -2.7610e-01, -8.1173e-03, -2.5648e-01, -3.3209e-01,\n",
      "         8.9797e-02,  3.8748e-01, -4.3592e-01,  2.0402e-01, -2.2355e-01,\n",
      "        -2.7420e-01, -2.1733e-01, -1.0244e-01,  4.0572e-01,  2.2475e-01,\n",
      "        -1.4057e-01,  2.4766e-01, -3.3350e-01, -4.6498e-01, -3.1568e-01,\n",
      "        -3.6808e-02,  1.2248e-01, -2.7359e-01, -8.0107e-02,  2.7075e-01,\n",
      "         1.2412e-02, -1.2501e-02,  1.4780e-01,  1.2577e-01, -3.0993e-02,\n",
      "         8.9030e-02, -1.6788e-02,  1.1638e-02,  3.8740e-02, -1.3983e-02,\n",
      "        -5.9009e-02, -4.2100e-02, -2.2735e-02, -2.5721e-02,  4.7565e-02,\n",
      "        -9.9831e-02, -6.0756e-02,  3.6057e-02,  2.1124e-02, -1.0215e-01,\n",
      "         4.6449e-02,  9.6387e-02,  2.6188e-02, -1.7030e-02,  6.4404e-03,\n",
      "         1.0947e-02,  6.0101e-02,  2.5808e-02, -1.1793e-01,  4.4182e-02,\n",
      "         8.9342e-02,  7.9163e-02, -5.5879e-03, -2.7889e-02, -2.2957e-01,\n",
      "        -1.6104e-01, -1.3530e-01,  1.7305e-01, -3.6109e-02,  9.5632e-02,\n",
      "        -5.9768e-02,  1.5958e-01, -4.9957e-02, -1.1770e-01,  1.0207e-01,\n",
      "         3.7746e-02, -1.3569e-01, -1.7018e-01, -1.1901e-02,  1.4030e-02,\n",
      "         2.1731e-01,  1.9667e-01,  5.1105e-02,  3.5669e-02,  3.6724e-02,\n",
      "         3.1341e-02,  5.3036e-02,  7.0288e-02,  1.5787e-01, -5.0897e-02,\n",
      "         7.9409e-02, -1.5759e-01, -1.0488e-01, -1.4457e-01, -4.8528e-02,\n",
      "        -6.7102e-02,  2.6360e-02, -1.6095e-02,  2.5413e-02,  4.3015e-02,\n",
      "        -8.8616e-02,  3.5091e-02,  4.9107e-03, -3.6768e-03, -3.2993e-02,\n",
      "        -7.3057e-02, -3.0640e-02,  1.4690e-03, -2.1060e-03,  1.2071e-01,\n",
      "         4.7960e-02, -1.4949e-02, -3.2664e-02,  3.1165e-02, -5.0292e-02,\n",
      "        -1.1045e-01,  1.8090e-02,  4.4494e-05, -2.6915e-02, -6.1834e-02,\n",
      "        -5.5287e-03, -1.2642e-02, -1.1249e-01, -1.2934e-02, -2.6827e-02,\n",
      "        -1.6367e-02, -2.2690e-02,  2.0311e-02, -5.3050e-02, -4.6362e-02,\n",
      "         1.5210e-02, -1.0064e-01,  6.2757e-02,  2.1956e-02, -2.8261e-02,\n",
      "         4.8257e-02,  5.5444e-02,  1.9955e-02, -1.2066e-02,  9.7628e-03,\n",
      "         1.1939e-02, -4.0983e-02, -4.1113e-02, -7.7364e-03,  2.9196e-02,\n",
      "        -2.5253e-02, -3.1995e-02, -1.4607e-02,  4.6656e-02,  5.0697e-02,\n",
      "        -7.0311e-02,  4.7084e-02,  6.5951e-02,  1.2702e-02, -7.0765e-02,\n",
      "        -2.9584e-02, -4.9665e-02, -7.7237e-03, -2.1584e-01, -1.6117e-02,\n",
      "         1.6987e-04,  1.6170e-01, -2.2783e-01, -1.9376e-02,  4.2672e-02,\n",
      "        -1.2411e-01,  1.6237e-01, -3.9095e-03, -1.4529e-01, -6.8693e-02,\n",
      "         1.1214e-01,  2.9765e-02, -1.8891e-01, -8.2279e-02, -1.9865e-01,\n",
      "         2.4792e-01,  2.0354e-01, -2.1753e-02, -6.1714e-02, -4.7039e-02,\n",
      "         2.6547e-01,  1.5219e-01, -7.4498e-02,  4.2367e-02,  1.5058e-01,\n",
      "        -1.5880e-01,  3.8039e-02,  1.6509e-04, -7.6014e-02, -2.2585e-01,\n",
      "        -1.5066e-02, -8.0821e-02, -9.0636e-02, -3.7558e-02, -1.1352e-01,\n",
      "        -7.9375e-02,  4.4684e-02,  1.4543e-01,  1.5280e-01, -9.1333e-02,\n",
      "        -3.3716e-02,  1.3460e-01, -1.4819e-01,  2.7041e-01, -1.2968e-01,\n",
      "        -1.8967e-01, -6.4528e-02,  3.0885e-02,  7.8239e-02,  1.4837e-01,\n",
      "         9.5480e-02, -5.6343e-02,  1.0507e-01,  4.9403e-02, -8.7041e-02,\n",
      "         2.8470e-01,  7.1186e-02, -1.2744e-03,  8.5219e-02, -7.0912e-02,\n",
      "        -8.9293e-03,  2.0226e-01])\n",
      "trainable parameters: bert.encoder.layer.3.attention.self.key.weight tensor([[-0.0318, -0.0548,  0.0349,  ...,  0.0051, -0.0334, -0.0457],\n",
      "        [-0.0638, -0.0108,  0.0043,  ..., -0.0050,  0.0089,  0.0135],\n",
      "        [-0.0484,  0.0089,  0.0777,  ..., -0.0490,  0.0391,  0.0126],\n",
      "        ...,\n",
      "        [-0.0119, -0.0133,  0.0509,  ...,  0.0510, -0.0408, -0.0160],\n",
      "        [-0.0200, -0.0962, -0.0015,  ..., -0.0032,  0.0487,  0.0258],\n",
      "        [-0.0193, -0.0464,  0.0300,  ..., -0.0144, -0.1264, -0.0054]])\n",
      "trainable parameters: bert.encoder.layer.3.attention.self.key.bias tensor([ 0.0159, -0.0218, -0.0198, -0.0370,  0.0094,  0.0079, -0.0505, -0.0316,\n",
      "        -0.0085, -0.0092,  0.0054,  0.0439, -0.0062, -0.0299,  0.0259, -0.0484,\n",
      "         0.0233, -0.0121, -0.0251,  0.0012, -0.0145,  0.0286,  0.0170, -0.0529,\n",
      "        -0.0123,  0.0009, -0.0129, -0.0342, -0.0392,  0.0402,  0.0229,  0.0155,\n",
      "        -0.0391, -0.0403, -0.0105, -0.0239,  0.0687, -0.0070,  0.0686, -0.0423,\n",
      "        -0.0520, -0.0100, -0.0548, -0.0082,  0.0144,  0.0330, -0.0019, -0.0022,\n",
      "         0.0588, -0.0262,  0.0360,  0.0071,  0.0023,  0.0145, -0.0433, -0.0540,\n",
      "         0.0158, -0.0293,  0.0263, -0.0401, -0.0067, -0.0141, -0.0115,  0.0044,\n",
      "        -0.0280,  0.0519,  0.0111, -0.0585, -0.0374,  0.0089,  0.0175,  0.0220,\n",
      "        -0.0188, -0.0235,  0.0567, -0.0238,  0.0761, -0.0070,  0.0410,  0.0295,\n",
      "         0.0383, -0.0078, -0.0178, -0.0162, -0.0263,  0.0588, -0.0510, -0.0253,\n",
      "        -0.0625, -0.0091, -0.0435, -0.0421, -0.0276, -0.0145, -0.0032, -0.0010,\n",
      "         0.0077, -0.0071,  0.0119,  0.0245, -0.0214, -0.0363,  0.0042,  0.0514,\n",
      "        -0.0354,  0.0130, -0.0350, -0.0063,  0.0225,  0.0167, -0.0406,  0.0035,\n",
      "         0.0130, -0.0601, -0.0159, -0.0412,  0.0330, -0.0037, -0.0152,  0.0227,\n",
      "         0.0392, -0.0297,  0.0490,  0.0130,  0.0167, -0.0005, -0.0645,  0.0411,\n",
      "        -0.0780, -0.0343,  0.0830, -0.0590, -0.0210,  0.0471, -0.0181,  0.0372,\n",
      "        -0.0164,  0.0115,  0.0378, -0.0138, -0.0169, -0.0053, -0.0607,  0.0024,\n",
      "        -0.0271,  0.0206,  0.0177, -0.0445, -0.1163, -0.0289, -0.0031,  0.0185,\n",
      "         0.0399,  0.1312, -0.0103,  0.0356,  0.0185,  0.0233, -0.0033,  0.0110,\n",
      "         0.0489,  0.0228, -0.0178, -0.0102,  0.0643,  0.0989,  0.0362, -0.0371,\n",
      "        -0.0379, -0.0304, -0.0016,  0.0098,  0.0631, -0.0264, -0.0050,  0.0172,\n",
      "        -0.0568, -0.0200, -0.0153,  0.0453,  0.0089, -0.0118, -0.0023, -0.0112,\n",
      "         0.0659, -0.0278,  0.0162, -0.0245,  0.0381, -0.0160,  0.0058, -0.0183,\n",
      "         0.0574, -0.0477, -0.0831, -0.0166, -0.1113, -0.0708,  0.0184,  0.0034,\n",
      "        -0.0610,  0.0003,  0.0461,  0.0195,  0.0173,  0.0308, -0.0075,  0.0269,\n",
      "         0.0306, -0.0370,  0.0326, -0.0559, -0.0355, -0.0362, -0.0400, -0.0296,\n",
      "        -0.0169, -0.0716, -0.0521, -0.0154,  0.0647, -0.0242, -0.0354,  0.0290,\n",
      "        -0.0165,  0.0408, -0.0639, -0.0633,  0.0112,  0.0454, -0.0042,  0.0017,\n",
      "        -0.0468,  0.0046, -0.0025, -0.0483,  0.0348,  0.0137,  0.0212, -0.0024,\n",
      "         0.0044,  0.0829, -0.0539,  0.0235,  0.0440,  0.0254, -0.0447, -0.0138,\n",
      "         0.0148,  0.0037, -0.0073, -0.0153, -0.0069,  0.0219,  0.0490,  0.0257,\n",
      "        -0.0654, -0.0200, -0.0148,  0.0086, -0.0520, -0.0254, -0.0075,  0.0719,\n",
      "        -0.0209,  0.0206, -0.0006, -0.0349, -0.0118, -0.0148,  0.0187, -0.0162,\n",
      "        -0.0423,  0.0275,  0.0206, -0.0431, -0.0037, -0.0072,  0.0406, -0.0024,\n",
      "        -0.0749,  0.0533, -0.0105,  0.0697,  0.0118,  0.0079, -0.0353,  0.0343,\n",
      "         0.0498, -0.0404, -0.0158,  0.0332,  0.0062,  0.0380, -0.0579,  0.0137,\n",
      "        -0.0232,  0.0417,  0.0095,  0.0378, -0.0517, -0.0323,  0.0353,  0.0174,\n",
      "         0.0376,  0.0728,  0.0106, -0.0288, -0.0417, -0.0715,  0.0049, -0.0320,\n",
      "         0.0257,  0.0198,  0.0451, -0.0649, -0.0170,  0.0844, -0.0357, -0.0092,\n",
      "         0.0374, -0.0678, -0.0483, -0.0182,  0.0607, -0.0085,  0.0219,  0.0158,\n",
      "        -0.0555,  0.0158, -0.0460, -0.0373,  0.0828,  0.0300, -0.0445, -0.0412,\n",
      "        -0.0177,  0.0555,  0.0077, -0.0018, -0.0505,  0.0331, -0.0175,  0.0086,\n",
      "        -0.0411, -0.0336,  0.0330, -0.0044, -0.0259,  0.0463,  0.0282,  0.0017,\n",
      "        -0.0004,  0.0054,  0.0017, -0.0224, -0.0770,  0.0603, -0.0405,  0.1014,\n",
      "         0.0014,  0.0724, -0.0304, -0.0746, -0.0038,  0.0289, -0.0573, -0.0311,\n",
      "        -0.0141,  0.0096, -0.0172, -0.0107, -0.0037,  0.0665,  0.0722,  0.0498,\n",
      "        -0.0139,  0.0623, -0.0040, -0.0558, -0.0051, -0.0668, -0.0292, -0.0080,\n",
      "        -0.0277, -0.0282, -0.0362,  0.0317,  0.0315, -0.0734,  0.0244,  0.0622,\n",
      "         0.0391, -0.0113, -0.0279,  0.0141, -0.0318,  0.0139, -0.0138,  0.0018,\n",
      "         0.0151,  0.0135, -0.0145,  0.0309,  0.0394, -0.0530, -0.0110,  0.0068,\n",
      "        -0.0038,  0.0057,  0.0177,  0.0169, -0.0220,  0.0220,  0.0258, -0.0029,\n",
      "         0.0414, -0.0284, -0.0340, -0.0038,  0.0163,  0.0037, -0.0380,  0.0151,\n",
      "         0.0351, -0.0172, -0.0006,  0.0376,  0.0045, -0.0336,  0.0061, -0.0051,\n",
      "        -0.0202,  0.0097,  0.0308, -0.0444,  0.0218,  0.0039, -0.0225, -0.0631,\n",
      "         0.0131, -0.0405,  0.0391,  0.0157,  0.0161,  0.0472,  0.0181, -0.0196,\n",
      "        -0.0087, -0.0229,  0.0038, -0.0059, -0.0133, -0.0200, -0.0017,  0.0111,\n",
      "        -0.0060,  0.0255,  0.0068, -0.0248, -0.0393, -0.0140, -0.0013, -0.0093,\n",
      "        -0.0293,  0.0018, -0.0340, -0.0146,  0.0246,  0.0282,  0.0276,  0.0025,\n",
      "         0.0017,  0.0038,  0.0274, -0.0287, -0.0388,  0.0128, -0.0170, -0.0241,\n",
      "        -0.0012, -0.0104,  0.0896,  0.0015, -0.0211,  0.0153,  0.0262, -0.0229,\n",
      "         0.0111,  0.0023, -0.0405,  0.0115, -0.0327,  0.0056, -0.0200, -0.0279,\n",
      "         0.0413, -0.0175,  0.0120, -0.0382, -0.0263,  0.0169,  0.0022,  0.0042,\n",
      "        -0.0281, -0.0028, -0.0035, -0.0401,  0.0531,  0.0181, -0.0134, -0.0751])\n",
      "trainable parameters: bert.encoder.layer.3.attention.self.value.weight tensor([[-0.0816, -0.0847, -0.0322,  ..., -0.0444,  0.0052,  0.0130],\n",
      "        [-0.0299,  0.0233,  0.0401,  ...,  0.0110,  0.0074, -0.0074],\n",
      "        [ 0.0178,  0.0687, -0.0468,  ...,  0.0237, -0.0145,  0.0138],\n",
      "        ...,\n",
      "        [-0.0288, -0.0055,  0.0484,  ..., -0.0154,  0.0165,  0.0116],\n",
      "        [-0.0223,  0.0427, -0.0075,  ...,  0.0850,  0.0416,  0.0157],\n",
      "        [-0.0259, -0.0405,  0.0888,  ...,  0.0956, -0.0225,  0.0883]])\n",
      "trainable parameters: bert.encoder.layer.3.attention.self.value.bias tensor([-9.4230e-03, -2.0206e-02,  1.4882e-01, -5.1621e-02, -6.1083e-02,\n",
      "         8.8518e-02, -1.2765e-01, -3.7040e-02,  1.9536e-01,  7.0895e-02,\n",
      "         2.3878e-02,  1.0282e-01, -3.0932e-02,  6.8382e-02, -9.3629e-02,\n",
      "        -1.0874e-01,  1.5440e-01,  5.2194e-02,  4.3954e-02, -1.6973e-01,\n",
      "        -1.5168e-01, -1.0440e-01, -1.1228e-01,  7.0588e-02, -7.3171e-02,\n",
      "         3.1130e-02,  2.4760e-02,  1.5657e-01,  4.1326e-02,  2.5296e-02,\n",
      "        -2.3138e-01,  1.1853e-01,  1.2390e-01, -4.2562e-02, -2.4313e-01,\n",
      "         3.5389e-02, -5.4893e-03,  3.8615e-02,  1.7530e-01, -4.6521e-02,\n",
      "         7.3698e-02,  1.2514e-01, -2.1098e-02, -2.7625e-02,  5.0161e-02,\n",
      "         1.4492e-01,  8.8218e-03,  6.3567e-02,  5.5846e-02, -4.1050e-02,\n",
      "        -1.5293e-01, -9.1867e-03,  4.2130e-02, -2.1750e-02,  1.3075e-01,\n",
      "         5.2129e-02, -1.1703e-01, -3.3095e-02,  4.1727e-02,  1.1574e-01,\n",
      "         9.1235e-02,  1.4402e-01, -1.0581e-01, -1.0807e-02,  6.4369e-02,\n",
      "         3.9550e-02,  9.5295e-03,  2.7542e-02,  2.9092e-02,  1.1681e-02,\n",
      "         9.8843e-03, -4.6489e-02, -4.7023e-02,  3.9036e-02,  1.9843e-02,\n",
      "         2.0471e-02, -1.1367e-02,  2.6361e-02, -1.8653e-02, -2.8418e-03,\n",
      "        -2.0100e-02,  2.5773e-02,  3.0714e-02, -3.1755e-02, -9.8850e-03,\n",
      "        -8.2204e-03, -2.7706e-02,  6.0327e-02, -6.5228e-02,  2.7181e-02,\n",
      "         3.1244e-03,  5.6430e-02,  4.2737e-03, -1.1044e-02, -3.4990e-03,\n",
      "         3.1600e-02, -4.0763e-02,  2.1560e-02, -5.3051e-02,  1.2660e-03,\n",
      "        -5.3603e-02, -1.0252e-02, -8.0574e-03, -9.3522e-02, -1.0292e-01,\n",
      "        -9.5115e-04, -4.8495e-02, -1.0269e-03,  8.2914e-03, -8.9139e-02,\n",
      "        -9.5872e-04,  5.0648e-02,  1.2466e-02, -9.7094e-03, -2.3600e-02,\n",
      "         7.9002e-02, -4.3711e-03, -5.6846e-03,  4.1330e-02, -4.8869e-03,\n",
      "         3.6438e-02, -1.1962e-02, -4.3788e-02, -1.8317e-02, -4.0992e-02,\n",
      "         3.6857e-03, -1.2816e-02,  4.0463e-02, -4.5347e-02, -2.3578e-02,\n",
      "        -4.7513e-02,  3.8947e-02,  4.8291e-03,  1.1086e-01,  7.1210e-03,\n",
      "         1.0413e-02, -5.0458e-02,  7.6368e-02,  6.8853e-02,  3.0592e-02,\n",
      "         1.1314e-02,  6.0507e-02, -1.0796e-01,  6.7771e-02,  5.4211e-03,\n",
      "        -2.6468e-03, -3.6789e-02, -1.7010e-02, -9.5384e-03,  3.6694e-02,\n",
      "         3.2151e-02, -6.9526e-02,  5.7349e-03, -1.0010e-01, -3.9510e-02,\n",
      "         2.1549e-02, -2.9974e-03,  4.7856e-02, -7.9465e-02,  6.7981e-02,\n",
      "         2.3774e-03,  1.9154e-02, -3.9393e-02,  4.1359e-02,  1.2104e-02,\n",
      "        -2.9127e-02, -7.9022e-02, -3.1325e-02, -6.0651e-02,  5.6189e-03,\n",
      "         3.6460e-02, -8.6188e-02,  1.0039e-02,  8.0971e-03, -3.0873e-02,\n",
      "         7.2220e-03, -4.9379e-03,  2.4260e-02,  6.6560e-02,  3.4030e-03,\n",
      "        -2.3645e-02,  4.7677e-02, -1.4546e-02, -4.4584e-02, -8.7907e-02,\n",
      "        -1.8591e-02, -1.1139e-01,  8.3598e-02,  4.4964e-02,  1.0587e-02,\n",
      "        -6.3923e-02, -3.5327e-02,  4.2792e-02, -3.9369e-03, -4.4346e-02,\n",
      "         4.8209e-02, -9.9238e-02, -2.3945e-02, -1.3260e-02,  9.8965e-02,\n",
      "        -6.2874e-03, -7.7584e-02,  5.7855e-02, -4.3734e-02, -8.8612e-02,\n",
      "         3.4556e-02, -1.0744e-02,  4.8027e-02,  1.2362e-02, -7.0094e-02,\n",
      "         2.0710e-02, -4.0481e-02, -6.6771e-03, -1.2626e-01,  8.1482e-02,\n",
      "        -1.1933e-02, -1.9545e-03,  5.7204e-02, -3.8671e-02, -1.4029e-01,\n",
      "        -1.2295e-02,  2.4644e-02,  7.6074e-02,  7.0787e-02, -1.0404e-02,\n",
      "         5.4801e-02,  3.6440e-02,  1.4299e-02, -2.1826e-02, -7.1456e-02,\n",
      "        -3.1487e-02,  3.1768e-03,  2.5607e-02, -6.6583e-02, -1.1508e-02,\n",
      "         3.1673e-02,  8.3772e-02,  2.4587e-02, -5.5228e-02, -1.2578e-02,\n",
      "         2.7467e-02, -1.6041e-02, -1.6316e-02, -6.1235e-02, -7.5546e-02,\n",
      "         1.3357e-02, -3.6825e-02,  2.8733e-03, -5.8056e-02,  7.5891e-03,\n",
      "         4.0796e-02, -3.7083e-02,  5.3475e-02, -2.5152e-02,  4.2388e-02,\n",
      "         2.8670e-02, -6.7819e-03,  7.0614e-03, -4.4181e-02, -5.2152e-02,\n",
      "         1.2440e-02,  5.0135e-03,  2.3688e-02, -3.0598e-02,  7.2668e-03,\n",
      "         5.3283e-03, -6.0595e-03, -3.4693e-02,  1.9946e-02,  2.1440e-02,\n",
      "         4.1567e-02, -1.9036e-02, -6.1759e-02,  1.4471e-02,  2.8911e-03,\n",
      "        -3.0940e-02, -7.4938e-02,  7.8061e-03, -6.4293e-04,  2.0553e-02,\n",
      "        -1.7003e-02, -4.9909e-03,  2.9901e-03,  1.4400e-02,  1.7686e-02,\n",
      "        -3.7863e-02,  3.9414e-03, -2.9549e-02,  5.7854e-03,  1.3523e-02,\n",
      "         1.6040e-02,  1.4536e-02,  6.1425e-03, -7.8943e-04,  1.6113e-02,\n",
      "        -3.2880e-03,  1.2251e-02,  2.9458e-02,  6.9245e-03,  3.3702e-02,\n",
      "        -1.6833e-02, -1.1570e-02,  1.0793e-02,  3.2881e-02, -5.1833e-03,\n",
      "         8.1774e-03,  9.5623e-03,  1.6213e-02,  1.0387e-02, -1.8012e-02,\n",
      "        -6.0580e-02, -3.8830e-02,  5.4136e-03, -1.3806e-03, -2.3501e-02,\n",
      "        -1.6791e-03, -3.6284e-02, -1.5713e-02,  3.6765e-02,  9.5404e-03,\n",
      "        -7.0106e-02,  3.1583e-02, -2.0567e-02,  4.3096e-02, -2.9065e-02,\n",
      "         2.8100e-02,  3.2063e-03,  1.7237e-02,  4.5855e-02,  2.3422e-02,\n",
      "        -7.4308e-03,  1.4599e-03, -3.7667e-02,  8.2658e-02, -6.9389e-02,\n",
      "        -4.0285e-02, -7.7446e-03,  6.3409e-02,  8.1528e-02, -9.4490e-02,\n",
      "        -3.4283e-02, -3.9286e-02, -2.5525e-02,  6.1864e-02,  6.5428e-03,\n",
      "         4.3346e-03,  3.2065e-02,  4.3230e-02,  2.9064e-02,  6.7079e-02,\n",
      "        -8.4506e-04,  6.3990e-04,  7.0607e-03, -6.0297e-03,  1.1994e-02,\n",
      "         3.0964e-02, -3.8102e-02,  6.7747e-02, -3.4208e-02, -6.6748e-02,\n",
      "         3.4370e-03, -6.6027e-03, -7.9872e-03, -4.5536e-02, -4.0665e-02,\n",
      "        -3.3548e-02,  5.2022e-02,  3.0313e-02,  1.6982e-02, -6.0876e-02,\n",
      "        -4.8643e-02, -2.0336e-02,  4.1869e-02,  6.3714e-02,  4.4623e-02,\n",
      "         2.0916e-02, -4.9731e-02, -5.3833e-02,  4.3345e-02,  1.1326e-02,\n",
      "        -3.4178e-02, -1.6835e-02, -5.9654e-03, -3.7192e-02,  3.4922e-02,\n",
      "        -2.0477e-02,  7.5387e-03, -3.4795e-03, -1.4177e-02, -4.3773e-03,\n",
      "        -2.0087e-02,  6.5674e-03, -2.2673e-02,  2.2522e-03, -9.3597e-03,\n",
      "         5.8169e-03, -6.1777e-03, -2.7555e-02, -2.9460e-04,  3.4292e-03,\n",
      "         6.5284e-03,  3.7496e-03, -6.1878e-03,  2.9268e-02, -6.6093e-03,\n",
      "         1.3560e-03, -7.2651e-03,  9.0297e-03,  2.6942e-03,  9.5315e-03,\n",
      "         2.0632e-02, -3.8370e-03, -2.0487e-02, -5.2309e-03,  2.2158e-02,\n",
      "        -2.9636e-02,  3.5815e-04, -1.2466e-02, -1.2531e-02,  1.8134e-02,\n",
      "        -4.1848e-02, -1.6857e-02, -9.6881e-03, -1.7789e-02, -2.3286e-02,\n",
      "        -2.4110e-02, -3.0884e-03, -1.6715e-02, -1.8578e-03, -1.2633e-02,\n",
      "        -4.8797e-03,  2.2010e-02,  2.3633e-03,  8.2597e-03, -2.4325e-02,\n",
      "        -9.7295e-03, -2.4771e-02, -8.5757e-03,  6.4425e-03, -1.5266e-02,\n",
      "         1.8209e-02, -3.1314e-02,  1.3407e-02,  1.5666e-02,  5.6642e-03,\n",
      "         1.9395e-02, -6.5883e-03,  1.7003e-04, -7.5179e-02, -3.0772e-02,\n",
      "        -1.6425e-01, -4.1515e-02,  2.2795e-03,  9.8322e-02, -1.1212e-01,\n",
      "        -1.3033e-01, -9.8496e-02, -2.8410e-02,  6.2270e-02, -6.1967e-02,\n",
      "         1.4461e-01,  3.7429e-02,  9.7559e-02,  9.9415e-02, -2.4197e-03,\n",
      "        -1.7864e-01,  2.0994e-01,  2.0326e-01,  1.0754e-01,  1.1816e-01,\n",
      "         1.5298e-02, -2.7195e-03,  3.8507e-02,  1.2196e-01, -9.2972e-02,\n",
      "        -2.9601e-01,  1.3505e-01,  3.8865e-02,  2.9583e-02, -2.0520e-01,\n",
      "         4.4400e-02, -2.9562e-01,  3.0302e-02, -2.1207e-01,  7.2058e-02,\n",
      "         9.6878e-02, -5.8355e-04, -8.1039e-02,  2.1101e-02, -3.4452e-03,\n",
      "        -3.5089e-02, -8.9463e-02, -1.3088e-01,  2.0480e-01, -2.0106e-02,\n",
      "         6.7382e-02, -5.9183e-03,  1.0138e-01,  3.3705e-02, -2.1922e-03,\n",
      "        -5.0563e-02,  2.9793e-03, -1.8012e-01,  3.5251e-02,  1.7240e-02,\n",
      "        -4.3754e-02,  2.2963e-02, -3.0503e-02, -1.7884e-02, -3.4366e-02,\n",
      "         4.3537e-02,  2.2842e-02])\n",
      "trainable parameters: bert.encoder.layer.3.attention.output.dense.weight tensor([[-0.0548, -0.0397, -0.1168,  ..., -0.0399,  0.0769,  0.0477],\n",
      "        [ 0.0100,  0.0293, -0.0468,  ..., -0.0234,  0.0050,  0.0297],\n",
      "        [-0.1166,  0.1133, -0.0481,  ...,  0.0789,  0.0106,  0.0307],\n",
      "        ...,\n",
      "        [-0.0446, -0.0320, -0.0121,  ...,  0.0018,  0.0049, -0.0299],\n",
      "        [ 0.0602, -0.0995, -0.0728,  ...,  0.0144,  0.0525,  0.0453],\n",
      "        [-0.0370, -0.0276, -0.0070,  ..., -0.0373,  0.0052,  0.0105]])\n",
      "trainable parameters: bert.encoder.layer.3.attention.output.dense.bias tensor([-2.9705e-02, -7.6778e-02, -1.7622e-01, -4.0634e-02,  4.8597e-02,\n",
      "        -1.3276e-01,  1.5350e-01, -1.0636e-01,  2.0208e-01, -3.2439e-01,\n",
      "         3.1293e-02,  1.9875e-01, -9.7249e-02,  3.3107e-02, -1.0219e-01,\n",
      "         1.2842e-01,  1.3711e-01, -6.6448e-02, -5.5120e-02, -1.4062e-01,\n",
      "         1.1526e-01,  5.0994e-02, -3.7961e-02, -9.0663e-02,  1.0128e-01,\n",
      "         2.9212e-01,  2.2033e-02, -1.0494e-01,  1.1589e-03, -6.2820e-02,\n",
      "         8.1468e-02, -1.3858e-01,  4.6169e-02,  6.2895e-03,  1.3365e-01,\n",
      "         3.5776e-02, -9.2199e-02,  1.0816e-01, -5.0933e-02, -8.8763e-02,\n",
      "        -2.7385e-02,  9.7507e-02, -9.6392e-02, -3.7962e-03, -5.1095e-02,\n",
      "        -2.6629e-01, -1.2480e-01, -2.0226e-01, -2.1583e-02,  1.7874e-02,\n",
      "         4.1744e-02,  2.0709e-01, -4.5444e-02, -1.1477e-02,  9.9953e-02,\n",
      "        -1.8786e-01,  4.4082e-01, -5.0130e-02, -1.6332e-01, -2.2574e-01,\n",
      "        -2.0327e-01, -1.5345e-01, -1.3337e-01, -1.5097e-01, -2.3620e-01,\n",
      "         1.1905e-02,  3.8687e-02, -6.2535e-02,  2.3043e-01,  9.5731e-02,\n",
      "         1.2617e-02, -4.7904e-02,  1.0241e-01, -7.5556e-02, -1.5999e-01,\n",
      "         1.0655e-01,  3.2677e-01, -1.7653e-03,  2.7212e-01, -1.3723e-01,\n",
      "        -3.7478e-02,  1.7631e-03,  2.1340e-03,  8.4703e-02, -2.7775e-02,\n",
      "        -3.0125e-03, -3.0275e-01,  6.2100e-02,  1.3602e-01, -1.2345e-02,\n",
      "         5.0154e-02,  1.3397e-02, -1.9273e-01,  1.1584e-01, -1.3630e-01,\n",
      "         3.5244e-01, -1.8723e-01, -2.0653e-01, -1.1778e-02, -7.3119e-02,\n",
      "         6.5132e-02, -1.3787e-01,  1.1279e-01, -9.6414e-02, -2.1427e-01,\n",
      "         1.5624e-01, -1.2138e-01,  3.3441e-02,  1.4829e-01,  1.3602e-01,\n",
      "        -3.1376e-02,  3.4379e-01, -1.5544e-01, -1.8085e-01, -4.4500e-02,\n",
      "         3.0155e-02, -9.4789e-02, -7.1269e-02, -1.9116e-01,  5.8929e-02,\n",
      "        -6.2518e-02, -1.7399e-01,  1.6755e-01,  1.9094e-01, -9.3361e-02,\n",
      "         8.5321e-02, -6.1744e-02,  1.0230e-01, -2.0290e-01, -5.8787e-02,\n",
      "        -4.1521e-02,  1.4483e-01, -7.6496e-02, -1.1181e-01, -2.6670e-01,\n",
      "         3.8461e-02, -5.8275e-03,  7.9499e-02, -2.4037e-01, -1.8363e-01,\n",
      "        -3.0388e-02, -1.4365e-01,  1.7572e-02,  1.5733e-01, -1.3649e-01,\n",
      "         2.6797e-01,  1.8700e-01, -1.0086e-01, -9.4144e-02,  8.4220e-02,\n",
      "        -3.5592e-02, -2.8947e-01, -1.4366e-02, -3.4748e-01,  2.1741e-02,\n",
      "        -2.3489e-01, -4.7066e-01,  1.5969e-01, -2.5211e-01, -1.3160e-01,\n",
      "        -4.1125e-01,  1.9951e-01, -1.2524e-01, -3.7066e-02,  2.3339e-01,\n",
      "         1.3014e-01, -2.4147e-01, -2.9271e-02,  4.1543e-01, -4.0806e-02,\n",
      "        -1.5528e-01,  7.8238e-02,  8.5774e-02,  4.8336e-02,  2.5818e-02,\n",
      "        -2.8972e-01,  2.8422e-02, -1.4460e-01, -7.5818e-02, -1.8423e-01,\n",
      "        -7.8148e-02,  2.5981e-01, -2.0399e-01, -5.4893e-02,  1.2301e-01,\n",
      "         1.8213e-01, -5.7799e-02, -2.1299e-01,  3.2948e-01, -2.2334e-01,\n",
      "        -1.0193e-01, -3.8831e-02,  2.7483e-01,  2.1681e-01,  5.7538e-02,\n",
      "         2.0348e-01,  9.9828e-02,  1.2577e-01, -6.6450e-02,  3.8665e-01,\n",
      "        -1.1582e-01, -1.9346e-01, -1.7974e-01,  3.8858e-03,  7.1952e-02,\n",
      "         1.8391e-01,  1.2933e-01,  3.2930e-01,  3.7064e-02,  6.1067e-04,\n",
      "         1.0863e-01,  2.6806e-01,  1.3732e-01,  1.3250e-01, -8.0660e-02,\n",
      "        -2.3506e-01, -1.3669e-01,  2.7835e-03,  2.7735e-01, -4.8494e-04,\n",
      "         6.9884e-02, -1.4870e-01, -2.0317e-01, -2.1145e-01,  4.3672e-02,\n",
      "         3.8025e-01, -5.1864e-02,  3.0298e-01,  1.3197e-02,  1.7633e-01,\n",
      "         2.4276e-01,  1.1115e-01, -9.0137e-02, -3.5451e-01,  1.8676e-01,\n",
      "         1.8242e-01,  2.4174e-01, -1.9641e-01, -9.5203e-02, -1.7772e-01,\n",
      "         1.8480e-02, -1.3596e-01, -5.3268e-02,  2.5153e-01,  2.6681e-02,\n",
      "         1.9459e-02,  7.6842e-02, -3.9636e-01,  5.3855e-02, -4.1411e-02,\n",
      "        -9.3121e-02, -5.0760e-02,  2.3568e-02, -3.5393e-02,  8.7937e-02,\n",
      "        -1.7209e-01, -4.9258e-02, -6.7748e-02,  2.3415e-01, -5.7073e-02,\n",
      "         2.4827e-01,  1.2102e-01, -1.6524e-01,  1.2600e-01,  1.4517e-01,\n",
      "        -1.6015e-01,  1.1425e-01,  4.6932e-02,  1.9129e-01, -1.7215e-01,\n",
      "         2.5038e-01, -1.5903e-04,  2.5812e-01,  5.3173e-02, -8.8379e-02,\n",
      "        -5.8251e-01,  9.7932e-01,  1.1768e-01, -1.6002e-01, -2.6863e-01,\n",
      "         3.3981e-02,  2.0148e-01,  2.3393e-01, -1.8595e-01, -3.8428e-01,\n",
      "        -5.3005e-02,  1.8104e-01,  2.2472e-01, -2.5371e-01,  3.5812e-02,\n",
      "         1.0240e-01,  4.4466e-02, -9.0850e-02, -2.5121e-01,  1.2650e-01,\n",
      "         1.0836e-01,  7.5835e-02,  4.2109e-01, -2.0420e-02,  2.0737e-01,\n",
      "         7.0175e-02, -4.2003e-02, -1.7393e-01,  2.0511e-01,  8.2426e-02,\n",
      "         1.7040e-02, -4.7288e-02,  8.9060e-02,  1.4671e-02,  2.7632e-01,\n",
      "         2.8123e-02, -1.0032e-02,  2.8715e-01,  1.9993e-01, -4.0432e-02,\n",
      "         1.3956e-01, -2.2109e-02, -1.1245e-03, -2.4380e-01,  1.4862e-03,\n",
      "        -7.8986e-02,  2.7688e-01,  1.5647e-01, -2.3323e-02, -6.3082e-02,\n",
      "        -7.6135e-02,  2.3040e-01,  1.4500e-01, -9.7702e-02, -6.7739e-02,\n",
      "         2.3743e-01, -1.3745e-01,  1.1360e-01, -5.3324e-03, -1.4809e-01,\n",
      "        -8.8021e-03,  2.7275e-01,  1.5282e-01,  2.1569e-01, -2.3280e-01,\n",
      "        -3.6704e-02,  9.7250e-02,  1.4427e-01, -1.1815e-02, -7.9806e-02,\n",
      "        -6.0774e-02,  3.8095e-02,  2.0165e-01, -2.3550e-02,  1.2392e-02,\n",
      "        -2.2325e-01, -2.2083e-01, -6.2450e-02, -5.1776e-02, -7.4111e-02,\n",
      "         7.4534e-02, -1.4406e-01, -7.8272e-02, -1.7045e-02,  1.7652e-01,\n",
      "         1.5418e-01, -1.3807e-01,  7.7499e-02,  1.1571e-01, -3.0329e-01,\n",
      "        -2.9775e-01,  6.1272e-02, -1.6136e-01,  3.0049e-02, -2.5263e-01,\n",
      "        -3.1928e-03, -8.1105e-03,  1.7463e-01,  1.7389e-02, -2.4122e-02,\n",
      "        -3.7744e-02, -1.9328e-01,  1.4797e-01,  7.6290e-03,  2.6675e-01,\n",
      "         2.0632e-01, -7.8854e-02,  3.6590e-02,  2.1177e-01,  3.1884e-02,\n",
      "        -2.7684e-01,  7.6304e-02,  1.0474e-01,  1.0124e-01, -3.6771e-02,\n",
      "        -2.6317e-01, -3.6218e-01, -9.1360e-02,  1.6771e-01, -2.1153e-02,\n",
      "        -1.1143e-01,  6.6747e-02, -1.6192e-01,  1.2204e-01,  2.4919e-01,\n",
      "         1.3840e-01, -1.6988e-02, -4.3878e-02,  2.9321e-02, -4.5685e-02,\n",
      "        -1.2041e-01, -1.1559e-01,  1.1064e-01, -1.3401e-01,  5.0916e-02,\n",
      "         1.3376e-01, -1.8372e-01,  1.8590e-01,  8.5639e-02, -5.6216e-02,\n",
      "         1.5355e-02,  4.1906e-01, -1.2209e-01, -1.9885e-01, -8.9653e-02,\n",
      "         4.2079e-03, -6.5594e-02, -1.8632e-01,  1.1399e-01,  3.5009e-02,\n",
      "         6.2950e-02, -3.1982e-01, -3.5752e-01,  6.1713e-02, -1.4715e-03,\n",
      "         2.1366e-01, -1.3883e-01, -2.2899e-01, -9.9367e-02,  8.2552e-02,\n",
      "         6.4143e-02, -2.5971e-01, -1.4809e-01,  1.3812e-01,  1.1528e-01,\n",
      "        -2.0137e-02,  1.5707e-01,  3.7916e-03, -6.7905e-02, -1.7384e-01,\n",
      "         1.1340e-01,  1.0551e-01, -1.3210e-01,  7.2175e-02, -6.6167e-02,\n",
      "        -9.2474e-02, -2.1156e-01, -1.6446e-01,  3.9117e-01,  1.9883e-01,\n",
      "        -6.3479e-02,  2.2687e-01, -2.9662e-01, -3.6569e-02, -1.4673e-01,\n",
      "         1.8179e-01,  1.5177e-02, -1.9593e-01, -3.4257e-02, -1.6418e-01,\n",
      "        -4.2498e-03,  1.7808e-01,  2.3653e-01,  7.4116e-02,  9.0571e-02,\n",
      "        -2.9049e-01,  7.1120e-02, -3.5410e-01, -2.3440e-01, -3.0058e-01,\n",
      "        -6.0549e-02,  1.2138e-01,  2.5627e-02,  7.1444e-02,  1.2685e-01,\n",
      "         5.3999e-01, -2.5355e-01, -4.5480e-03,  4.2621e-01, -1.0459e-01,\n",
      "         1.7173e-01, -1.7261e-01,  2.0298e-01,  5.2360e-02, -1.9610e-01,\n",
      "         7.9000e-02,  1.0941e-01, -1.0414e-01,  1.1820e-01,  2.9701e-03,\n",
      "        -2.0108e-02, -1.1534e-01,  2.9355e-01, -7.8820e-02,  1.5904e-01,\n",
      "        -1.9624e-01,  1.1735e-01, -2.0656e-02,  2.5150e-03, -7.4296e-02,\n",
      "         1.9179e-01,  5.6939e-02, -1.5157e-01, -1.0779e-01,  7.3534e-02,\n",
      "        -2.1576e-01, -1.9168e-01])\n",
      "trainable parameters: bert.encoder.layer.3.attention.output.LayerNorm.weight tensor([0.6320, 0.6623, 0.7049, 0.7371, 0.6666, 0.7130, 0.6423, 0.7692, 0.6247,\n",
      "        0.7195, 0.7055, 0.7183, 0.7177, 0.7004, 0.6574, 0.7374, 0.6951, 0.6917,\n",
      "        0.6823, 0.7257, 0.6940, 0.7748, 0.7070, 0.7266, 0.6521, 0.7541, 0.6865,\n",
      "        0.6849, 0.6680, 0.6798, 0.7232, 0.7500, 0.7578, 0.7207, 0.6687, 0.6773,\n",
      "        0.6846, 0.6995, 0.6775, 0.7204, 0.7261, 0.7290, 0.6963, 0.7279, 0.7400,\n",
      "        0.7157, 0.6958, 0.7110, 0.8109, 0.7426, 0.7056, 0.7247, 0.6952, 0.7046,\n",
      "        0.7141, 0.6627, 0.7369, 0.6745, 0.7162, 0.7229, 0.6579, 0.7841, 0.6909,\n",
      "        0.7479, 0.7338, 0.7482, 0.6989, 0.7023, 0.6638, 0.7057, 0.6508, 0.6661,\n",
      "        0.7018, 0.7387, 0.7416, 0.7746, 0.7428, 0.7355, 0.7057, 0.7149, 0.7724,\n",
      "        0.7497, 0.7023, 0.6852, 0.6762, 0.7317, 0.7274, 0.6828, 0.7290, 0.7336,\n",
      "        0.7623, 0.6692, 0.6612, 0.7286, 0.6787, 0.7176, 0.6863, 0.6871, 0.7600,\n",
      "        0.6648, 0.6686, 0.6698, 0.7177, 0.7219, 0.7214, 0.7538, 0.7121, 0.7363,\n",
      "        0.6899, 0.7270, 0.7085, 0.7077, 0.7202, 0.7654, 0.7294, 0.7312, 0.7345,\n",
      "        0.8348, 0.6885, 0.7045, 0.7030, 0.9547, 0.6944, 0.6886, 0.6914, 0.8220,\n",
      "        0.7716, 0.6775, 0.7737, 0.7327, 0.6447, 0.6990, 0.6860, 0.6871, 0.7101,\n",
      "        0.6869, 0.6900, 0.6551, 0.6845, 0.6916, 0.7655, 0.7098, 0.6988, 0.7025,\n",
      "        0.7181, 0.6816, 0.7465, 0.7207, 0.6946, 0.6632, 0.7852, 0.7400, 0.7020,\n",
      "        0.7495, 0.6874, 0.7266, 0.8126, 0.7369, 0.8141, 0.6862, 0.7745, 0.6907,\n",
      "        0.7896, 0.6777, 0.6784, 0.6652, 0.7091, 0.6787, 0.7152, 0.7136, 0.7640,\n",
      "        0.7938, 0.6939, 0.7348, 0.7276, 0.7460, 0.7205, 0.7563, 0.6939, 0.6936,\n",
      "        0.6835, 0.7394, 0.6812, 0.7593, 0.7190, 0.6870, 0.6815, 0.6909, 0.7353,\n",
      "        0.7486, 0.6841, 0.7344, 0.7335, 0.6866, 0.6993, 0.7250, 0.7419, 0.7170,\n",
      "        0.7159, 0.7317, 0.6683, 0.6684, 0.6672, 0.7496, 0.6860, 0.8151, 0.7166,\n",
      "        0.7813, 0.6936, 0.7161, 0.6975, 0.7605, 0.7154, 0.6623, 0.7345, 0.6966,\n",
      "        0.6891, 0.7539, 0.6960, 0.7032, 0.7440, 0.6788, 0.7197, 0.7499, 0.6563,\n",
      "        0.7280, 0.7271, 0.7052, 0.6831, 0.7048, 0.7645, 0.6963, 0.6716, 0.6972,\n",
      "        0.7363, 0.7762, 0.7271, 0.7092, 0.6822, 0.6630, 0.7240, 0.7639, 0.7315,\n",
      "        0.8377, 0.7404, 0.6841, 0.7515, 0.7063, 0.7233, 0.7137, 0.6595, 0.7313,\n",
      "        0.6899, 0.7861, 0.6857, 0.7039, 0.6807, 0.6947, 0.7348, 0.6878, 0.6939,\n",
      "        0.7442, 0.7810, 0.7025, 0.6885, 0.6976, 0.6743, 0.7467, 0.6437, 0.7394,\n",
      "        0.6891, 0.6947, 0.6872, 0.7128, 0.6980, 0.1385, 1.1030, 0.7278, 0.7462,\n",
      "        0.6699, 0.6483, 0.7746, 0.7486, 0.7456, 0.7469, 0.6658, 0.6924, 0.7223,\n",
      "        0.7186, 0.6584, 0.7351, 0.6850, 0.7823, 0.7444, 0.7014, 0.6924, 0.6778,\n",
      "        0.6545, 0.6791, 0.6977, 0.6943, 0.6899, 0.7027, 0.7256, 0.6970, 0.6875,\n",
      "        0.7849, 0.6915, 0.7432, 0.7469, 0.7279, 0.7489, 0.7494, 0.7622, 0.6930,\n",
      "        0.7095, 0.6714, 0.7140, 0.7621, 0.7355, 0.6951, 0.7204, 0.7266, 0.6855,\n",
      "        0.6946, 0.6892, 0.6742, 0.7143, 0.7299, 0.7646, 0.6728, 0.7040, 0.6647,\n",
      "        0.7387, 0.7464, 0.6506, 0.7547, 0.7295, 0.6765, 0.6799, 0.6602, 0.7097,\n",
      "        0.7178, 0.6967, 0.7723, 0.6733, 0.6381, 0.7755, 0.7151, 0.6876, 0.7402,\n",
      "        0.7049, 0.6873, 0.6975, 0.6885, 0.7723, 0.4580, 0.7237, 0.6991, 0.6821,\n",
      "        0.7208, 0.7315, 0.7177, 0.7492, 0.7629, 0.7291, 0.7117, 0.6569, 0.6973,\n",
      "        0.6960, 0.6930, 0.7171, 0.6839, 0.7370, 0.7387, 0.7803, 0.6883, 0.7073,\n",
      "        0.6918, 0.7276, 0.6849, 0.7456, 0.6768, 0.7699, 0.6253, 0.6650, 0.6891,\n",
      "        0.7322, 0.7622, 0.7183, 0.7042, 0.6983, 0.7006, 0.7738, 0.6979, 0.6890,\n",
      "        0.7034, 0.6653, 0.7064, 0.7663, 0.6608, 0.7125, 0.6654, 0.6675, 0.7209,\n",
      "        0.6418, 0.7255, 0.7006, 0.7091, 0.7135, 0.7023, 0.7022, 0.7045, 0.7333,\n",
      "        0.7173, 0.6609, 0.6506, 0.6949, 0.7312, 0.6225, 0.6752, 0.7309, 0.6918,\n",
      "        0.7232, 0.6944, 0.6711, 0.6863, 0.8087, 0.6846, 0.6649, 0.7462, 0.7317,\n",
      "        0.7405, 0.6934, 0.7725, 0.7490, 0.6933, 0.7148, 0.7261, 0.7082, 0.7168,\n",
      "        0.7279, 0.7274, 0.6570, 0.2653, 0.7343, 0.8097, 0.7260, 0.7136, 0.7103,\n",
      "        0.7162, 0.6922, 0.7238, 0.7411, 0.7619, 0.7507, 0.7220, 0.7140, 0.6870,\n",
      "        0.7231, 0.7379, 0.7158, 0.7422, 0.7639, 0.6691, 0.7497, 0.7054, 0.7242,\n",
      "        0.7108, 0.7304, 0.7331, 0.7292, 0.7664, 0.7274, 0.7642, 0.7826, 0.6481,\n",
      "        0.6978, 0.6951, 0.7119, 0.7779, 0.7037, 0.7449, 0.6524, 0.7241, 0.7306,\n",
      "        0.6986, 0.7416, 0.7126, 0.6693, 0.7256, 0.7149, 0.7935, 0.6949, 0.7174,\n",
      "        0.6803, 0.6526, 0.7353, 0.7247, 0.6741, 0.7531, 0.7055, 0.6922, 0.7412,\n",
      "        0.6846, 0.7098, 0.7886, 0.6902, 0.6962, 0.7309, 0.7480, 0.7286])\n",
      "trainable parameters: bert.encoder.layer.3.attention.output.LayerNorm.bias tensor([ 8.4010e-02,  4.7287e-02, -1.6265e-02, -4.5691e-02, -1.6828e-01,\n",
      "         1.8638e-01, -1.5341e-01,  1.9658e-02, -2.3198e-01,  2.9718e-01,\n",
      "         6.1780e-02, -8.5413e-02, -4.6089e-02, -1.6405e-01, -5.0553e-02,\n",
      "         6.8099e-02, -1.0385e-01, -2.6533e-02,  1.8614e-01,  1.1082e-01,\n",
      "         1.1216e-01,  1.8733e-02,  3.1590e-02,  8.6215e-02, -1.5258e-02,\n",
      "        -8.3776e-02, -1.0230e-02,  1.5191e-01,  6.5673e-02,  6.9466e-02,\n",
      "         1.6237e-02, -5.0855e-02, -6.8332e-02,  1.0093e-02, -6.6313e-02,\n",
      "         1.7055e-02,  1.4834e-01, -2.3083e-02, -2.0504e-02,  9.0089e-02,\n",
      "        -1.3208e-02,  8.6677e-02,  1.2885e-01,  1.5495e-01,  1.1838e-01,\n",
      "         1.7083e-01,  1.6880e-01,  6.7943e-02, -1.2604e-01,  1.1712e-01,\n",
      "         4.0172e-02,  2.0715e-01, -1.3521e-01,  5.7619e-02, -8.0781e-02,\n",
      "         1.7509e-01, -2.3566e-01, -3.9217e-02,  1.4702e-01,  4.1954e-01,\n",
      "         1.8846e-01, -2.7671e-02,  7.9479e-02,  1.6074e-01,  2.6085e-01,\n",
      "        -2.0246e-01, -8.3162e-03,  8.9587e-02, -2.4872e-01, -5.5228e-03,\n",
      "         1.2249e-01, -2.9052e-02, -2.5544e-02,  1.5759e-01,  6.4579e-02,\n",
      "         5.5415e-02, -1.4085e-01,  1.5267e-02, -6.6095e-02,  6.5178e-02,\n",
      "         2.1916e-01, -1.0157e-01,  1.3138e-02,  4.3983e-02, -3.2353e-02,\n",
      "         1.7217e-02,  1.4510e-01,  2.0772e-02,  3.5276e-02,  1.2756e-01,\n",
      "         1.6638e-01,  4.3530e-02,  1.5597e-01, -3.3527e-03,  2.5065e-02,\n",
      "        -7.7615e-02,  5.8243e-02,  1.3898e-01,  5.6116e-02,  6.8468e-02,\n",
      "         1.7595e-02,  5.6374e-02, -1.2277e-01,  5.7342e-02,  1.5335e-01,\n",
      "        -1.9975e-01,  2.8410e-02, -2.3005e-02, -9.0572e-03, -5.1643e-02,\n",
      "         3.4618e-02, -1.7574e-01, -7.3154e-02,  1.3724e-01, -1.4155e-01,\n",
      "         1.1812e-02,  2.8022e-02, -5.1559e-02,  1.7113e-01,  8.7939e-02,\n",
      "         1.2886e-01, -2.1410e-02, -1.7042e-01,  1.3055e-02,  9.2607e-03,\n",
      "        -1.4883e-01,  5.4071e-02,  6.8857e-02,  3.8462e-02,  1.2457e-01,\n",
      "         2.0342e-01,  6.1408e-02,  7.6888e-02, -1.3348e-02,  3.4693e-01,\n",
      "         4.0124e-03,  7.1840e-02,  3.5173e-02,  2.1676e-01,  6.7812e-02,\n",
      "         5.7802e-02,  5.4368e-02, -1.2487e-01, -1.8299e-01,  1.5327e-01,\n",
      "        -4.3757e-02, -1.3937e-01,  1.2767e-01,  2.1364e-01,  7.0073e-02,\n",
      "         2.2400e-01,  1.2491e-01,  1.2569e-01,  6.1732e-02, -7.8504e-02,\n",
      "         1.5820e-01,  2.5861e-01, -7.7151e-02,  2.9769e-01,  1.8581e-01,\n",
      "         1.6514e-01, -1.6000e-01, -2.4394e-02,  1.1855e-01, -3.0677e-02,\n",
      "         1.7613e-01,  2.7368e-01,  8.4877e-02, -1.2396e-01,  4.7826e-02,\n",
      "         4.1988e-02,  7.3840e-02,  1.9488e-02, -1.4767e-02, -4.3015e-02,\n",
      "         4.5211e-02,  1.4041e-01,  5.9487e-02,  6.4203e-02,  1.3464e-01,\n",
      "         7.8494e-02, -5.7445e-02,  1.0625e-01,  4.1737e-02,  1.6506e-01,\n",
      "        -1.4000e-01,  1.7252e-03,  1.9239e-01, -2.5565e-01,  1.6228e-01,\n",
      "         5.0221e-02, -2.0977e-02,  1.3214e-01, -3.3424e-01, -4.4264e-02,\n",
      "         3.3975e-02, -1.1848e-01,  1.0736e-01,  8.4968e-02, -1.6410e-01,\n",
      "         1.0380e-01,  1.6298e-01,  1.9090e-02, -1.3762e-01,  8.0283e-03,\n",
      "         1.0062e-01, -1.0441e-01, -8.7804e-02,  6.3156e-03,  1.4293e-01,\n",
      "         1.0673e-02, -5.0449e-02, -1.1871e-01,  6.9696e-02,  1.0297e-01,\n",
      "         1.4577e-02,  1.0646e-01, -1.2464e-01, -2.0401e-01, -2.9516e-02,\n",
      "         1.6059e-01,  1.8745e-01,  7.4506e-02,  3.6244e-02,  4.7491e-02,\n",
      "        -7.7331e-02,  1.2852e-01, -7.0019e-02,  8.6802e-02,  9.5945e-02,\n",
      "        -5.6852e-02,  2.7402e-02,  1.0511e-01,  1.8956e-01, -1.0797e-01,\n",
      "        -1.1638e-01, -1.1724e-01,  1.2995e-01,  1.4672e-01,  1.5354e-01,\n",
      "        -3.2129e-02,  1.1453e-01,  1.6577e-02, -1.1564e-01,  9.0854e-02,\n",
      "        -7.4521e-02,  1.4667e-01,  1.4713e-01, -1.2176e-02, -4.5105e-02,\n",
      "         2.3156e-01, -9.3369e-02,  5.6998e-02,  4.5190e-02, -2.9841e-02,\n",
      "         2.1490e-01,  3.1874e-02,  2.5849e-01, -6.8511e-02,  1.1789e-01,\n",
      "        -1.0501e-01, -4.2052e-02,  3.0118e-01, -1.2453e-01, -1.2225e-01,\n",
      "         1.0833e-01, -7.2748e-02, -1.6531e-01, -2.0842e-02,  1.6536e-02,\n",
      "        -1.1616e-01, -1.7874e-01, -7.8562e-02,  5.7043e-02,  9.1296e-02,\n",
      "        -2.6308e-01, -1.5383e+00, -7.7991e-02,  2.7504e-01,  2.7177e-01,\n",
      "         1.9830e-02, -9.4961e-02, -1.2299e-01,  4.2060e-02,  2.6676e-01,\n",
      "        -2.6760e-02, -1.9161e-03, -5.9701e-02,  2.1408e-01, -4.2670e-02,\n",
      "         1.3355e-01, -6.7077e-02,  1.8230e-01,  2.3326e-01, -6.5021e-02,\n",
      "         3.8181e-02,  8.0328e-02, -1.4338e-01,  1.5988e-01, -3.3555e-02,\n",
      "         1.0570e-01,  2.2224e-02,  1.3130e-01, -2.0169e-02,  1.9194e-01,\n",
      "         3.0078e-02,  1.3201e-01, -1.3168e-02,  9.1267e-02,  4.5887e-03,\n",
      "        -3.8187e-02, -1.0867e-01, -1.1900e-01, -1.4349e-01,  1.0397e-02,\n",
      "        -1.9136e-01,  5.7065e-03,  2.4944e-02,  1.7796e-01,  1.3089e-01,\n",
      "         6.7509e-02, -1.5151e-01, -1.6114e-01,  2.1095e-01,  7.8987e-02,\n",
      "         2.0561e-01, -1.1047e-01, -2.6106e-02,  4.2747e-02,  1.4020e-01,\n",
      "        -2.4179e-01,  3.6629e-02, -3.4350e-02, -3.9057e-02,  1.6303e-01,\n",
      "         1.8148e-01, -5.1118e-02, -1.6267e-02, -2.2677e-01,  3.1906e-01,\n",
      "         6.4986e-02, -3.8445e-02,  7.0519e-02,  1.9548e-01,  1.0214e-02,\n",
      "         1.0896e-01,  9.8452e-02, -1.3114e-01, -3.1972e-02,  1.2007e-01,\n",
      "        -3.3193e-02,  9.3102e-02,  1.6605e-01,  1.7658e-01,  2.2114e-01,\n",
      "        -9.4565e-03, -1.0548e-01, -1.3758e-02,  1.4361e-02,  6.8254e-02,\n",
      "        -4.6105e-03,  1.5172e-01, -1.7055e-01, -2.4210e-03,  1.9978e-01,\n",
      "         2.9187e-01, -8.7640e-02,  1.5446e-01, -1.5538e-01,  2.5511e-02,\n",
      "         1.1480e-01, -1.3891e-01, -9.6881e-02,  3.6824e-02,  1.4247e-01,\n",
      "        -1.1331e-01,  2.5782e-01, -1.7673e-02,  8.2332e-02, -8.4387e-02,\n",
      "        -6.8365e-02, -1.3370e-01,  5.1720e-02, -1.9591e-01, -8.4195e-03,\n",
      "         5.5056e-02, -1.3448e-01, -1.0082e-01,  2.9282e-02, -1.4071e-01,\n",
      "         1.6200e-02,  1.9726e-01,  1.3782e-02,  5.4246e-02,  1.5763e-01,\n",
      "         1.4078e-01,  1.2367e-01,  5.6637e-02, -2.8326e-02,  4.5217e-02,\n",
      "         1.4250e-01, -6.7647e-02,  5.3414e-02,  1.7181e-01,  1.3823e-01,\n",
      "         1.8802e-01,  1.1485e-01,  9.9713e-02,  2.8013e-01,  9.5100e-02,\n",
      "         3.1116e-02, -1.6334e-01, -7.3359e-02, -1.9368e-02,  1.5707e-02,\n",
      "        -4.9985e-02, -2.4393e-01,  9.6087e-02,  1.4594e-01,  7.9845e-02,\n",
      "         1.9079e-01,  9.6361e-02,  1.5952e-01,  6.6312e-02, -9.1226e-02,\n",
      "        -1.2695e-01,  1.5702e-01,  1.7710e-01,  1.1741e-01,  1.4592e-01,\n",
      "        -1.0791e-02,  3.9068e-02,  1.5131e-01,  2.0605e-01, -1.2720e-01,\n",
      "         2.5813e-01,  1.7437e-01,  1.7684e-01, -1.3854e-03,  5.6085e-02,\n",
      "         1.6164e-01, -2.0574e-01,  4.1172e-02,  7.0075e-02, -3.6596e-01,\n",
      "        -7.0825e-02, -8.1624e-02,  1.8674e-01,  7.4519e-02, -4.3096e-02,\n",
      "         1.2193e-01,  1.7337e-01,  3.3130e-01, -7.8541e-02,  3.5103e-03,\n",
      "         1.6356e-01, -1.5251e-01,  1.7754e-01,  1.8602e-01,  1.7548e-01,\n",
      "        -1.1184e-01,  7.7614e-02, -6.1740e-02,  1.4863e-01, -3.8839e-02,\n",
      "        -8.0927e-02,  7.3378e-02, -1.1769e-01, -4.4580e-02,  1.0909e-01,\n",
      "         1.5446e-01,  8.1136e-02,  3.1174e-01,  5.9516e-02,  5.7387e-02,\n",
      "         1.4554e-01, -1.1261e-01,  1.2883e-02,  3.5143e-02, -1.6109e-01,\n",
      "         4.5569e-02,  1.4542e-01, -4.9842e-02, -1.8080e-01,  1.7043e-01,\n",
      "        -9.7929e-02,  3.4714e-02, -5.2739e-02,  4.1879e-02,  1.0366e-01,\n",
      "        -7.7893e-02,  4.4712e-02,  1.8616e-01, -5.9840e-02,  9.4362e-02,\n",
      "         1.5231e-01,  5.4832e-02, -2.3896e-01, -4.2765e-02,  7.2178e-02,\n",
      "         2.2837e-01, -3.0317e-02,  2.2194e-01, -4.0166e-02,  1.7104e-01,\n",
      "         6.5592e-03,  5.5209e-02,  1.2326e-01,  3.4165e-01, -1.4363e-01,\n",
      "         2.0003e-01,  1.2449e-01])\n",
      "trainable parameters: bert.encoder.layer.3.intermediate.dense.weight tensor([[-1.8411e-02, -8.1117e-03, -5.4623e-03,  ..., -8.7405e-02,\n",
      "          5.6318e-02, -2.5680e-02],\n",
      "        [-2.9455e-02,  3.9893e-05, -1.9813e-02,  ..., -2.0749e-03,\n",
      "         -4.2301e-04, -5.7533e-02],\n",
      "        [-2.3380e-02,  7.0726e-02,  7.9113e-02,  ...,  9.6591e-03,\n",
      "          7.2456e-02, -8.5814e-02],\n",
      "        ...,\n",
      "        [ 2.2529e-02,  3.0903e-03,  3.1127e-03,  ..., -4.3712e-02,\n",
      "          1.0087e-01,  7.4836e-03],\n",
      "        [-1.3349e-02,  3.1886e-02,  5.3566e-02,  ..., -2.4658e-02,\n",
      "          2.9257e-02,  4.3236e-02],\n",
      "        [-3.9223e-02, -4.2465e-02, -4.1520e-02,  ...,  6.6930e-03,\n",
      "          4.2756e-02,  3.3833e-02]])\n",
      "trainable parameters: bert.encoder.layer.3.intermediate.dense.bias tensor([-0.0813, -0.0423, -0.1938,  ..., -0.1453,  0.0119, -0.0340])\n",
      "trainable parameters: bert.encoder.layer.3.output.dense.weight tensor([[-0.0248,  0.0832, -0.0427,  ...,  0.0150, -0.0704,  0.0033],\n",
      "        [-0.0192, -0.0447,  0.0349,  ..., -0.0527,  0.0287,  0.0285],\n",
      "        [-0.0772,  0.0698,  0.0536,  ...,  0.0371,  0.0904, -0.0083],\n",
      "        ...,\n",
      "        [-0.0166, -0.0206,  0.0171,  ...,  0.0416,  0.0047, -0.0562],\n",
      "        [-0.0582, -0.0315,  0.0286,  ..., -0.0086,  0.0687, -0.0450],\n",
      "        [-0.0292,  0.0216,  0.0925,  ...,  0.0142, -0.0083,  0.0414]])\n",
      "trainable parameters: bert.encoder.layer.3.output.dense.bias tensor([ 2.1163e-02, -5.5655e-04, -4.0697e-02,  1.1294e-02,  1.9285e-02,\n",
      "         2.4595e-02,  3.6563e-03, -6.3611e-02,  3.8903e-03, -1.4207e-02,\n",
      "         4.1341e-03, -2.5534e-02, -5.1447e-02, -1.8087e-02,  4.5804e-02,\n",
      "         2.9642e-02, -1.4064e-02, -7.0952e-02,  4.9279e-03,  1.3360e-02,\n",
      "         7.5918e-02,  3.1029e-02,  4.0601e-02, -9.5007e-03,  2.1573e-02,\n",
      "        -1.6833e-02, -6.0944e-02, -2.0681e-02, -8.1122e-02, -3.8462e-02,\n",
      "         1.6091e-02, -8.7819e-02, -5.3331e-02, -7.4290e-03, -8.5575e-03,\n",
      "         4.0034e-02, -1.6261e-02, -9.8892e-02,  2.5163e-02,  3.1721e-02,\n",
      "        -6.3206e-03,  4.9390e-02,  3.3654e-02, -5.2871e-02, -3.4071e-02,\n",
      "         2.9017e-02,  6.4004e-03, -2.8633e-03, -5.4971e-03,  2.1812e-02,\n",
      "         3.2662e-02, -4.5351e-02, -4.4042e-02, -1.9616e-02, -6.1787e-03,\n",
      "         4.7751e-02, -5.6826e-02, -3.6485e-03, -2.9458e-02,  6.2306e-02,\n",
      "        -2.2901e-02, -5.8428e-02, -1.9527e-02, -1.7423e-02, -5.1616e-02,\n",
      "        -9.5913e-02,  3.0673e-02, -8.4008e-03, -4.9530e-02,  1.6663e-02,\n",
      "         5.4030e-02, -1.5399e-02, -6.3213e-02, -3.9858e-02, -1.0755e-02,\n",
      "         5.6486e-02, -4.8002e-02, -4.0995e-02, -6.8745e-02,  4.3507e-02,\n",
      "        -2.0473e-02,  3.2812e-02,  1.9580e-02,  2.1871e-02, -3.6724e-02,\n",
      "         2.6063e-02,  2.8090e-02,  3.9132e-03, -3.1718e-02, -2.3344e-02,\n",
      "         4.2037e-02, -1.1175e-02,  9.1708e-02, -1.5742e-02, -3.4127e-02,\n",
      "         9.8716e-03, -1.8579e-02,  1.8842e-02,  6.4793e-02, -2.5244e-02,\n",
      "         1.1056e-02, -7.8480e-02, -9.4263e-02, -5.4637e-02, -1.8635e-02,\n",
      "        -2.8589e-02, -3.6995e-03, -3.2598e-02, -6.5431e-02, -6.1262e-02,\n",
      "         1.7979e-02, -3.6833e-02,  2.2239e-03,  5.1958e-02, -4.4414e-02,\n",
      "        -4.7879e-02,  2.4585e-02, -6.3564e-02,  1.1834e-03,  4.0633e-02,\n",
      "         2.1236e-02, -8.0593e-03,  2.8585e-02, -9.3871e-02, -1.2433e-02,\n",
      "        -7.6821e-02,  1.0456e-02,  6.0734e-02, -1.2144e-02,  4.5189e-02,\n",
      "        -2.3740e-03, -2.8628e-02,  2.3204e-02, -7.7755e-03, -2.1332e-02,\n",
      "         1.9095e-02, -5.2106e-02,  6.1980e-02,  6.9229e-03, -1.0666e-02,\n",
      "        -4.2671e-02, -1.5677e-02, -3.0427e-02, -2.0450e-02,  2.6919e-02,\n",
      "         5.6716e-04, -5.1065e-02, -6.0978e-02,  2.2853e-02, -6.6841e-03,\n",
      "         4.1510e-02,  3.4159e-02, -5.3132e-02, -3.1516e-02, -5.4200e-04,\n",
      "        -5.4422e-02,  6.8648e-02, -2.9835e-02,  7.5591e-02, -8.9902e-03,\n",
      "         9.1296e-02,  7.1012e-04, -1.9289e-02,  6.0085e-02, -1.9273e-02,\n",
      "         9.9990e-02,  2.3034e-02, -5.1204e-02, -8.7519e-02, -8.5126e-02,\n",
      "        -3.6286e-02, -8.3589e-02,  4.3478e-02,  1.7589e-02, -9.4755e-03,\n",
      "        -6.7132e-02,  6.1992e-02, -5.6301e-02, -4.9089e-02,  4.0738e-02,\n",
      "         6.7513e-03,  4.1451e-02, -5.2625e-02, -3.8425e-02,  1.0679e-01,\n",
      "         4.9803e-02,  2.6997e-02,  4.8998e-02, -1.8108e-02, -2.8077e-02,\n",
      "        -1.0619e-02, -3.5130e-02,  2.0557e-02, -5.6917e-03, -3.9353e-02,\n",
      "         2.7295e-02, -7.0237e-03,  7.7305e-02,  2.3740e-03,  9.6364e-03,\n",
      "        -4.4969e-02, -1.0985e-02,  7.1658e-02,  3.1569e-02,  3.3118e-02,\n",
      "         1.3734e-02, -3.4190e-02, -3.3002e-02,  3.8526e-02,  3.9582e-03,\n",
      "        -7.9723e-02, -3.4039e-02, -4.6411e-02, -7.3355e-02,  2.7904e-02,\n",
      "        -6.4252e-02,  2.1238e-02,  4.2430e-02, -8.1339e-02, -3.2097e-02,\n",
      "        -2.6668e-03, -1.6911e-02, -2.3558e-02, -5.6600e-02,  5.1188e-02,\n",
      "        -1.6637e-02,  3.3476e-02,  2.6703e-04,  9.7223e-03,  1.3625e-02,\n",
      "        -6.2875e-02, -3.6577e-02,  2.4111e-02,  5.5942e-02, -8.1189e-02,\n",
      "         1.8885e-02, -5.4485e-02, -4.7608e-02, -6.4068e-02,  2.4482e-02,\n",
      "        -7.5446e-02, -5.2304e-02,  4.2866e-02, -2.4643e-02,  1.2576e-02,\n",
      "        -3.6513e-02, -3.9755e-02, -3.1770e-03,  6.2577e-02, -8.6786e-03,\n",
      "         1.7327e-02, -3.1105e-02,  8.6627e-02,  2.6143e-02,  3.9071e-02,\n",
      "         2.6346e-02, -1.2684e-02, -1.1931e-02, -1.0183e-02,  3.0857e-02,\n",
      "        -1.0497e-01, -5.0563e-02,  2.8137e-02, -4.7934e-02, -1.4684e-02,\n",
      "         5.6262e-02, -3.2069e-02, -5.7350e-02,  2.1544e-03,  1.8399e-02,\n",
      "         3.8997e-02,  1.4613e-02,  2.5101e-02, -3.1155e-02,  7.9932e-02,\n",
      "         1.0981e-01, -2.7675e-01, -6.5655e-03,  1.3542e-02,  9.0568e-03,\n",
      "        -1.2097e-02,  4.1127e-02,  1.9969e-02,  2.5457e-02, -4.1708e-03,\n",
      "        -4.4176e-02, -3.8772e-02, -1.2533e-03,  4.7901e-02, -6.4533e-03,\n",
      "         1.0003e-02, -7.3333e-02, -7.2603e-03,  3.1855e-03, -3.4080e-02,\n",
      "        -2.0956e-02,  5.6428e-02, -2.8983e-02,  5.1203e-02,  4.5975e-03,\n",
      "         4.7840e-04, -7.5409e-02, -2.6899e-02, -1.7864e-03,  4.6566e-02,\n",
      "         3.2926e-02,  1.6610e-02,  2.2617e-02,  8.0055e-02,  1.1901e-02,\n",
      "        -4.7469e-02,  1.1339e-01, -4.8292e-02, -1.6220e-02, -1.2823e-01,\n",
      "        -5.1695e-02,  2.4881e-03, -6.5947e-02, -3.3512e-02,  5.4835e-02,\n",
      "         8.4809e-02, -1.8870e-02,  6.7816e-03,  4.6658e-02, -3.7597e-02,\n",
      "         9.7616e-02, -7.3922e-02, -3.1021e-02,  2.2347e-02, -4.4068e-02,\n",
      "        -1.3690e-02,  2.0295e-02,  5.7788e-02, -1.5207e-02,  4.0952e-02,\n",
      "         1.0330e-01,  1.8542e-02, -4.1586e-03, -4.7514e-03,  1.2610e-01,\n",
      "         5.8287e-02,  7.2676e-02, -3.5119e-02,  4.4867e-02, -5.7692e-03,\n",
      "         2.4772e-02, -3.8985e-03,  2.5018e-02, -1.4971e-02, -9.9163e-04,\n",
      "        -4.3827e-02,  2.3745e-02, -2.6369e-03,  1.6775e-02,  1.5264e-02,\n",
      "        -1.8783e-02,  3.6842e-04, -3.4463e-02, -2.4790e-02, -1.4603e-02,\n",
      "        -8.3282e-03, -3.9195e-03, -6.7800e-02, -5.4813e-02, -1.2031e-03,\n",
      "        -1.8767e-02,  6.9639e-03, -4.6782e-03, -5.0423e-03,  5.8834e-02,\n",
      "         8.7523e-03, -2.7337e-02, -1.0220e-02,  4.8435e-03, -6.5151e-02,\n",
      "        -6.8203e-02,  5.6123e-02, -3.4188e-02, -6.5745e-02, -6.3751e-02,\n",
      "         1.3601e-02, -3.4472e-02, -4.2717e-03, -2.0654e-02, -3.9132e-02,\n",
      "         8.8575e-03,  3.1699e-02, -6.5162e-02,  4.1016e-02, -2.9888e-02,\n",
      "         3.4135e-02,  1.2334e-02,  1.7854e-02, -2.9368e-03,  7.2955e-02,\n",
      "         2.6179e-03,  4.7237e-02,  6.9498e-02, -9.1863e-03,  2.7024e-02,\n",
      "        -1.4001e-02,  1.6867e-02,  4.0368e-02, -5.6764e-02, -4.7681e-03,\n",
      "         5.5338e-04,  2.2739e-03,  6.6870e-02,  5.4319e-02,  1.1713e-01,\n",
      "         2.4176e-02, -2.1934e-02, -6.2526e-02,  1.0958e-01, -2.7422e-02,\n",
      "        -2.2450e-02, -1.1869e-03,  6.8179e-03, -6.8439e-02,  2.4238e-02,\n",
      "        -3.5306e-02,  6.3561e-02,  6.5497e-02,  3.2432e-02,  4.3106e-02,\n",
      "        -3.4069e-02, -3.7899e-03,  8.1752e-03,  6.8577e-02,  1.0714e-02,\n",
      "        -4.3177e-03, -1.1447e-01,  3.4385e-02,  5.1663e-02, -2.6748e-02,\n",
      "        -1.8381e-02,  4.4008e-02, -4.5060e-02,  6.8973e-02, -7.3442e-03,\n",
      "        -2.5029e-02, -1.2226e-01,  5.0805e-02, -9.0947e-03,  1.8549e-01,\n",
      "        -1.8699e-02,  4.3790e-02, -2.4555e-02,  8.9633e-02,  6.0412e-02,\n",
      "         4.9133e-02,  2.9023e-02,  8.0963e-02, -1.7248e-02,  6.8721e-02,\n",
      "        -1.4164e-02,  3.6627e-03,  4.1716e-02, -4.7942e-02,  2.3147e-02,\n",
      "         1.9552e-04,  3.2057e-02, -6.2981e-04, -1.9759e-02, -6.2938e-02,\n",
      "        -9.0687e-02,  5.0070e-02,  5.5199e-02,  3.1638e-02,  1.8932e-02,\n",
      "         2.1924e-02,  2.2086e-03, -3.2916e-02, -8.7919e-02, -3.5841e-02,\n",
      "         3.2962e-02, -4.5600e-02,  8.3215e-02, -5.1102e-02,  3.9252e-02,\n",
      "         1.3980e-02,  2.5834e-02,  1.5804e-02, -4.8654e-02, -2.6329e-03,\n",
      "         5.3022e-02,  4.8159e-03, -4.4249e-03,  3.2686e-02,  3.9406e-02,\n",
      "         2.6968e-02,  5.8949e-03,  9.1468e-02, -6.1529e-02, -1.3922e-02,\n",
      "        -3.1260e-02, -2.8354e-02, -2.5629e-02, -7.6501e-02,  1.2118e-02,\n",
      "         1.0006e-01,  4.6252e-02,  5.7125e-02,  5.3589e-02,  1.8209e-02,\n",
      "         3.9950e-02,  2.1258e-02,  2.0386e-03,  1.1043e-01, -4.8019e-02,\n",
      "         4.4985e-02,  6.2622e-02])\n",
      "trainable parameters: bert.encoder.layer.3.output.LayerNorm.weight tensor([0.7669, 0.8061, 0.7900, 0.7531, 0.8777, 0.7627, 0.7763, 0.7477, 0.8655,\n",
      "        0.8251, 0.7368, 0.7503, 0.7660, 0.8102, 0.7694, 0.7372, 0.7698, 0.7728,\n",
      "        0.8222, 0.7966, 0.7846, 0.8015, 0.7628, 0.8250, 0.7866, 0.7656, 0.7984,\n",
      "        0.7740, 0.8055, 0.7992, 0.7384, 0.7900, 0.8198, 0.7907, 0.7830, 0.7558,\n",
      "        0.8016, 0.7718, 0.7598, 0.7735, 0.7990, 0.7863, 0.7473, 0.8135, 0.7823,\n",
      "        0.7854, 0.8082, 0.7904, 0.8416, 0.8696, 0.7775, 0.7869, 0.7907, 0.7714,\n",
      "        0.8148, 0.8664, 0.7742, 0.7650, 0.8026, 0.8569, 0.8116, 0.7356, 0.7601,\n",
      "        0.8206, 0.7521, 0.7997, 0.7554, 0.7985, 0.8367, 0.7959, 0.8055, 0.7734,\n",
      "        0.7652, 0.7900, 0.7866, 0.7896, 0.8253, 0.8023, 0.7617, 0.7490, 0.8294,\n",
      "        0.7686, 0.7636, 0.8220, 0.7853, 0.8035, 0.7763, 0.7934, 0.7755, 0.8310,\n",
      "        0.8226, 0.7561, 0.7985, 0.7633, 0.7986, 0.8194, 0.7666, 0.7622, 0.7560,\n",
      "        0.7731, 0.7714, 0.7960, 0.7612, 0.7972, 0.7939, 0.8690, 0.7363, 0.7603,\n",
      "        0.7651, 0.7875, 0.7662, 0.8015, 0.7721, 0.7267, 0.8430, 0.8053, 0.7920,\n",
      "        0.7662, 0.7703, 0.7968, 0.8075, 0.8630, 0.8345, 0.8087, 0.7561, 0.7531,\n",
      "        0.7706, 0.7814, 0.7932, 0.7788, 0.7724, 0.8024, 0.7548, 0.7948, 0.8246,\n",
      "        0.7909, 0.8015, 0.7854, 0.7913, 0.7692, 0.7750, 0.7439, 0.7826, 0.7774,\n",
      "        0.7890, 0.7703, 0.7900, 0.7685, 0.7804, 0.8040, 0.8891, 0.8116, 0.7826,\n",
      "        0.7777, 0.7787, 0.7445, 0.8967, 0.8153, 0.8033, 0.8270, 0.7890, 0.7666,\n",
      "        0.7558, 0.8190, 0.7943, 0.7528, 0.7695, 0.7673, 0.7980, 0.8239, 0.7885,\n",
      "        0.9012, 0.7592, 0.7540, 0.7757, 0.7922, 0.7600, 0.8077, 0.7798, 0.7655,\n",
      "        0.7792, 0.8367, 0.8216, 0.7817, 0.8054, 0.7959, 0.7651, 0.7962, 0.8212,\n",
      "        0.7612, 0.7587, 0.7816, 0.8192, 0.7776, 0.7880, 0.8082, 0.7946, 0.7669,\n",
      "        0.7826, 0.7907, 0.7726, 0.8262, 0.7554, 0.7770, 0.8266, 0.7856, 0.7693,\n",
      "        0.8104, 0.7847, 0.8195, 0.7895, 0.7504, 0.8435, 0.7859, 0.7434, 0.7580,\n",
      "        0.7539, 0.8481, 0.8410, 0.8117, 0.8519, 0.8183, 0.7711, 0.7404, 0.7939,\n",
      "        0.7930, 0.7810, 0.8145, 0.7475, 0.7513, 0.7862, 0.7941, 0.7571, 0.7840,\n",
      "        0.7908, 0.7810, 0.7862, 0.7919, 0.7817, 0.7625, 0.8199, 0.7371, 0.7286,\n",
      "        0.8742, 0.7368, 0.7990, 0.7668, 0.7796, 0.7660, 0.7661, 0.8452, 0.7649,\n",
      "        0.7698, 0.7549, 0.7717, 0.8059, 0.7981, 0.7801, 0.7639, 0.8014, 0.7608,\n",
      "        0.7547, 0.9097, 0.7839, 0.7940, 0.8015, 0.7859, 0.8261, 0.8186, 0.7396,\n",
      "        0.8138, 0.7395, 0.7962, 0.7681, 0.8076, 0.7507, 0.5138, 0.7951, 0.7966,\n",
      "        0.7980, 0.7889, 0.8050, 0.8313, 0.7704, 0.7909, 0.7701, 0.7881, 0.7903,\n",
      "        0.8121, 0.7991, 0.7778, 0.7643, 0.7962, 0.8143, 0.7692, 0.7847, 0.7668,\n",
      "        0.7959, 0.8162, 0.8114, 0.7768, 0.7581, 0.7750, 0.7840, 0.8383, 0.7520,\n",
      "        0.7688, 0.7953, 0.7904, 0.8143, 0.7344, 0.7776, 0.7916, 0.7749, 0.7824,\n",
      "        0.7845, 0.7464, 0.7796, 0.7353, 0.8208, 0.7914, 0.7899, 0.8012, 0.8345,\n",
      "        0.7794, 0.8108, 0.7748, 0.8019, 0.7215, 0.8646, 0.8417, 0.7776, 0.7793,\n",
      "        0.7542, 0.8021, 0.8025, 0.7899, 0.7787, 0.8684, 0.8197, 0.7610, 0.7632,\n",
      "        0.8003, 0.8310, 0.7751, 0.8098, 0.7863, 0.7885, 0.7828, 0.7884, 0.7038,\n",
      "        0.7808, 0.7518, 0.7572, 0.7942, 0.8029, 0.7074, 0.7911, 0.8164, 0.8094,\n",
      "        0.7643, 0.7648, 0.7566, 0.7817, 0.8117, 0.7860, 0.7928, 0.7973, 0.7697,\n",
      "        0.7805, 0.7690, 0.7429, 0.7869, 0.7850, 0.7810, 0.7851, 0.8246, 0.7862,\n",
      "        0.7849, 0.7844, 0.7798, 0.7635, 0.7768, 0.8267, 0.7793, 0.7793, 0.7512,\n",
      "        0.7846, 0.7902, 0.8020, 0.7768, 0.7823, 0.7908, 0.7706, 0.7645, 0.7748,\n",
      "        0.7417, 0.7995, 0.7784, 0.8122, 0.8148, 0.7885, 0.7940, 0.7612, 0.8018,\n",
      "        0.7900, 0.7381, 0.7831, 0.7600, 0.7857, 0.7590, 0.7512, 0.7914, 0.7845,\n",
      "        0.7815, 0.7808, 0.7620, 0.7762, 0.7838, 0.7741, 0.8156, 0.7551, 0.7970,\n",
      "        0.7702, 0.7757, 0.7825, 0.7910, 0.7815, 0.8166, 0.7787, 0.7642, 0.7677,\n",
      "        0.7788, 0.7871, 0.8018, 0.8262, 0.8292, 0.7497, 0.7909, 0.7567, 0.7627,\n",
      "        0.8151, 0.7748, 0.7677, 0.5384, 0.7494, 0.9524, 0.7989, 0.7825, 0.8282,\n",
      "        0.7921, 0.7868, 0.7321, 0.8146, 0.7800, 0.8034, 0.8310, 0.8154, 0.7683,\n",
      "        0.7907, 0.7580, 0.7412, 0.7767, 0.9117, 0.7868, 0.7621, 0.8138, 0.7483,\n",
      "        0.7665, 0.7719, 0.7812, 0.7749, 0.7722, 0.7681, 0.7724, 0.7589, 0.8187,\n",
      "        0.7827, 0.7600, 0.8191, 0.8122, 0.7784, 0.7541, 0.8169, 0.7819, 0.7921,\n",
      "        0.7600, 0.8022, 0.7864, 0.8024, 0.7839, 0.7657, 0.8316, 0.7764, 0.7833,\n",
      "        0.7929, 0.7729, 0.7737, 0.8113, 0.7580, 0.8017, 0.7741, 0.7773, 0.8733,\n",
      "        0.7610, 0.7997, 0.8268, 0.7805, 0.7805, 0.7932, 0.7910, 0.7892])\n",
      "trainable parameters: bert.encoder.layer.3.output.LayerNorm.bias tensor([-5.3647e-02, -8.7456e-02,  6.9675e-02, -1.1227e-01, -1.5024e-01,\n",
      "        -1.3827e-02, -5.3477e-02, -1.1471e-01, -1.2610e-01,  2.2853e-01,\n",
      "        -1.9376e-01, -1.8650e-01, -4.1090e-02, -9.9990e-02,  5.8484e-02,\n",
      "         6.8995e-03, -2.0159e-02,  1.7032e-02,  1.3623e-01,  5.5402e-02,\n",
      "         2.9577e-02, -9.1719e-02, -4.3650e-02,  6.9076e-02, -3.3061e-02,\n",
      "        -2.1841e-01, -9.2937e-02, -2.7420e-02, -1.6035e-02,  5.1696e-02,\n",
      "        -1.1178e-01, -1.4147e-01,  3.1128e-02, -6.9303e-02,  5.9385e-03,\n",
      "         9.1092e-02,  4.6903e-02, -1.8869e-01, -7.5224e-03, -8.0668e-02,\n",
      "        -1.5075e-01,  2.5526e-02,  1.6292e-02, -3.5040e-02, -1.6298e-01,\n",
      "         1.0075e-01,  1.8256e-02, -3.9010e-02,  4.5491e-02,  7.3737e-03,\n",
      "        -1.2230e-01,  2.1670e-02,  8.7436e-03,  2.4980e-02, -1.0280e-01,\n",
      "         1.3052e-01, -1.1541e-01, -6.5180e-04, -1.4864e-02,  1.1317e-01,\n",
      "         5.7684e-02,  2.7503e-02,  3.0704e-02,  1.2946e-01,  6.0749e-02,\n",
      "        -2.2189e-01,  4.5637e-03, -4.6305e-02, -1.0375e-01,  5.8216e-02,\n",
      "         2.5847e-02, -9.3237e-02, -8.8463e-02, -2.2054e-01, -1.0890e-01,\n",
      "         2.6962e-02, -1.9235e-01, -3.3249e-02, -4.7780e-02,  1.5599e-02,\n",
      "         1.6524e-01,  6.8557e-02, -5.1061e-02, -8.6477e-02, -6.9073e-02,\n",
      "         1.5455e-01,  9.8467e-02, -1.3299e-01, -8.3770e-02,  9.6892e-02,\n",
      "         1.8963e-02,  1.2565e-01,  2.8469e-02, -9.8842e-02, -7.2037e-03,\n",
      "        -2.1172e-01, -7.0724e-02,  4.9375e-02,  7.8206e-02,  4.2827e-02,\n",
      "         3.9845e-02, -1.5411e-01,  1.8964e-03,  3.8770e-02,  5.2570e-02,\n",
      "        -2.6690e-01, -3.2692e-02, -1.0220e-01, -1.4734e-01, -1.5473e-01,\n",
      "         9.1870e-02, -1.0147e-01, -5.8542e-02, -4.9910e-02, -8.3905e-02,\n",
      "         8.6948e-03,  1.2117e-01, -1.3373e-01, -4.1998e-02,  8.8889e-02,\n",
      "         3.6129e-02,  6.1292e-02, -8.9550e-02, -3.6229e-03, -1.4934e-01,\n",
      "        -1.1983e-01, -4.0586e-02,  2.5148e-02, -2.7140e-02,  6.3688e-02,\n",
      "        -2.4110e-02, -4.1706e-02, -7.9582e-02,  1.6607e-01,  1.4923e-01,\n",
      "         8.1525e-02,  5.7692e-02,  6.9613e-02,  6.2885e-02,  2.4352e-02,\n",
      "        -1.8452e-01,  4.3053e-02, -1.4750e-01, -2.1252e-01,  1.7094e-01,\n",
      "        -4.7394e-02, -1.9260e-01, -7.8181e-02,  8.5390e-02,  7.9678e-02,\n",
      "         8.1335e-02,  1.6465e-01, -4.3301e-02, -3.6138e-02, -1.0364e-01,\n",
      "        -3.8911e-02,  3.4899e-01, -1.5758e-01,  1.7791e-01,  4.6429e-02,\n",
      "         2.3668e-01,  7.5198e-02,  6.7461e-02,  7.1136e-02, -5.8347e-02,\n",
      "         7.5645e-02, -5.9031e-02, -1.2075e-01, -1.5684e-01,  3.8965e-02,\n",
      "        -1.1829e-01, -7.7077e-02, -1.6456e-02,  8.0039e-02,  1.0443e-02,\n",
      "        -2.4117e-02, -5.0436e-02, -1.3348e-01, -8.9256e-02, -1.4259e-02,\n",
      "        -3.9822e-03,  5.8031e-02,  1.5128e-01, -3.2022e-02,  8.0573e-02,\n",
      "         4.5667e-02,  5.7932e-02,  9.8120e-02, -1.7446e-01,  1.0710e-02,\n",
      "         8.2523e-02, -1.3872e-01, -9.0483e-02, -9.0337e-03,  6.8356e-02,\n",
      "        -9.9495e-02, -2.0313e-01,  8.7975e-02,  2.7624e-02, -5.2575e-02,\n",
      "        -6.7000e-02,  9.5424e-02,  1.5156e-01, -1.1930e-01, -1.2796e-01,\n",
      "        -3.3692e-02, -1.9579e-01, -2.4089e-02,  3.5044e-02, -1.3176e-02,\n",
      "        -1.5506e-01, -4.7171e-02, -1.8999e-01, -9.1571e-02, -3.9582e-02,\n",
      "        -2.6973e-02, -3.1643e-02, -9.6991e-03, -2.8927e-01, -1.4725e-01,\n",
      "        -5.6984e-03,  1.7813e-02, -1.6882e-01, -5.9151e-02, -1.0249e-01,\n",
      "        -1.7661e-01, -4.9082e-02, -1.0659e-01, -6.9165e-02, -1.7381e-02,\n",
      "        -1.9925e-02, -1.5616e-01, -1.4096e-01,  1.4270e-01, -6.4873e-02,\n",
      "         6.6179e-02, -5.2524e-02, -4.2676e-02, -1.0313e-01,  1.0183e-01,\n",
      "        -1.6052e-01,  2.3606e-02,  1.0188e-01, -1.0914e-01,  8.0667e-02,\n",
      "        -1.4061e-01, -3.6880e-02, -2.0778e-02,  1.1020e-01, -1.0647e-01,\n",
      "         5.4900e-02, -1.0467e-01, -3.7209e-02,  9.7489e-02, -7.0437e-02,\n",
      "         1.4824e-01, -7.3776e-02,  6.2505e-02, -1.6009e-01, -5.1566e-02,\n",
      "        -1.6422e-01, -1.0667e-01,  8.9748e-02, -1.4528e-01, -9.3524e-02,\n",
      "         6.9031e-03,  3.8433e-02, -1.4394e-01, -7.8866e-02,  6.6580e-02,\n",
      "        -1.7229e-01,  1.4295e-01, -7.3029e-02,  7.3714e-02,  6.2472e-02,\n",
      "         1.8193e-01,  3.4659e-02, -1.1406e-01, -7.0298e-02, -5.1213e-02,\n",
      "         9.5562e-02, -1.3688e-02, -1.0232e-01,  5.5771e-02,  1.3303e-01,\n",
      "         3.2263e-02, -1.4953e-01,  6.3490e-02,  1.5668e-01, -1.5616e-01,\n",
      "        -1.0788e-01, -8.5109e-02,  8.5825e-02,  1.3825e-01,  7.1821e-03,\n",
      "        -2.0669e-02,  2.8778e-02, -1.5228e-01,  1.0894e-01, -1.3679e-01,\n",
      "         5.0197e-02, -7.3059e-03,  1.3735e-03,  1.8747e-02,  1.8832e-02,\n",
      "        -6.2308e-02,  7.3608e-03, -6.9134e-03,  7.6755e-02,  8.9032e-02,\n",
      "        -5.7880e-02,  1.2439e-01, -1.9183e-01, -1.4424e-01, -5.6504e-02,\n",
      "        -8.7750e-02, -1.4070e-02, -4.6896e-02, -1.0408e-01,  1.0563e-01,\n",
      "         7.2757e-02, -1.3499e-01, -1.7704e-01,  8.9108e-02, -1.1295e-01,\n",
      "         3.2154e-02, -2.2105e-02, -6.9069e-02, -1.1899e-01,  1.4045e-01,\n",
      "        -8.4704e-02,  7.2054e-02, -2.5425e-03, -5.9077e-02,  8.5945e-03,\n",
      "         1.2930e-01,  1.1556e-01,  7.2480e-03, -1.9492e-01,  1.4560e-03,\n",
      "         1.2265e-02,  1.5085e-01,  1.9659e-02, -3.6471e-02, -6.4268e-02,\n",
      "         1.3305e-01, -4.4644e-02, -2.9885e-02,  2.7430e-02, -2.6808e-02,\n",
      "        -1.7806e-01, -5.6589e-02, -2.3839e-02, -1.6332e-02,  4.3326e-02,\n",
      "        -3.8982e-02, -6.3392e-02,  6.6628e-03, -2.0568e-01, -8.0089e-02,\n",
      "         2.4838e-02,  5.9409e-02, -1.1868e-01, -2.2040e-01,  2.1989e-01,\n",
      "        -7.2575e-02, -7.5770e-02, -2.5031e-02,  4.5156e-02,  5.4450e-02,\n",
      "         1.2838e-02, -4.5444e-02, -8.2986e-02, -7.7609e-02, -3.1008e-02,\n",
      "        -5.4948e-02,  1.4761e-02,  9.0962e-02,  1.4872e-02, -8.1637e-02,\n",
      "        -1.5937e-05, -1.3738e-01,  6.1962e-02, -1.9787e-01, -1.4615e-01,\n",
      "         1.7140e-02,  3.4289e-02, -2.1269e-01,  1.5960e-01,  6.6753e-02,\n",
      "         5.7621e-02,  1.5977e-02,  2.4144e-02, -1.5509e-01, -1.5024e-01,\n",
      "        -5.6200e-02, -4.4868e-02, -5.0485e-02, -5.4510e-02,  2.6661e-02,\n",
      "         3.4485e-02, -6.2717e-02, -7.2362e-03, -9.7925e-02, -9.7970e-02,\n",
      "         4.0258e-02, -7.6300e-02, -1.1082e-01,  6.2026e-03,  8.1479e-02,\n",
      "        -8.4295e-02, -1.1831e-01, -5.4626e-02,  1.7438e-02, -6.4404e-02,\n",
      "        -3.6415e-02,  1.1284e-01,  2.4880e-02, -2.1245e-01, -4.4258e-02,\n",
      "         7.7064e-02, -1.3433e-01,  1.5125e-01, -1.8176e-01,  1.0454e-01,\n",
      "        -1.2107e-01,  4.5534e-02,  1.4131e-01, -1.7493e-02, -5.4189e-02,\n",
      "        -1.1612e-01, -1.6581e-02,  5.9808e-02,  1.9598e-02, -1.6334e-01,\n",
      "         5.6107e-02, -5.9093e-02,  1.4823e-02, -1.3196e-01, -1.3634e-01,\n",
      "        -1.2489e-01, -2.0130e-01,  9.1151e-02, -9.1426e-02,  5.4228e-02,\n",
      "        -1.4048e-01, -6.1818e-02,  4.6713e-02,  2.3720e-02, -5.4845e-02,\n",
      "        -9.6347e-02,  4.1665e-02,  5.2348e-02, -2.1188e-01,  6.2758e-02,\n",
      "         1.4285e-01, -7.2040e-02,  7.4931e-02, -3.6978e-02,  5.5297e-02,\n",
      "        -7.2023e-02,  7.2027e-02, -1.5067e-01,  1.2984e-01,  3.1599e-02,\n",
      "        -1.4180e-01, -1.2944e-01, -8.0680e-02,  1.4192e-03,  3.3370e-02,\n",
      "         9.3001e-02,  1.2504e-01,  1.4170e-02, -6.2141e-02, -7.8732e-02,\n",
      "         1.8555e-02, -6.9091e-02, -1.8709e-02, -1.4329e-01, -1.9406e-01,\n",
      "        -5.2221e-02,  5.0916e-02, -1.1104e-01, -2.2996e-01, -2.1379e-02,\n",
      "        -6.5202e-02,  6.1276e-02, -1.7902e-01, -8.6534e-03,  2.9583e-02,\n",
      "        -8.8103e-02, -1.0918e-01,  1.3824e-01,  1.0456e-01, -1.1285e-01,\n",
      "        -2.6930e-02,  6.4374e-02, -8.6810e-02, -1.0272e-02,  6.0518e-02,\n",
      "         1.1506e-01, -2.9552e-02, -3.3823e-02, -6.3076e-02,  6.5215e-02,\n",
      "         8.6522e-02,  1.3064e-02, -6.5467e-02,  8.8387e-03, -1.0167e-01,\n",
      "         7.6319e-02,  1.1972e-01])\n",
      "trainable parameters: bert.pooler.dense.weight tensor([[ 0.0168,  0.0224, -0.0735,  ...,  0.0725, -0.0799, -0.0841],\n",
      "        [ 0.0041, -0.1317,  0.1029,  ..., -0.0228, -0.0140,  0.0430],\n",
      "        [-0.0077,  0.0328,  0.0465,  ..., -0.0273,  0.0175, -0.0195],\n",
      "        ...,\n",
      "        [-0.0395, -0.0344, -0.0061,  ..., -0.0172, -0.0214, -0.0128],\n",
      "        [-0.0034,  0.0019,  0.0334,  ...,  0.0544,  0.0262, -0.0208],\n",
      "        [ 0.0630,  0.1096,  0.0009,  ...,  0.0019, -0.0471, -0.0274]])\n",
      "trainable parameters: bert.pooler.dense.bias tensor([ 1.1019e-02, -4.5856e-02, -1.3468e-02,  3.0728e-02, -2.4772e-02,\n",
      "        -3.9822e-03,  1.0182e-01,  8.9449e-03, -4.8621e-02,  1.1087e-02,\n",
      "        -5.7776e-03, -1.1511e-01,  7.4636e-02, -1.2469e-02,  2.9773e-03,\n",
      "         1.3464e-02, -3.3500e-03,  2.8674e-02, -7.2814e-02,  2.9462e-02,\n",
      "         5.8961e-02,  9.4916e-04,  3.8032e-03, -7.1465e-02,  1.5058e-01,\n",
      "         2.3833e-02, -8.2749e-03, -4.6421e-02,  5.4393e-02,  8.4126e-02,\n",
      "         1.3808e-02, -1.3876e-02,  2.2390e-02,  1.4570e-03,  2.3037e-02,\n",
      "        -5.8925e-02, -2.3630e-02, -7.5927e-02, -6.5457e-03, -2.6966e-02,\n",
      "        -5.7283e-02, -3.7504e-02,  2.6970e-03, -1.0444e-01, -1.2523e-02,\n",
      "         4.6506e-02, -1.2357e-02, -3.5624e-02, -2.9070e-02, -6.4566e-02,\n",
      "         1.1294e-01, -4.0208e-02,  1.3963e-01, -5.4254e-02, -4.6346e-02,\n",
      "         4.3587e-02,  3.3337e-02, -3.1520e-02, -1.3328e-01, -2.9311e-02,\n",
      "         7.5766e-03,  1.0852e-02,  1.3709e-03, -1.1471e-02,  3.0349e-02,\n",
      "        -1.1259e-02,  2.6490e-02,  4.0882e-02, -1.1348e-02, -2.2574e-02,\n",
      "         3.6065e-03,  1.5255e-01, -8.5109e-03,  1.6586e-02,  1.3883e-02,\n",
      "         3.6761e-02,  1.1272e-02,  6.9675e-02,  6.0421e-03, -4.9986e-02,\n",
      "        -2.2708e-02, -6.1605e-02,  1.6946e-02, -2.5776e-02,  9.5902e-02,\n",
      "        -8.2931e-03,  1.4757e-03,  2.0614e-03, -7.9394e-02,  3.0467e-02,\n",
      "        -6.8663e-02,  2.0702e-02,  6.4394e-02, -9.7438e-03,  2.9834e-02,\n",
      "        -5.0732e-03,  1.2224e-02, -4.9187e-02, -3.3188e-02,  1.6256e-02,\n",
      "        -4.8563e-03,  2.1159e-02, -1.7914e-02, -3.8072e-02, -1.9723e-02,\n",
      "        -3.0198e-02,  4.0761e-03,  3.6302e-02, -6.5483e-02,  3.2225e-02,\n",
      "         7.8698e-03, -3.9039e-03,  1.6395e-02, -8.4893e-02, -3.7821e-02,\n",
      "         2.3974e-02,  1.3057e-02,  4.6439e-02,  7.2311e-03,  1.1316e-01,\n",
      "        -1.2634e-02, -4.8228e-02, -9.1334e-02,  3.0710e-02, -5.0200e-02,\n",
      "        -3.9984e-02,  1.4531e-02, -1.2770e-02, -4.7459e-02, -4.6901e-02,\n",
      "         1.5761e-02, -2.4174e-03,  1.4827e-03,  2.4893e-02,  3.1541e-02,\n",
      "         2.2380e-02,  1.0951e-01, -7.0635e-02, -2.1206e-02,  2.0691e-02,\n",
      "         8.4338e-02,  3.2529e-02, -6.3158e-02, -2.5616e-02, -1.7626e-02,\n",
      "         1.0277e-01, -1.2771e-01,  4.2540e-03,  7.0163e-02, -2.9683e-02,\n",
      "        -5.1188e-02,  2.0425e-03,  9.7578e-02, -6.4909e-02,  5.7634e-02,\n",
      "        -4.5034e-02, -6.2224e-02,  2.9348e-02,  1.1069e-02,  6.0495e-02,\n",
      "        -4.2163e-02,  1.7382e-02, -1.9458e-02, -3.7077e-02,  1.4260e-01,\n",
      "        -6.1754e-02, -6.7518e-02, -6.4917e-02,  1.2834e-02,  5.7970e-03,\n",
      "         4.0304e-02,  6.1882e-03, -1.7182e-02, -7.9139e-02,  2.1352e-02,\n",
      "         6.7495e-02,  4.8361e-03, -1.7133e-02,  1.6536e-01,  2.4525e-02,\n",
      "         9.0633e-02, -6.0749e-02,  2.9896e-03, -3.7268e-02, -2.4326e-02,\n",
      "        -4.6952e-03, -1.2609e-01,  1.6709e-02,  5.6826e-02,  9.4449e-03,\n",
      "         1.1062e-02,  8.0858e-03,  2.6648e-02, -2.7033e-02,  1.2996e-01,\n",
      "        -5.2813e-02,  5.6817e-02, -9.2528e-02,  1.1167e-02, -1.0304e-02,\n",
      "         1.7892e-03, -3.3765e-02,  5.7719e-02,  2.4285e-02, -3.8140e-02,\n",
      "        -7.6828e-02, -3.9927e-02,  1.4582e-02,  1.1739e-01, -4.3323e-02,\n",
      "         5.1805e-02, -5.7073e-02,  1.8926e-02,  7.6071e-02,  6.6912e-02,\n",
      "        -1.8046e-02,  8.2744e-02, -5.6711e-02,  8.6726e-02,  8.6726e-03,\n",
      "        -8.5855e-02, -4.5324e-02, -1.7912e-02,  4.5817e-02, -1.6935e-02,\n",
      "        -2.4393e-02, -8.3283e-02, -2.2444e-02,  1.3739e-02,  9.8456e-02,\n",
      "        -4.7836e-03,  1.0078e-02, -5.6195e-02,  6.6807e-02,  9.4317e-02,\n",
      "         4.5297e-02,  4.2449e-02, -1.1404e-03,  7.6401e-02,  7.0903e-03,\n",
      "        -4.5660e-02,  1.3197e-01,  5.4070e-02,  1.3805e-01,  4.9661e-02,\n",
      "         5.9303e-02,  1.8317e-02,  1.2273e-02, -3.1386e-02,  8.3710e-04,\n",
      "         1.4584e-02, -6.0100e-02, -1.9480e-02,  2.9043e-02,  1.4393e-01,\n",
      "        -4.6257e-02, -3.1603e-02, -1.1470e-01,  2.2389e-02, -6.2633e-03,\n",
      "        -3.4430e-02, -9.8872e-02, -4.1831e-02,  6.5624e-03,  2.1897e-02,\n",
      "         1.2006e-01,  8.4056e-02,  1.9151e-03, -9.4584e-03, -9.7709e-03,\n",
      "         2.0171e-02, -3.6304e-04,  2.3266e-02,  1.2830e-01, -8.4949e-02,\n",
      "         6.5735e-03, -3.3220e-03,  4.4490e-02, -8.1946e-02,  5.8238e-02,\n",
      "         1.0936e-02,  3.5345e-02,  8.3840e-02,  1.4175e-01, -2.7367e-02,\n",
      "        -1.7733e-02,  3.9336e-02,  2.2765e-02, -9.2059e-02, -1.5604e-01,\n",
      "        -7.1008e-03,  7.0549e-02,  5.3630e-02,  2.0588e-02,  6.6062e-02,\n",
      "        -2.0094e-02, -2.1018e-02,  1.2739e-01, -2.4254e-02,  1.2130e-01,\n",
      "         1.2700e-01, -1.2506e-02,  9.7587e-03,  9.3688e-02, -7.9875e-02,\n",
      "         2.7029e-02,  2.3554e-02,  1.2740e-01, -1.5090e-02,  3.3111e-02,\n",
      "        -4.4130e-02, -1.6021e-02,  3.5555e-05,  7.7298e-02, -1.8243e-02,\n",
      "        -2.3496e-02,  1.8312e-02,  5.7005e-02,  8.3366e-02,  1.0155e-01,\n",
      "         3.1197e-03,  2.0363e-02,  7.0030e-03, -8.2137e-03, -2.8152e-02,\n",
      "        -4.9783e-02, -1.7593e-03,  3.0202e-02, -9.1345e-02, -1.5894e-02,\n",
      "        -1.8382e-02, -7.0968e-03, -2.4476e-02, -4.0330e-02,  2.1870e-02,\n",
      "         4.0127e-02,  5.9231e-03,  6.7289e-03,  3.6547e-03,  1.1158e-02,\n",
      "         5.1715e-03, -3.1954e-02, -6.1697e-02,  3.6555e-03,  2.4915e-02,\n",
      "        -2.3872e-02, -2.1593e-02,  1.2994e-01,  2.0378e-03,  9.9496e-02,\n",
      "         2.1948e-02,  4.1957e-02, -5.1660e-02, -2.4128e-02,  8.7160e-02,\n",
      "        -1.5923e-03,  6.4324e-02, -3.1718e-02, -6.0775e-02,  6.6215e-03,\n",
      "        -1.7201e-02, -7.9709e-02, -8.5472e-02, -2.5292e-02, -2.7175e-02,\n",
      "         2.3495e-02, -8.4819e-02, -3.0174e-02,  6.8809e-02,  5.6334e-02,\n",
      "        -3.5759e-02,  1.4091e-01, -5.9682e-02, -2.2997e-02, -6.9489e-02,\n",
      "        -1.4533e-01,  1.5375e-02,  4.8459e-02, -1.5774e-02, -2.5587e-02,\n",
      "         6.2863e-02,  3.2072e-02,  8.6590e-03,  3.7181e-02,  1.0030e-01,\n",
      "         4.9017e-02,  7.1962e-02, -3.4035e-02,  3.6876e-02, -3.3684e-02,\n",
      "        -8.4128e-03,  3.6363e-03, -1.2940e-01,  4.7946e-02, -6.5736e-03,\n",
      "        -2.9881e-02, -4.6005e-02, -7.7366e-02, -1.1234e-02,  3.8325e-02,\n",
      "        -5.9362e-03,  6.8836e-02,  6.1046e-02, -4.7510e-02, -1.9026e-02,\n",
      "         3.8625e-02, -6.9204e-02, -3.0168e-02,  2.5076e-02,  3.0434e-02,\n",
      "        -8.2471e-03,  7.0396e-03, -3.4052e-03,  7.2382e-03,  5.2183e-02,\n",
      "         3.0324e-02,  4.2077e-02,  6.5551e-02,  4.8475e-02, -3.4871e-02,\n",
      "        -4.2710e-02,  4.7351e-03,  1.3946e-02,  8.0568e-02,  9.3082e-03,\n",
      "         2.4942e-02, -5.6810e-02,  3.3037e-02,  6.3249e-03,  1.7047e-02,\n",
      "         5.9997e-02,  1.1159e-02,  1.2986e-01, -1.5557e-01,  1.7858e-03,\n",
      "         3.0951e-02, -8.3531e-02,  6.1104e-02, -4.7091e-03, -3.5977e-02,\n",
      "         1.3994e-02, -1.5251e-01,  9.2797e-03,  4.7291e-02, -1.7845e-02,\n",
      "        -7.3118e-02,  4.2896e-02,  1.4844e-02, -4.7872e-02,  5.4966e-02,\n",
      "         7.7872e-02,  1.4256e-03,  4.5615e-03, -1.2251e-02,  7.3041e-02,\n",
      "         1.2863e-01,  2.0313e-02, -5.1219e-02,  4.6216e-02,  5.5401e-03,\n",
      "         1.2109e-02,  3.3040e-02, -1.3401e-01,  5.4734e-02,  9.5910e-02,\n",
      "         1.4325e-01,  7.4942e-02,  1.3519e-01, -2.2166e-02, -2.0855e-02,\n",
      "         3.5293e-02,  2.1127e-02, -4.7042e-02,  3.2126e-02,  4.0756e-02,\n",
      "        -1.2841e-01,  2.7581e-02, -1.4590e-02, -1.3401e-01,  1.1042e-01,\n",
      "         5.3869e-02,  2.0519e-02,  6.7500e-02,  6.8815e-02,  2.7755e-02,\n",
      "         3.9031e-02, -5.0066e-02, -4.6311e-02,  3.1392e-03, -3.2818e-02,\n",
      "        -2.9618e-02, -1.7810e-01,  1.2471e-02,  7.2641e-02,  2.3004e-02,\n",
      "        -6.1524e-02,  1.8270e-02,  3.9535e-02, -6.3436e-02,  1.5227e-01,\n",
      "        -1.6250e-02, -2.1882e-02, -7.3840e-03,  2.3370e-02,  7.0824e-02,\n",
      "        -6.2608e-02,  3.1503e-02,  8.0301e-02,  5.5185e-02, -2.1432e-03,\n",
      "        -6.8730e-02, -6.1750e-03])\n",
      "trainable parameters: classifier.weight tensor([[ 0.0032, -0.0076, -0.0195,  ...,  0.0468,  0.0024,  0.0175],\n",
      "        [-0.0075, -0.0392, -0.0290,  ...,  0.0039,  0.0059, -0.0023],\n",
      "        [ 0.0258, -0.0182,  0.0529,  ...,  0.0038, -0.0222, -0.0315]])\n",
      "trainable parameters: classifier.bias tensor([ 0.0032, -0.0034, -0.0020])\n"
     ]
    }
   ],
   "source": [
    "classifier.unfreeze_base()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Early stopping is used to determine the optimal number of training epochs before the model starts to overfit. The *early_stopping* function, randomly shuffle the data passed as arguments (training data, labels, encoded labels), then split it into an analysis (train) set and an assessment (validation) set. By default, 20% of the data is used for validation (this number can be adjusted using the *val_proportion* argument). Because only 1 out of 5 folds is used, the estimate of the number of epochs has high variance. We encourage the reader to estimate the optimal number of epochs by running early stopping algorithm multiple times using different fold each time. Beware however, that the computational cost can be very high and this might take a long time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-small were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-small and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Training Loss: 0.4520879461343375, Training Accuracy = 0.8243427140602035\n",
      "Validation\n",
      "Loss: 0.37873299795004967, Accuracy = 0.8567073170731707\n",
      "Epoch: 0, Training Loss: 0.31911021510646975, Training Accuracy = 0.8826955527733928\n",
      "Validation\n",
      "Loss: 0.3715384116182136, Accuracy = 0.8610627177700348\n",
      "Epoch: 0, Training Loss: 0.2436333684952639, Training Accuracy = 0.9119808393663927\n",
      "Validation\n",
      "Loss: 0.4032980676234184, Accuracy = 0.8534407665505227\n",
      "optimal number of epochs:  2\n"
     ]
    }
   ],
   "source": [
    "from explainable_bert_classifier.model import early_stopping\n",
    "\n",
    "optimal_nb_epoch, history_early_stopping = early_stopping(classifier, X_train, train_labels, encoded_train_labels, mytokenizer, max_epoch=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal number of epochs:  2\n",
      "{'train_acc': [0.8243427140602035, 0.8826955527733928, 0.9119808393663927], 'train_loss': [0.4520879461343375, 0.31911021510646975, 0.2436333684952639], 'val_acc': [0.8567073170731707, 0.8610627177700348, 0.8534407665505227], 'val_loss': [0.37873299795004967, 0.3715384116182136, 0.4032980676234184]}\n"
     ]
    }
   ],
   "source": [
    "print(\"optimal number of epochs: \", optimal_nb_epoch)\n",
    "print(history_early_stopping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After determining the optimal number of epochs using early stopping, the model is trained on the entire training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Training Loss: 0.4376412469771859, Training Accuracy = 0.8271567303923704\n",
      "Epoch: 1, Training Loss: 0.3134477616699062, Training Accuracy = 0.8854243783477769\n"
     ]
    }
   ],
   "source": [
    "history2 = classifier.fit(loader=train_loader, total_iterations=optimal_nb_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classifier.model.save_pretrained('./models/bert-small-vulnerability_confidentiality_impact-classification')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from explainable_bert_classifier.model import BertClassifier\n",
    "\n",
    "classifier =  BertClassifier(model_name='./models/bert-small-vulnerability_confidentiality_impact-classification/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.37964943548151725, Accuracy = 0.8637373165527152\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['predicted_labels', 'predicted_scores', 'accuracy', 'loss'])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=16)\n",
    "predictions_dict = classifier.evaluate_batch_by_batch(test_loader)\n",
    "predictions_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.8637373165527152\n",
      "precision:  0.86271703192871\n",
      "recall:  0.8637373165527152\n",
      "f1 score:  0.8628228464529746\n",
      "confusion matrix: \n",
      "[[12361   546   609]\n",
      " [  721  3576   202]\n",
      " [  923   128  3897]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "y_true = test_dataset[:]['encoded_labels'].numpy()\n",
    "y_pred = np.array(predictions_dict['predicted_labels'])\n",
    "\n",
    "print(\"accuracy: \", accuracy_score(y_true, y_pred))\n",
    "print(\"precision: \", precision_score(y_true, y_pred, average='weighted'))\n",
    "print(\"recall: \", recall_score(y_true, y_pred, average='weighted'))\n",
    "print(\"f1 score: \", f1_score(y_true, y_pred, average='weighted'))\n",
    "\n",
    "\n",
    "print(\"confusion matrix: \")\n",
    "print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the distribution of the confidence (score of the logit after softmax for the predicted class) of our model for the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   61.,   162.,   538.,   649.,   731.,   863.,   963.,  1229.,\n",
       "         2044., 15723.]),\n",
       " array([0.34684891, 0.41189826, 0.47694761, 0.54199696, 0.60704631,\n",
       "        0.67209566, 0.73714501, 0.80219436, 0.86724371, 0.93229306,\n",
       "        0.99734241]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(predictions_dict['predicted_scores'], bins=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explaining classification results using gradient-based input saliency maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Explainability*, also reffered to as *Interpretability* of a machine learning model refers to the ability to determine the cause and effect relationship between the inputs of a model and its prediction. It allows a human user to understand and explain the decision of a model. It also allows knowledge discovery (spot specific patterns in the data) and helps debug the model, for example, to better understand incorrect predictions.\n",
    "\n",
    "Gradient-based input saliency methods is used to find out which input tokens (sub-words) are the most important for a given prediction made by the model.\n",
    "\n",
    "For a given prediction, the importance of each input token is obtained by calculating the gradient of the score (value of the output logit) corresponding to the predicted class, with respect to the inputs. Specifically, the smallest change in the input token with the highest gradient-based saliency value will result in a large change in the output of the model. \n",
    "We use the *Gradient X Input* method in which the computed gradient vector per token is multiplied by the input embedding of the token. Taking the $L2$ norm of the resulting vector gives the token's feature importance score, a measure of how sensitive the model is to that specific input token. More formally, the importance of the token at the $i^{th}$ position in the input sequence is given by:\n",
    "<p style=\"text-align: center;\"> \n",
    "    $\\left \\| \\nabla_{X_{i}} f_{c}(X_{1:n}) \\cdot X_{i} \\right \\|_{2}$\n",
    "</p>\n",
    "where $X_{i}$ is the embedding vector of the $i^{th}$ input token, $X_{1:n}$ is the list of embedding vectors of all the tokens in the input sequence (of length $n$), $f_{c}(X_{1:n})$ is the score of the predicted class after a forward pass through the model, $\\nabla_{X_{i}} f_{c}(X_{1:n})$ is the back-propagated gradient of the score of the predicted class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predicted_labels': tensor([2, 0, 0, 0, 2, 1, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0]),\n",
       " 'predicted_scores': tensor([0.9961, 0.9798, 0.9803, 0.9840, 0.9921, 0.9964, 0.8504, 0.8156, 0.9939,\n",
       "         0.9950, 0.9804, 0.9849, 0.8253, 0.9949, 0.9948, 0.9807],\n",
       "        grad_fn=<MaxBackward0>)}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "#load a batch of 16 test samples\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "test_batch = next(iter(test_loader))\n",
    "input_ids = test_batch['input_ids']\n",
    "attention_mask = test_batch['attention_mask']\n",
    "labels = test_batch['encoded_labels']\n",
    "\n",
    "classifier.predict(test_batch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing the connectivity tensor obtained when predicting the class of a specific vulnerability description in the batch. The connectivity tensor contains the importance score of each input token for a vulnerability description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input grad variable: None\n",
      "output logits: tensor([[ 3.4673, -0.4992, -3.4166]], grad_fn=<AddmmBackward>)\n",
      "predicted label (after softmax): 0\n",
      "score for predicted label (after softmax): 0.9804266691207886\n",
      "input grad variable: tensor([[-0.0077,  0.0132,  0.0011,  ..., -0.0039, -0.0055, -0.0235],\n",
      "        [-0.0722, -0.0150,  0.0241,  ..., -0.0907, -0.1056,  0.0477],\n",
      "        [ 0.0202,  0.0081,  0.0301,  ...,  0.0226,  0.0087,  0.0112],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.1480, 0.8103, 0.1246, 0.0362, 0.1025, 0.0359, 0.0877, 0.1018, 0.0741,\n",
       "        0.0281, 0.0281, 0.0234, 0.0261, 0.1407, 0.0295, 0.0358, 0.0612, 0.0143,\n",
       "        0.0665, 0.0183, 0.0292, 0.0319, 0.0173, 0.1188, 0.0377, 0.0253, 0.0773,\n",
       "        0.0274, 0.0789, 0.0236, 0.0278, 0.0209, 0.0328, 0.0426, 0.0331, 0.0313,\n",
       "        0.0376, 0.0287, 0.0518, 0.0243, 0.0221, 0.0197, 0.0183, 0.0395, 0.0448,\n",
       "        0.0280, 0.0447, 0.0312, 0.0567, 0.0368, 0.0302, 0.0350, 0.0209, 0.1517,\n",
       "        0.0184, 0.0213, 0.0309, 0.0369, 0.0245, 0.0238, 0.0524, 0.0259, 0.0265,\n",
       "        0.0483, 0.0224, 0.1540, 0.0227, 0.0360, 0.0336, 0.0472, 0.0639, 0.0759,\n",
       "        0.4462, 0.0449, 0.0867, 0.0532, 0.0484, 0.1815, 0.1971, 0.1462, 0.2402,\n",
       "        0.1867, 0.9692, 1.0000, 0.0954, 0.3056, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from explainable_bert_classifier.input_saliency_maps import connectivity_tensor_computation\n",
    "\n",
    "idx = 10 #index in the batch of the vulnerability to analyze\n",
    "connectivity_tensor_computation(classifier.model, input_ids[idx], attention_mask[idx], verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*top_k_tokens* takes as input a vulnerability description and returns the list of input tokens (tokenized representation of the description) along with the indices, the values and the connectivities of the top k tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_tokens': ['[CLS]',\n",
       "  'adobe',\n",
       "  'ac',\n",
       "  '##ro',\n",
       "  '##bat',\n",
       "  'and',\n",
       "  'reader',\n",
       "  'versions',\n",
       "  '2019',\n",
       "  '.',\n",
       "  '01',\n",
       "  '##2',\n",
       "  '.',\n",
       "  '2003',\n",
       "  '##5',\n",
       "  'and',\n",
       "  'earlier',\n",
       "  ',',\n",
       "  '2019',\n",
       "  '.',\n",
       "  '01',\n",
       "  '##2',\n",
       "  '.',\n",
       "  '2003',\n",
       "  '##5',\n",
       "  'and',\n",
       "  'earlier',\n",
       "  ',',\n",
       "  '2017',\n",
       "  '.',\n",
       "  '01',\n",
       "  '##1',\n",
       "  '.',\n",
       "  '301',\n",
       "  '##42',\n",
       "  'and',\n",
       "  'earlier',\n",
       "  ',',\n",
       "  '2017',\n",
       "  '.',\n",
       "  '01',\n",
       "  '##1',\n",
       "  '.',\n",
       "  '301',\n",
       "  '##43',\n",
       "  'and',\n",
       "  'earlier',\n",
       "  ',',\n",
       "  '2015',\n",
       "  '.',\n",
       "  '00',\n",
       "  '##6',\n",
       "  '.',\n",
       "  '304',\n",
       "  '##9',\n",
       "  '##7',\n",
       "  'and',\n",
       "  'earlier',\n",
       "  ',',\n",
       "  'and',\n",
       "  '2015',\n",
       "  '.',\n",
       "  '00',\n",
       "  '##6',\n",
       "  '.',\n",
       "  '304',\n",
       "  '##9',\n",
       "  '##8',\n",
       "  'and',\n",
       "  'earlier',\n",
       "  'have',\n",
       "  'an',\n",
       "  'integer',\n",
       "  'over',\n",
       "  '##flow',\n",
       "  'vulnerability',\n",
       "  '.',\n",
       "  'successful',\n",
       "  'exploitation',\n",
       "  'could',\n",
       "  'lead',\n",
       "  'to',\n",
       "  'information',\n",
       "  'disclosure',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " 'top_k_tokens': ['disclosure', 'information', 'adobe', 'integer', '[SEP]'],\n",
       " 'top_k_indices': [83, 82, 1, 72, 85],\n",
       " 'top_k_connectivity_weight': [1.0,\n",
       "  0.9692372679710388,\n",
       "  0.8103095293045044,\n",
       "  0.44617149233818054,\n",
       "  0.3055560290813446]}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from explainable_bert_classifier.input_saliency_maps import top_k_tokens\n",
    "\n",
    "top_k_tokens(test_batch['vulnerability_description'][idx], mytokenizer, classifier.model, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*print_texts_with_top_influential_words_in_bold* print the vulnerability descriptions with the top_k relevant tokens in bold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mAdobe\u001b[0m Acrobat and Reader versions 2019.012.20035 and earlier, 2019.012.20035 and earlier, 2017.011.30142 and earlier, 2017.011.30143 and earlier, 2015.006.30497 and earlier, and 2015.006.30498 and earlier have an \u001b[1minteger\u001b[0m overflow vulnerability. Successful exploitation could lead to \u001b[1minformation\u001b[0m \u001b[1mdisclosure\u001b[0m.\n"
     ]
    }
   ],
   "source": [
    "from explainable_bert_classifier.input_saliency_maps import print_texts_with_top_influential_words_in_bold\n",
    "\n",
    "_ = print_texts_with_top_influential_words_in_bold(test_batch['vulnerability_description'][idx], mytokenizer, classifier.model, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each instance of *test_batch*, printing the predicted label and the confidence score (vaue of the logit of the predicted class after softmax), followed by the vulnerability description with top relevant tokens in bold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------\n",
      "Predicted Confidentiality Impact:  NONE\n",
      "Confidence:  tensor(0.9961, grad_fn=<UnbindBackward>)\n",
      "In Ceph before 12.2.3 and 13.x through 13.0.1, the rgw_civetweb.cc RGWCivetWeb::init_env function in radosgw doesn't handle malformed HTTP \u001b[1mheader\u001b[0ms properly, \u001b[1mallowing\u001b[0m for \u001b[1mdenial\u001b[0m \u001b[1mof\u001b[0m \u001b[1mservice\u001b[0m.\n",
      "--------------------------------------------------------------------------------------------\n",
      "Predicted Confidentiality Impact:  HIGH\n",
      "Confidence:  tensor(0.9798, grad_fn=<UnbindBackward>)\n",
      "An \u001b[1melevation\u001b[0m of \u001b[1mprivilege\u001b[0m vulnerability exists when the \u001b[1mWindows\u001b[0m Update Orchestrator Service improperly handles file \u001b[1moperations\u001b[0m, aka '\u001b[1mWindows\u001b[0m Update Orchestrator Service Elevation of Privilege Vulnerability'. This CVE ID is unique from CVE-2020-0868.\n",
      "--------------------------------------------------------------------------------------------\n",
      "Predicted Confidentiality Impact:  HIGH\n",
      "Confidence:  tensor(0.9803, grad_fn=<UnbindBackward>)\n",
      "The official Consul Docker images 0.7.1 through 1.4.2 contain a blank \u001b[1mpassword\u001b[0m for a root user. System using the Consul Docker container deployed by affected versions of the Docker image may allow a remote attacker to \u001b[1machieve\u001b[0m \u001b[1mroot\u001b[0m access with a \u001b[1mblank\u001b[0m \u001b[1mpassword\u001b[0m.\n",
      "--------------------------------------------------------------------------------------------\n",
      "Predicted Confidentiality Impact:  HIGH\n",
      "Confidence:  tensor(0.9840, grad_fn=<UnbindBackward>)\n",
      "IBM Security Identity Manager 7.0.1 Virtual Appliance \u001b[1mcontains\u001b[0m hard-\u001b[1mcoded\u001b[0m \u001b[1mcredentials\u001b[0m, such as a \u001b[1mpassword\u001b[0m or cryptographic key, which it uses for its own inbound \u001b[1mauthentication\u001b[0m, outbound communication to external components, or encryption of internal data. IBM X-Force ID: 153633.\n",
      "--------------------------------------------------------------------------------------------\n",
      "Predicted Confidentiality Impact:  NONE\n",
      "Confidence:  tensor(0.9921, grad_fn=<UnbindBackward>)\n",
      "Vulnerability in the Solaris component of Oracle Sun Systems Products Suite (subcomponent: NTPD). The supported version that is affected is 11.3. Easily exploitable vulnerability allows low privileged attacker with logon to the infrastructure where Solaris executes to compromise Solaris. Successful attacks of this vulnerability can result in \u001b[1munauthorized\u001b[0m \u001b[1mupdate\u001b[0m, \u001b[1minsert\u001b[0m or \u001b[1mdel\u001b[0m\u001b[1mete\u001b[0m access to some of Solaris accessible data. CVSS 3.0 Base Score 3.3 (Integrity impacts). CVSS Vector: (CVSS:3.0/AV:L/AC:L/PR:L/UI:N/S:U/C:N/I:L/A:N).\n",
      "--------------------------------------------------------------------------------------------\n",
      "Predicted Confidentiality Impact:  LOW\n",
      "Confidence:  tensor(0.9964, grad_fn=<UnbindBackward>)\n",
      "An issue was discovered in S-CMS 3.0. It \u001b[1mallows\u001b[0m \u001b[1mX\u001b[0m\u001b[1mSS\u001b[0m \u001b[1mvia\u001b[0m the admin/demo.\u001b[1mphp\u001b[0m T_id parameter.\n",
      "--------------------------------------------------------------------------------------------\n",
      "Predicted Confidentiality Impact:  NONE\n",
      "Confidence:  tensor(0.8504, grad_fn=<UnbindBackward>)\n",
      "An issue was discovered in py-lmdb 0.97. For certain values of md_\u001b[1mflags\u001b[0m, mdb_node_add does not properly set up a memcpy destination, \u001b[1mleading\u001b[0m to an \u001b[1minvalid\u001b[0m \u001b[1mwrite\u001b[0m operation. \u001b[1mNOTE\u001b[0m: this outcome occurs when accessing a data.mdb file supplied by an attacker.\n",
      "--------------------------------------------------------------------------------------------\n",
      "Predicted Confidentiality Impact:  HIGH\n",
      "Confidence:  tensor(0.8156, grad_fn=<UnbindBackward>)\n",
      "When OTRS uses multiple backends for \u001b[1muser\u001b[0m \u001b[1mauthentication\u001b[0m (with LDAP), agents are able to \u001b[1mlog\u001b[0m\u001b[1min\u001b[0m even if the account is set to \u001b[1minvalid\u001b[0m. This issue affects OTRS; 8.0.9 and prior versions.\n",
      "--------------------------------------------------------------------------------------------\n",
      "Predicted Confidentiality Impact:  HIGH\n",
      "Confidence:  tensor(0.9939, grad_fn=<UnbindBackward>)\n",
      "Zoho ManageEngine Applications Manager version 14740 and \u001b[1mprior\u001b[0m \u001b[1mallows\u001b[0m an authenticated \u001b[1mSQL\u001b[0m \u001b[1mInjection\u001b[0m \u001b[1mvia\u001b[0m a crafted jsp request in the SAP module.\n",
      "--------------------------------------------------------------------------------------------\n",
      "Predicted Confidentiality Impact:  HIGH\n",
      "Confidence:  tensor(0.9950, grad_fn=<UnbindBackward>)\n",
      "\u001b[1mAdobe\u001b[0m Bridge versions 10.0.1 and earlier version have an out-of-\u001b[1mbounds\u001b[0m write vulnerability. Successful exploitation could lead to \u001b[1marbitrary\u001b[0m \u001b[1mcode\u001b[0m \u001b[1mexecution\u001b[0m .\n",
      "--------------------------------------------------------------------------------------------\n",
      "Predicted Confidentiality Impact:  HIGH\n",
      "Confidence:  tensor(0.9804, grad_fn=<UnbindBackward>)\n",
      "\u001b[1mAdobe\u001b[0m Acrobat and Reader versions 2019.012.20035 and earlier, 2019.012.20035 and earlier, 2017.011.30142 and earlier, 2017.011.30143 and earlier, 2015.006.30497 and earlier, and 2015.006.30498 and earlier have an \u001b[1minteger\u001b[0m overflow vulnerability. Successful exploitation could lead to \u001b[1minformation\u001b[0m \u001b[1mdisclosure\u001b[0m.\n",
      "--------------------------------------------------------------------------------------------\n",
      "Predicted Confidentiality Impact:  HIGH\n",
      "Confidence:  tensor(0.9849, grad_fn=<UnbindBackward>)\n",
      "An issue was discovered on Weidmueller IE-SW-VL05M 3.6.6 Build 16102415, IE-SW-VL08MT 3.5.2 Build 16102415, and IE-SW-PL10M 3.3.16 Build 16102416 devices\u001b[1m. \u001b[0m\u001b[1mPassword\u001b[0ms are stored in \u001b[1mclear\u001b[0m\u001b[1mtext\u001b[0m and can be \u001b[1mread\u001b[0m by anyone with access to the device.\n",
      "--------------------------------------------------------------------------------------------\n",
      "Predicted Confidentiality Impact:  HIGH\n",
      "Confidence:  tensor(0.8253, grad_fn=<UnbindBackward>)\n",
      "SolarWinds Serv-U Managed \u001b[1mFile\u001b[0m Transfer (MFT) Web client before 15.1.6 Hotfix 2 is vulnerable to Cross-\u001b[1mSite\u001b[0m \u001b[1mRequest\u001b[0m \u001b[1mForge\u001b[0mry in the file upload \u001b[1mfunctionality\u001b[0m via ?Command=Upload with the Dir and File parameters.\n",
      "--------------------------------------------------------------------------------------------\n",
      "Predicted Confidentiality Impact:  LOW\n",
      "Confidence:  tensor(0.9949, grad_fn=<UnbindBackward>)\n",
      "In FusionPBX up to v4.5.7, the file app\\recordings\\recording_play.php uses an unsanitized \"filename\" variable coming from the URL, which is base64 decoded and reflected in \u001b[1mHTML\u001b[0m, \u001b[1mleading\u001b[0m \u001b[1mto\u001b[0m \u001b[1mX\u001b[0m\u001b[1mSS\u001b[0m.\n",
      "--------------------------------------------------------------------------------------------\n",
      "Predicted Confidentiality Impact:  HIGH\n",
      "Confidence:  tensor(0.9948, grad_fn=<UnbindBackward>)\n",
      "A \u001b[1mremote\u001b[0m \u001b[1mcode\u001b[0m \u001b[1mexecution\u001b[0m vulnerability exists when Internet Explorer improperly accesses objects in memory, aka \"Internet Explorer \u001b[1mMemory\u001b[0m \u001b[1mCorruption\u001b[0m Vulnerability.\" This affects Internet Explorer 11, Internet Explorer 10. This CVE ID is unique from CVE-2018-0870, CVE-2018-0997, CVE-2018-1018, CVE-2018-1020.\n",
      "--------------------------------------------------------------------------------------------\n",
      "Predicted Confidentiality Impact:  HIGH\n",
      "Confidence:  tensor(0.9807, grad_fn=<UnbindBackward>)\n",
      "In libhwbinder, there is a possible information disclosure due to uninitialized data. This could lead to \u001b[1mlocal\u001b[0m \u001b[1minformation\u001b[0m \u001b[1mdisclosure\u001b[0m with System \u001b[1mexecution\u001b[0m \u001b[1mprivileges\u001b[0m required. User interaction is not needed for exploitation.\n"
     ]
    }
   ],
   "source": [
    "from explainable_bert_classifier.input_saliency_maps import print_texts_with_top_influential_words_in_bold\n",
    "\n",
    "predictions = classifier.predict(test_batch)\n",
    "cat_classes = ['HIGH', 'LOW', 'NONE']\n",
    "\n",
    "for description, label, score in zip( test_batch['vulnerability_description'], predictions['predicted_labels'], predictions['predicted_scores'] ):\n",
    "    print('--------------------------------------------------------------------------------------------')\n",
    "    print('Predicted Confidentiality Impact: ', cat_classes[label])\n",
    "    print('Confidence: ', score)\n",
    "    _ = print_texts_with_top_influential_words_in_bold(description, mytokenizer, classifier.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
